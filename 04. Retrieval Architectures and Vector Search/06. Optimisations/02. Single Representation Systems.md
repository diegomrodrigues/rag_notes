## Otimiza√ß√µes em Sistemas de Recupera√ß√£o de Informa√ß√£o Neural: Abordagens para √çndices Planos em Sistemas de Representa√ß√£o √önica

### Introdu√ß√£o
Em sistemas de recupera√ß√£o de informa√ß√£o neural (IR) [^5], a efici√™ncia da busca vetorial √© fundamental. Como mencionado na se√ß√£o 4.6 [^5], diversas otimiza√ß√µes s√£o aplicadas aos *embedding indexes* para melhorar o desempenho. Este cap√≠tulo se aprofunda nas estrat√©gias espec√≠ficas utilizadas para lidar com *single representation systems*, como DPR [Karpukhin et al. 2020] [^5], ANCE [Xiong et al. 2021] [^5] e STAR [Zhan et al. 2021b] [^5], que empregam *flat indexes*. Abordaremos as limita√ß√µes impostas pela utiliza√ß√£o de *product quantization* nesses cen√°rios e discutiremos t√©cnicas recentes, como Po-emm [Zhang et al. 2021] [^5], JPQ [Zhan et al. 2021a] [^5] e RepCONC [Zhan et al. 2022] [^5], que visam mitigar essas restri√ß√µes atrav√©s do treinamento simult√¢neo das fases de *document encoding* e *embedding compression*.

### Desafios e Limita√ß√µes dos √çndices Planos
Sistemas de representa√ß√£o √∫nica, conforme discutido na se√ß√£o 3.1 [^5], representam *queries* e documentos com um √∫nico *embedding* [Urbanek et al. 2019] [^5]. A simplicidade dessa abordagem facilita a implementa√ß√£o de sistemas de recupera√ß√£o, mas imp√µe restri√ß√µes em termos de escalabilidade e efici√™ncia de busca. Os *flat indexes*, utilizados em DPR, ANCE e STAR, armazenam os *embeddings* de documentos explicitamente, exigindo uma busca exaustiva para identificar o documento mais relevante [^5].

A complexidade espacial e temporal de uma busca exaustiva em um *flat index* √© O(nl), onde *n* √© o n√∫mero de documentos e *l* √© a dimensionalidade dos *embeddings*. Essa complexidade torna-se proibitiva para grandes cole√ß√µes de documentos e *embeddings* de alta dimens√£o.

> üí° **Exemplo Num√©rico:**
> Suponha que temos uma cole√ß√£o de 1 milh√£o de documentos (*n* = 1,000,000) e *embeddings* com dimensionalidade 768 (*l* = 768). A complexidade computacional seria proporcional a 1,000,000 * 768 = 768,000,000 opera√ß√µes. Cada busca exigiria avaliar a similaridade do *query embedding* com 768 milh√µes de vetores, tornando a busca extremamente lenta.

#### A Impraticabilidade do *Product Quantization* em √çndices Planos

O *product quantization* (PQ) √© uma t√©cnica de compress√£o de vetores que visa reduzir o espa√ßo de armazenamento e acelerar a busca aproximada por vizinhos mais pr√≥ximos (ANN) [J√©gou et al. 2011] [^5]. No entanto, a aplica√ß√£o direta de PQ em *single representation systems* utilizando *flat indexes* introduz um impacto negativo nas m√©tricas de IR, conforme mencionado na se√ß√£o 4.6 [^5].

Esse impacto negativo decorre da *separa√ß√£o entre as fases de document encoding e embedding compression* [^5]. Em sistemas tradicionais que utilizam PQ, os *embeddings* dos documentos s√£o primeiramente computados e, em seguida, quantizados utilizando um c√≥digo pr√©-definido. Essa separa√ß√£o impede que o processo de *encoding* se adapte √† quantiza√ß√£o, resultando em *embeddings* sub√≥timos para a tarefa de *ranking*.

Para formalizar essa observa√ß√£o, podemos introduzir o conceito de *distor√ß√£o da quantiza√ß√£o*.

**Defini√ß√£o 1 (Distor√ß√£o da Quantiza√ß√£o):** Seja $x \in \mathbb{R}^l$ um embedding de um documento e $q(x)$ a representa√ß√£o quantizada de $x$. A distor√ß√£o da quantiza√ß√£o $D(x, q(x))$ √© definida como a dist√¢ncia entre o embedding original e sua vers√£o quantizada, ou seja, $D(x, q(x)) = ||x - q(x)||^2$.

A separa√ß√£o entre as fases de *encoding* e quantiza√ß√£o tende a aumentar a distor√ß√£o da quantiza√ß√£o, pois o encoder n√£o √© treinado para minimizar essa distor√ß√£o.

> üí° **Exemplo Num√©rico:**
> Considere um embedding $x = [0.1, 0.5, 0.8, 0.2]$ e suponha que, ap√≥s a quantiza√ß√£o (usando PQ), ele se torna $q(x) = [0.0, 0.5, 1.0, 0.0]$.  A distor√ß√£o da quantiza√ß√£o √©:
>
> $D(x, q(x)) = ||x - q(x)||^2 = (0.1-0.0)^2 + (0.5-0.5)^2 + (0.8-1.0)^2 + (0.2-0.0)^2 = 0.01 + 0 + 0.04 + 0.04 = 0.09$.
>
> Se o encoder fosse treinado para minimizar essa distor√ß√£o, ele poderia gerar um embedding mais pr√≥ximo dos centr√≥ides de quantiza√ß√£o, reduzindo o valor de *D(x, q(x))*.

### T√©cnicas de Treinamento Simult√¢neo para Otimiza√ß√£o
Para superar as limita√ß√µes impostas pela separa√ß√£o entre as fases de *document encoding* e *embedding compression*, t√©cnicas recentes prop√µem o treinamento simult√¢neo dessas fases [^5]. Essas t√©cnicas, exemplificadas por Po-emm, JPQ e RepCONC, visam otimizar o processo de *encoding* para produzir *embeddings* que sejam intrinsecamente adequados √† quantiza√ß√£o.

**Teorema 1:** O treinamento simult√¢neo das fases de *document encoding* e *embedding compression* resulta em embeddings que minimizam a distor√ß√£o da quantiza√ß√£o, levando a um melhor desempenho em tarefas de recupera√ß√£o de informa√ß√£o.

*Estrat√©gia da Prova:* A prova pode ser constru√≠da mostrando que o treinamento simult√¢neo permite que o encoder aprenda a gerar embeddings que s√£o mais robustos √† quantiza√ß√£o, ou seja, que possuem uma menor distor√ß√£o ap√≥s a quantiza√ß√£o. Isso pode ser demonstrado formalmente atrav√©s da an√°lise da fun√ß√£o de perda utilizada no treinamento simult√¢neo, que tipicamente inclui um termo que penaliza a distor√ß√£o da quantiza√ß√£o.

#### Po-emm, JPQ e RepCONC: Uma Vis√£o Geral

*   **Po-emm (Projection-aware Online Embedding and Metric learning):** Essa t√©cnica integra o aprendizado de *embeddings* com a quantiza√ß√£o de produtos, otimizando as proje√ß√µes lineares utilizadas na quantiza√ß√£o durante o treinamento do modelo de *encoding* [Zhang et al. 2021] [^5]. Ao considerar a estrutura de quantiza√ß√£o durante o treinamento, o Po-emm consegue gerar *embeddings* que s√£o mais bem preservados ap√≥s a quantiza√ß√£o, resultando em melhorias significativas no desempenho de recupera√ß√£o.
*   **JPQ (Jointly Optimizing Product Quantization and Deep Hashing):** O JPQ combina *product quantization* com *deep hashing*, aprendendo representa√ß√µes bin√°rias compactas que preservam a similaridade sem√¢ntica dos documentos [Zhan et al. 2021a] [^5]. Essa abordagem utiliza redes neurais profundas para mapear os documentos em c√≥digos bin√°rios, otimizando simultaneamente a estrutura de *hashing* e os *embeddings* para minimizar a perda de informa√ß√£o durante a quantiza√ß√£o.
*   **RepCONC (Representation CONCensation):** O RepCONC visa condensar a informa√ß√£o relevante dos documentos em representa√ß√µes compactas, utilizando um processo de destila√ß√£o do conhecimento [Zhan et al. 2022] [^5]. Essa t√©cnica treina um modelo compacto para replicar o comportamento de um modelo maior e mais complexo, preservando a informa√ß√£o essencial para a tarefa de *ranking*. O RepCONC tamb√©m incorpora a quantiza√ß√£o durante o treinamento, garantindo que as representa√ß√µes condensadas sejam adequadas para compress√£o e busca eficiente.

> üí° **Exemplo Num√©rico (Knowledge Distillation in RepCONC):**
>
> Suponha que um modelo "teacher" (grande) produza uma distribui√ß√£o de probabilidade sobre documentos relevantes para uma dada query:  $P_{teacher} = [0.8, 0.1, 0.05, 0.05]$. O objetivo do modelo "student" (compacto) √© aprender a prever uma distribui√ß√£o similar, por exemplo, $P_{student} = [0.75, 0.12, 0.07, 0.06]$.
>
> A fun√ß√£o de perda de destila√ß√£o (e.g., Kullback-Leibler divergence) medir√° a diferen√ßa entre essas distribui√ß√µes, e o RepCONC otimiza o modelo student para se aproximar do teacher, garantindo que o modelo compacto preserve a informa√ß√£o essencial. Uma simplifica√ß√£o seria usar o MSE (Mean Squared Error):
> $$MSE = \frac{1}{4} \sum_{i=1}^{4} (P_{teacher_i} - P_{student_i})^2 = \frac{1}{4} [(0.8-0.75)^2 + (0.1-0.12)^2 + (0.05-0.07)^2 + (0.05-0.06)^2] = \frac{1}{4} [0.0025 + 0.0004 + 0.0004 + 0.0001] = 0.00085$$.
> Reduzir este erro ajuda a preservar a informa√ß√£o no modelo comprimido.

#### Benef√≠cios do Treinamento Simult√¢neo

O treinamento simult√¢neo das fases de *document encoding* e *embedding compression* oferece diversos benef√≠cios em rela√ß√£o √†s abordagens tradicionais:

*   **Otimiza√ß√£o End-to-End:** Permite que o modelo de *encoding* se adapte √† estrutura de quantiza√ß√£o, produzindo *embeddings* mais adequados para a compress√£o.
*   **Preserva√ß√£o da Informa√ß√£o:** Minimiza a perda de informa√ß√£o durante a quantiza√ß√£o, resultando em melhorias no desempenho de recupera√ß√£o.
*   **Efici√™ncia de Busca:** Facilita a busca eficiente por vizinhos mais pr√≥ximos, aproveitando as representa√ß√µes compactas geradas pela quantiza√ß√£o.

Al√©m desses benef√≠cios, o treinamento simult√¢neo tamb√©m pode levar a uma melhor generaliza√ß√£o do modelo, conforme detalhado no seguinte lema:

**Lema 1:** O treinamento simult√¢neo tende a resultar em modelos que generalizam melhor para novos dados, pois for√ßa o encoder a aprender representa√ß√µes mais robustas e menos sens√≠veis a ru√≠dos.

*Estrat√©gia da Prova:* A prova pode ser baseada em argumentos de regulariza√ß√£o. Ao incorporar a quantiza√ß√£o no processo de treinamento, o modelo √© exposto a uma forma de ru√≠do (a distor√ß√£o introduzida pela quantiza√ß√£o). O treinamento para minimizar a distor√ß√£o da quantiza√ß√£o for√ßa o modelo a aprender representa√ß√µes que s√£o menos sens√≠veis a esse ru√≠do, o que, por sua vez, leva a uma melhor generaliza√ß√£o.

> üí° **Exemplo Num√©rico (Contrastive Learning):**
>
> No treinamento contrastivo, pares de documentos relevantes (positivos) e irrelevantes (negativos) s√£o usados para treinar o encoder. Suponha que o score de similaridade entre a query e um documento positivo seja $s_+ = 0.7$, e o score entre a query e um documento negativo seja $s_- = 0.2$.
>
> Uma fun√ß√£o de perda comum, como a "margin ranking loss", √© definida como:  $L = max(0, margin - s_+ + s_-)$.
>
> Se o *margin* for definido como 1.0, ent√£o $L = max(0, 1.0 - 0.7 + 0.2) = max(0, 0.5) = 0.5$. O objetivo do treinamento √© minimizar essa perda, aumentando $s_+$ e diminuindo $s_-$.  Se, ap√≥s uma itera√ß√£o de treinamento, $s_+$ se tornar 0.8 e $s_-$ se tornar 0.1, ent√£o $L = max(0, 1.0 - 0.8 + 0.1) = max(0, 0.3) = 0.3$. A perda diminui, indicando que o modelo est√° aprendendo a distinguir melhor documentos relevantes e irrelevantes.
>
> O treinamento simult√¢neo, ao considerar a quantiza√ß√£o, pode garantir que essa separa√ß√£o seja mantida mesmo ap√≥s a compress√£o dos embeddings.

### Conclus√£o
A otimiza√ß√£o de *embedding indexes* √© crucial para a escalabilidade e efici√™ncia de sistemas de recupera√ß√£o de informa√ß√£o neural. Em sistemas de representa√ß√£o √∫nica, a utiliza√ß√£o de *flat indexes* apresenta desafios em termos de armazenamento e velocidade de busca. Embora o *product quantization* seja uma t√©cnica promissora para compress√£o de vetores, sua aplica√ß√£o direta em *flat indexes* pode degradar o desempenho de IR devido √† separa√ß√£o entre as fases de *document encoding* e *embedding compression*.

T√©cnicas recentes, como Po-emm, JPQ e RepCONC, prop√µem o treinamento simult√¢neo dessas fases, permitindo que o modelo de *encoding* se adapte √† estrutura de quantiza√ß√£o e produza *embeddings* mais adequados para compress√£o e busca eficiente. Essas abordagens representam um avan√ßo significativo na otimiza√ß√£o de sistemas de recupera√ß√£o de informa√ß√£o neural, abrindo caminho para o desenvolvimento de sistemas mais escal√°veis e eficientes.
### Refer√™ncias
[^5]: Nicola Tonellotto. 2022. Lecture Notes on Neural Information Retrieval.
<!-- END -->