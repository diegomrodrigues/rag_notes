## Otimiza√ß√µes em Sistemas de Recupera√ß√£o com M√∫ltiplas Representa√ß√µes: ColBERT e Abordagens de Busca Aproximada

### Introdu√ß√£o
Este cap√≠tulo aprofunda as otimiza√ß√µes empregadas em sistemas de recupera√ß√£o de informa√ß√£o neural (neural IR) que utilizam m√∫ltiplas representa√ß√µes, com √™nfase particular na arquitetura ColBERT [^25] e nas t√©cnicas de indexa√ß√£o e busca aproximada do vizinho mais pr√≥ximo (Approximate Nearest Neighbor - ANN) [^30, 31]. Discutiremos como essas otimiza√ß√µes s√£o cruciais para lidar com a complexidade e a escala de sistemas que mant√™m m√∫ltiplas representa√ß√µes de documentos, equilibrando efici√™ncia computacional com precis√£o na recupera√ß√£o de informa√ß√µes.

### Arquiteturas com M√∫ltiplas Representa√ß√µes e Desafios de Escalabilidade
Como vimos anteriormente, sistemas de recupera√ß√£o de informa√ß√£o (IR) evolu√≠ram desde modelos esparsos como o **Bag of Words (BOW)** [^9] e m√©todos de *Learning-to-Rank (LTR)* [^10] para representa√ß√µes densas baseadas em *word embeddings* [^11] e modelos de linguagem pr√©-treinados (Pre-trained Language Models - PLMs) [^12]. A transi√ß√£o para representa√ß√µes densas permitiu capturar nuances sem√¢nticas mais ricas, mas tamb√©m introduziu desafios significativos em termos de escalabilidade e efici√™ncia computacional.

Em particular, os sistemas que adotam *m√∫ltiplas representa√ß√µes* para documentos, como o ColBERT [^25], enfrentam um desafio ainda maior. Ao contr√°rio dos sistemas com *single representations* [^22] que utilizam um √∫nico embedding para representar cada documento, o ColBERT mant√©m um embedding para cada token do documento, resultando em um aumento substancial no n√∫mero de vetores a serem indexados e buscados.

> üí° **Exemplo Num√©rico:** Considere um sistema com 1 milh√£o de documentos. Se um modelo *single representation* usa um embedding de tamanho 768 para cada documento, o sistema precisa indexar 1 milh√£o de vetores de tamanho 768. Se um documento tem em m√©dia 200 tokens e o ColBERT usa um embedding de tamanho 768 para cada token, ent√£o o sistema precisa indexar 200 milh√µes de vetores de tamanho 768. Este aumento de 200 vezes no n√∫mero de vetores ilustra o desafio de escalabilidade.

Essa caracter√≠stica exige otimiza√ß√µes cuidadosas para garantir que a busca por documentos relevantes possa ser realizada em tempo h√°bil, sem comprometer a qualidade dos resultados.

**Proposi√ß√£o 1** Uma alternativa para reduzir a quantidade de vetores a serem indexados √© aplicar t√©cnicas de redu√ß√£o de dimensionalidade nos embeddings dos tokens, como a An√°lise de Componentes Principais (PCA).

Essa caracter√≠stica exige otimiza√ß√µes cuidadosas para garantir que a busca por documentos relevantes possa ser realizada em tempo h√°bil, sem comprometer a qualidade dos resultados.

### ColBERT: Recupera√ß√£o Baseada em Intera√ß√£o Tardia
O ColBERT [^25] se destaca por sua abordagem de *late interaction scoring*, onde a similaridade entre a *query* e o *document* √© calculada somente ap√≥s uma etapa inicial de recupera√ß√£o, diferentemente de modelos que realizam essa intera√ß√£o de forma impl√≠cita ou antecipada. Cada *query* e *document* s√£o representados por m√∫ltiplos embeddings, correspondendo a cada token. A fun√ß√£o de relev√¢ncia em ColBERT √© expressa como [^25]:

$$s(q,d) = \sum_{i=0}^{|q|} \max_{j=0,\ldots,|d|} \phi_i \cdot \psi_j$$.

onde $\phi_i$ representa o embedding do $i$-√©simo token da *query* e $\psi_j$ representa o embedding do $j$-√©simo token do *document*. Essa abordagem permite que cada termo da *query* contribua para o escore final atrav√©s de uma correspond√™ncia (maximal) com um termo diferente do documento, capturando rela√ß√µes lexicais mais sutis [^25].

> üí° **Exemplo Num√©rico:** Suponha que a *query* seja "melhor filme" e o documento contenha a frase "Este √© um √≥timo filme.".  Os embeddings dos tokens (simplificados para este exemplo) poderiam ser:
>
> *   $\phi_{\text{melhor}} = [0.8, 0.2]$
> *   $\phi_{\text{filme}} = [0.1, 0.9]$
> *   $\psi_{\text{Este}} = [0.2, 0.1]$
> *   $\psi_{\text{√©}} = [0.3, 0.2]$
> *   $\psi_{\text{um}} = [0.1, 0.1]$
> *   $\psi_{\text{√≥timo}} = [0.7, 0.2]$
> *   $\psi_{\text{filme}} = [0.1, 0.9]$
>
>  Ent√£o,
>
> $\max(\phi_{\text{melhor}} \cdot \psi_j) = \max([0.8, 0.2] \cdot [0.2, 0.1], [0.8, 0.2] \cdot [0.3, 0.2], \ldots, [0.8, 0.2] \cdot [0.7, 0.2], [0.8, 0.2] \cdot [0.1, 0.9]) = \max(0.18, 0.28, \ldots, 0.6, 0.26) = 0.6$ (correspondente a "√≥timo")
>
> $\max(\phi_{\text{filme}} \cdot \psi_j) = \max([0.1, 0.9] \cdot [0.2, 0.1], [0.1, 0.9] \cdot [0.3, 0.2], \ldots, [0.1, 0.9] \cdot [0.7, 0.2], [0.1, 0.9] \cdot [0.1, 0.9]) = \max(0.11, 0.21, \ldots, 0.3, 0.82) = 0.82$ (correspondente a "filme")
>
> $s(q, d) = 0.6 + 0.82 = 1.42$
>
> Este exemplo simplificado ilustra como cada token da *query* encontra a melhor correspond√™ncia no documento, mesmo que n√£o haja uma correspond√™ncia exata ("melhor" -> "√≥timo").

**Teorema 2** A complexidade computacional da fun√ß√£o de relev√¢ncia $s(q, d)$ √© $O(|q| \cdot |d|)$, onde $|q|$ e $|d|$ s√£o os comprimentos da query e do documento, respectivamente.
*Prova*: A fun√ß√£o de relev√¢ncia envolve calcular o produto escalar entre cada embedding da query ($\phi_i$) com todos os embeddings do documento ($\psi_j$) e tomar o valor m√°ximo. Isso resulta em $|q|$ itera√ß√µes externas, cada uma contendo $|d|$ produtos escalares e uma opera√ß√£o de m√°ximo. Portanto, a complexidade total √© $O(|q| \cdot |d|)$.

### Indexa√ß√£o IVFPQ e Busca ANN
Para lidar com o grande n√∫mero de embeddings de documentos no ColBERT, s√£o utilizadas t√©cnicas de *Inverted File with Product Quantization (IVFPQ)* e *Approximate Nearest Neighbor (ANN) search* [^34].

1.  **Inverted File (IVF):** Divide o espa√ßo vetorial dos embeddings em *clusters* ou parti√ß√µes, utilizando um *quantizer* [^32]. Cada parti√ß√£o cont√©m uma lista invertida de documentos cujos embeddings est√£o pr√≥ximos ao centroide dessa parti√ß√£o. No momento da busca, apenas as parti√ß√µes mais promissoras (i.e., aquelas cujos centroides est√£o mais pr√≥ximos do embedding da *query*) s√£o consideradas, reduzindo o espa√ßo de busca.

2.  **Product Quantization (PQ):** Cada embedding √© decomposto em subvetores, e cada subvetor √© quantizado independentemente usando *k-means* [^32]. Os centroides resultantes formam um *codebook*. O embedding original √© ent√£o aproximado pela concatena√ß√£o dos centroides dos seus subvetores. Essa t√©cnica reduz drasticamente o espa√ßo de armazenamento e permite c√°lculos de dist√¢ncia mais r√°pidos [^32].

> üí° **Exemplo Num√©rico (PQ):** Imagine um embedding de dimens√£o 128. Com PQ, podemos dividi-lo em 8 subvetores de dimens√£o 16 cada. Para cada subvetor, aplicamos k-means com, digamos, 256 centroides. Assim, para representar um subvetor, precisamos apenas do ID do centroide (8 bits, pois $2^8 = 256$). Portanto, em vez de armazenar 128 floats (cada float com 32 bits), armazenamos 8 bytes (8 subvetores * 1 byte/subvetor), reduzindo significativamente o espa√ßo de armazenamento. A dist√¢ncia entre dois embeddings √© aproximada pela soma das dist√¢ncias entre os centroides correspondentes.
>
> **Exemplo Num√©rico (IVF):** Imagine que temos 1 milh√£o de embeddings.  Com IVF, podemos dividi-los em 1000 parti√ß√µes (clusters). Durante a busca, calculamos a dist√¢ncia entre o embedding da *query* e os 1000 centroides das parti√ß√µes.  Selecionamos as 10 parti√ß√µes mais pr√≥ximas e buscamos apenas dentro dessas 10 parti√ß√µes, reduzindo o espa√ßo de busca de 1 milh√£o para aproximadamente 10,000 embeddings.

Combinando IVF e PQ, o IVFPQ index organiza os embeddings em parti√ß√µes e quantiza cada embedding dentro de sua parti√ß√£o. Durante a busca, as dist√¢ncias aproximadas s√£o calculadas usando os *codebooks*, permitindo uma identifica√ß√£o r√°pida dos vizinhos mais pr√≥ximos aproximados.

![Ranking pipeline architecture for multiple representation systems using learned embeddings and ANN search.](./../images/image3.png)

The image, labeled as Figure 9, depicts the ranking pipeline architecture for multiple representation systems within the context of neural information retrieval. It distinguishes between 'Online' and 'Offline' components, showing how a user's query is processed in real-time and how the document collection is preprocessed for efficient retrieval. Key components include learned query and document representation encoders, ANN (Approximate Nearest Neighbors) search, Neural Re-Ranker, and IVFPQ (Inverted File with Product Quantization) index, illustrating a dense retrieval architecture as discussed in Section 4 of the document.

**Teorema 2.1** A escolha do n√∫mero de parti√ß√µes no IVF e o n√∫mero de subvetores e centroides no PQ afeta diretamente a precis√£o da busca e o tempo de indexa√ß√£o. Aumentar o n√∫mero de parti√ß√µes e centroides geralmente melhora a precis√£o, mas tamb√©m aumenta o tempo de indexa√ß√£o e o tamanho do √≠ndice.
*Prova*: (Discuss√£o) Aumentar o n√∫mero de parti√ß√µes no IVF resulta em parti√ß√µes menores e mais especializadas, permitindo uma melhor aproxima√ß√£o dos vizinhos mais pr√≥ximos durante a busca. Similarmente, aumentar o n√∫mero de centroides no PQ permite uma representa√ß√£o mais precisa dos embeddings originais. No entanto, tanto o processo de cria√ß√£o das parti√ß√µes (clustering) quanto o processo de quantiza√ß√£o se tornam mais custosos computacionalmente, aumentando o tempo de indexa√ß√£o. Adicionalmente, um n√∫mero maior de parti√ß√µes e centroides aumenta o tamanho do √≠ndice, impactando o espa√ßo de armazenamento necess√°rio.

### Otimiza√ß√µes Adicionais e Re-Ranking
Embora a indexa√ß√£o IVFPQ e a busca ANN acelerem significativamente o processo de recupera√ß√£o, as similaridades aproximadas resultantes podem ser imprecisas. Para mitigar isso, uma etapa de *re-ranking* √© aplicada.

1.  **Recupera√ß√£o Inicial com ANN:** Para cada embedding de *query*, a busca ANN computa o conjunto de k' embeddings de documento mais similares [^34].

2.  **Mapeamento de Embeddings para Documentos:** Os embeddings recuperados s√£o mapeados de volta para os documentos correspondentes [^34].

3.  **Re-Ranking com Pontua√ß√£o Exata:** O conjunto de documentos recuperados √© re-classificado usando os embeddings de *query* e *document*, computando as pontua√ß√µes de relev√¢ncia exatas conforme definido pela fun√ß√£o de similaridade do ColBERT. Essa etapa garante que o *ranking* final seja baseado em pontua√ß√µes precisas, melhorando a qualidade dos resultados [^34].

> üí° **Exemplo Num√©rico (Re-ranking):** Suponha que a busca ANN retorne os seguintes 5 documentos para uma *query*, com suas pontua√ß√µes aproximadas:
>
> | Documento | Pontua√ß√£o ANN |
> | --------- | ------------- |
> | Doc 1     | 0.85          |
> | Doc 2     | 0.82          |
> | Doc 3     | 0.80          |
> | Doc 4     | 0.78          |
> | Doc 5     | 0.75          |
>
> Ap√≥s o re-ranking com a pontua√ß√£o exata do ColBERT, as pontua√ß√µes podem mudar:
>
> | Documento | Pontua√ß√£o ANN | Pontua√ß√£o ColBERT | Posi√ß√£o Final |
> | --------- | ------------- | ------------------ | ------------- |
> | Doc 1     | 0.85          | 1.50               | 2             |
> | Doc 2     | 0.82          | 1.60               | 1             |
> | Doc 3     | 0.80          | 1.45               | 3             |
> | Doc 4     | 0.78          | 1.30               | 4             |
> | Doc 5     | 0.75          | 1.20               | 5             |
>
> Observe que o Doc 2, que tinha uma pontua√ß√£o ANN menor que o Doc 1, agora tem a pontua√ß√£o ColBERT mais alta e √©, portanto, classificado em primeiro lugar. Isso demonstra como o re-ranking pode corrigir imprecis√µes da busca ANN inicial.
    
![Re-ranking pipeline architecture for interaction-focused neural IR systems.](./../images/image1.png)

The image, labeled as Figure 7, illustrates the re-ranking pipeline architecture for interaction-focused neural information retrieval (IR) systems as described in Section 4.1. It depicts a user query flowing into a 'Candidates Retriever' which accesses a 'Document Collection' to produce a 'Candidates List.' Subsequently, a 'Neural Re-Ranker' utilizes a learned query-document representation \(\eta(q,d)\) to generate a 'Results List' ultimately delivered to the user's device, which is a mobile, laptop, and desktop. The core concept emphasizes how interaction-focused neural IR systems employ a two-stage process: initial candidate retrieval followed by neural re-ranking, a methodology designed to enhance retrieval accuracy and relevance for user interaction. The re-ranker also takes as input the query to rank and output results list.

**Lema 3** O n√∫mero k' de embeddings recuperados na etapa inicial da busca ANN influencia o tradeoff entre precis√£o e efici√™ncia no re-ranking.

*Prova*: Um valor maior de k' aumenta a probabilidade de incluir documentos relevantes no conjunto a ser re-classificado, melhorando a precis√£o final. No entanto, tamb√©m aumenta o custo computacional da etapa de re-ranking, uma vez que mais documentos precisam ser avaliados com a fun√ß√£o de similaridade exata do ColBERT. Por outro lado, um valor menor de k' reduz o custo do re-ranking, mas pode levar √† exclus√£o de documentos relevantes, diminuindo a precis√£o.

### Impacto das Otimiza√ß√µes
As otimiza√ß√µes descritas acima t√™m um impacto significativo no desempenho dos sistemas de recupera√ß√£o baseados em m√∫ltiplas representa√ß√µes [^34]:
- A indexa√ß√£o IVFPQ reduz drasticamente o tempo de busca, permitindo a recupera√ß√£o eficiente em grandes cole√ß√µes de documentos [^32].
- A busca ANN fornece uma aproxima√ß√£o r√°pida dos vizinhos mais pr√≥ximos, permitindo uma pr√©-sele√ß√£o eficiente de candidatos [^30].
- O re-ranking com pontua√ß√µes exatas melhora a precis√£o dos resultados, garantindo que os documentos mais relevantes sejam classificados no topo [^34].

> üí° **Exemplo Num√©rico (Impacto das Otimiza√ß√µes):** Considere um experimento com 1 milh√£o de documentos e um conjunto de 1000 *queries*. Medimos o tempo de busca e o MAP (Mean Average Precision) com e sem as otimiza√ß√µes:
>
> | M√©todo                      | Tempo de Busca (ms) | MAP   |
> | --------------------------- | ------------------- | ----- |
> | ColBERT sem otimiza√ß√µes    | 5000                | 0.75  |
> | ColBERT com IVFPQ + ANN    | 500                 | 0.72  |
> | ColBERT com IVFPQ + ANN + Re-ranking | 700                 | 0.78  |
>
> Este exemplo mostra que IVFPQ e ANN reduzem drasticamente o tempo de busca, mas podem diminuir ligeiramente o MAP. O re-ranking compensa essa perda de precis√£o e at√© melhora o MAP em rela√ß√£o ao sistema sem otimiza√ß√µes, enquanto ainda mant√©m um tempo de busca significativamente menor.

### Conclus√£o
Sistemas de m√∫ltiplas representa√ß√µes como ColBERT apresentam um *trade-off* entre a riqueza sem√¢ntica e a complexidade computacional [^25]. As otimiza√ß√µes discutidas neste cap√≠tulo, incluindo indexa√ß√£o IVFPQ e busca ANN, s√£o cruciais para permitir que esses sistemas escalem para grandes cole√ß√µes de documentos, mantendo a precis√£o e a relev√¢ncia dos resultados da busca [^32]. Ao adotar essas t√©cnicas, os sistemas de recupera√ß√£o de informa√ß√£o neural podem efetivamente aproveitar o poder das m√∫ltiplas representa√ß√µes, proporcionando capacidades de busca aprimoradas para uma ampla gama de aplica√ß√µes.

### Refer√™ncias

[^9]: S. B√ºttcher, C. Clarke, and G. V. Cormack. 2010. Information Retrieval: Implementing and Evaluating Search Engines. The MIT Press.
[^10]: M. Bendersky, W. B. Croft, and Y. Diao. 2011. Quality-biased ranking of web documents. In Proc. WSDM, pp. 95‚Äì104.
[^11]: T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In Proc. NIPS.
[^12]: J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proc. NAACL, pp. 4171‚Äì4186.
[^22]: J. Urbanek, A. Fan, S. Karamcheti, S. Jain, S. Humeau, E. Dinan, T. Rockt√§schel, D. Kiela, A. Szlam, and J. Weston. 2019. Learning to speak and act in a fantasy text adventure game. In Proc. EMNLP-IJCNLP, pp. 673‚Äì683.
[^25]: O. Khattab and M. Zaharia. 2020. ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In Proc. SIGIR, p. 39‚Äì48.
[^30]: Y. Bachrach, Y. Finkelstein, R. Gilad-Bachrach, L. Katzir, N. Koenigstein, N. Nice, and U. Paquet. 2014. Speeding up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product Spaces. In Proc. RecSys, p. 257‚Äì264.
[^31]: P. Indyk and R. Motwani. 1998. Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. In Proc. STOC, p. 604‚Äì613.
[^32]: A. Gersho and R. M. Gray. 1992. Vector Quantization and Signal Compression. Kluwer.
[^34]: H. Zhang, H. Shen, Y. Qiu, Y. Jiang, S. Wang, S. Xu, Y. Xiao, B. Long, and W.-Y. Yang. 2021. Joint Learning of Deep Retrieval Model and Product Quantization Based Embedding Index. In Proc. SIGIR, pp. 1718‚Äì1722.
<!-- END -->