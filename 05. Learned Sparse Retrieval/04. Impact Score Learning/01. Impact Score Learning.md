## 5.2 Impact Score Learning: Leveraging Document Embeddings for Term Importance

### Introdu√ß√£o
Na busca por aprimorar a efici√™ncia e a efic√°cia dos sistemas de recupera√ß√£o de informa√ß√£o (IR), o **aprendizado de impacto de pontua√ß√£o (impact score learning)** surge como uma t√©cnica promissora. Conforme delineado na Se√ß√£o 5 [^3], o paradigma tradicional de IR fundamenta-se em representa√ß√µes *sparse*, √≠ndices invertidos, e fun√ß√µes de pontua√ß√£o lexicais, como o BM25. No entanto, modelos neurais de IR, centrados em representa√ß√µes *dense* de queries e documentos, t√™m demonstrado ganhos not√°veis em efic√°cia, embora com custos computacionais mais elevados.

O impact score learning busca integrar os benef√≠cios de modelos neurais, particularmente os baseados em *encoder-only*, aos √≠ndices invertidos cl√°ssicos, mantendo a efici√™ncia inerente a esses √∫ltimos. A ideia central √© utilizar *embeddings* de documentos geradas por modelos *encoder-only* para calcular um √∫nico valor inteiro para cada termo, que servir√° como um *proxy* para a relev√¢ncia desse termo no documento.

### Fundamentos do Impact Score Learning
O conceito de *impact score learning* parte da an√°lise de √≠ndices invertidos cl√°ssicos [^9], que armazenam informa√ß√µes estat√≠sticas sobre a ocorr√™ncia de termos em documentos. Cada *posting list* armazena, para cada termo, uma entrada para cada documento em que o termo aparece, contendo o identificador do documento do documento e a frequ√™ncia do termo nesse documento (TF - *term frequency*).

> üí° **Exemplo Num√©rico: Posting List**
>
> Suponha que temos um termo "recupera√ß√£o" e dois documentos:
>
> *   Documento 1: "A recupera√ß√£o de informa√ß√£o √© crucial." (ID = 1)
> *   Documento 2: "T√©cnicas de recupera√ß√£o avan√ßadas." (ID = 2)
>
> A posting list para o termo "recupera√ß√£o" seria:
>
> | Termo        | Documento ID | Term Frequency (TF) |
> |--------------|--------------|-----------------------|
> | recupera√ß√£o | 1            | 1                     |
> | recupera√ß√£o | 2            | 1                     |

Em contraste, o *impact score learning* ambiciona empregar *embeddings* de documentos para calcular um valor inteiro √∫nico para cada termo, representando sua relev√¢ncia. Este valor, denominado *impact score*, atuaria como um *proxy* para a import√¢ncia do termo no contexto do documento [^37].

Para atingir este objetivo, o processo envolve projetar os *embeddings* de documentos em uma representa√ß√£o de valor √∫nico, utilizando redes neurais e fun√ß√µes ReLU (*Rectified Linear Unit*). As fun√ß√µes ReLU s√£o aplicadas para filtrar valores negativos, e zeros s√£o descartados. Para otimizar o uso de espa√ßo, os valores reais resultantes podem ser quantizados em inteiros positivos de 8 bits [^37].

> üí° **Exemplo Num√©rico: ReLU e Quantiza√ß√£o**
>
> Suponha que o embedding de um documento para o termo "recupera√ß√£o" (ap√≥s alguma transforma√ß√£o pela rede neural) seja \[-0.5, 0.2, -0.1, 0.8].
>
> $\text{Step 1: Aplicar ReLU}$
>
> $ReLU([-0.5, 0.2, -0.1, 0.8]) = [max(0, -0.5), max(0, 0.2), max(0, -0.1), max(0, 0.8)] = [0, 0.2, 0, 0.8]$
>
> $\text{Step 2: Quantiza√ß√£o (para inteiros de 8 bits - escala de 0 a 255)}$
>
> Assumindo que o valor m√°ximo poss√≠vel ap√≥s a ReLU √© 1.0, podemos escalar os valores para 0-255:
>
> $0.2 * 255 = 51$
> $0.8 * 255 = 204$
>
> O impact score quantizado para o termo "recupera√ß√£o" seria ent√£o representado por um valor associado ao documento, onde as dimens√µes relevantes contribuem com 51 e 204, respectivamente, para o score final do termo. Essas dimens√µes podem ser vistas como diferentes "aspectos" da relev√¢ncia.

**Lema 1.** *A aplica√ß√£o da fun√ß√£o ReLU aos embeddings de documentos garante que os impact scores resultantes sejam n√£o-negativos. Isto √© essencial para compatibilidade com √≠ndices invertidos, onde frequ√™ncias de termos s√£o naturalmente n√£o-negativas.*

*Demonstra√ß√£o:* A fun√ß√£o ReLU, definida como $ReLU(x) = max(0, x)$, por defini√ß√£o, retorna 0 para valores de entrada negativos e o pr√≥prio valor para entradas n√£o-negativas. Portanto, ap√≥s a aplica√ß√£o da ReLU, todos os valores no embedding ser√£o n√£o-negativos. Isso se alinha com a interpreta√ß√£o de um impact score como uma medida de relev√¢ncia, que n√£o pode ser negativa.

Al√©m disso, a escolha da fun√ß√£o ReLU permite a introdu√ß√£o de esparsidade. Ao zerar os valores negativos, a ReLU remove dimens√µes potencialmente irrelevantes do embedding, o que pode melhorar a efici√™ncia computacional e a qualidade dos impact scores aprendidos.

### Desafios e Abordagens
Um desafio central no *impact score learning* reside na escolha do vocabul√°rio a ser utilizado [^37]. Dado que a maioria dos modelos *encoder-only* emprega *tokenizers* de *sub-word*, o vocabul√°rio da cole√ß√£o pode ser constru√≠do de duas maneiras distintas:

1.  Utilizando os termos produzidos pelo *tokenizer* de *sub-word* espec√≠fico do *encoder* (e.g., *tokenizers* do tipo BERT).
2.  Utilizando os termos produzidos por um *tokenizer* de palavras (word tokenizer).

A escolha entre estas alternativas tem implica√ß√µes no √≠ndice invertido final [^38]. A primeira abordagem resulta em um menor n√∫mero de termos, mas com *posting lists* mais longas e densas. A segunda abordagem leva a um maior n√∫mero de termos, mas com *posting lists* mais curtas e menos densas.

> üí° **Exemplo Num√©rico: Sub-word vs. Word Tokenizer**
>
> Considere a frase: "A intelig√™ncia artificial √© fascinante."
>
> *   **Word Tokenizer:** \["A", "intelig√™ncia", "artificial", "√©", "fascinante"]
> *   **Sub-word Tokenizer (e.g., Byte Pair Encoding):** \["A", "int", "elig", "√™ncia", "art", "ificial", "√©", "fasci", "nante"]
>
> | Tokenizer     | N√∫mero de Tokens | Tamanho do Vocabul√°rio (estimado) | Comprimento M√©dio da Posting List (estimado) |
> |---------------|------------------|------------------------------------|---------------------------------------------|
> | Word          | 5                | Grande                               | Curto                                         |
> | Sub-word      | 8                | Menor                                | Mais Longo                                    |

**Teorema 2.** *A escolha do vocabul√°rio (sub-word vs. word tokenizer) afeta o trade-off entre tamanho do vocabul√°rio e comprimento das posting lists, impactando diretamente o espa√ßo de armazenamento do √≠ndice invertido e o tempo de busca.*

*Demonstra√ß√£o (Esbo√ßo):* Um vocabul√°rio baseado em sub-words geralmente resulta em um tamanho de vocabul√°rio menor porque os termos s√£o mais granulares e podem ser combinados para formar palavras inteiras. No entanto, cada palavra no documento ser√° decomposta em mais sub-words, levando a frequ√™ncias de termos mais altas e, portanto, posting lists mais longas. Por outro lado, um vocabul√°rio baseado em palavras ter√° um tamanho maior, pois cada palavra √© um termo distinto. As posting lists ser√£o mais curtas, pois cada termo ocorrer√° com menos frequ√™ncia. O espa√ßo de armazenamento total depende do produto do tamanho do vocabul√°rio e do comprimento m√©dio das posting lists. O tempo de busca √© afetado pelo tamanho do vocabul√°rio (mais termos para iterar) e pelo comprimento das posting lists (mais documentos para pontuar).

**Proposi√ß√£o 2.1** *A utiliza√ß√£o de um vocabul√°rio baseado em sub-words pode ser vantajosa em cen√°rios com recursos computacionais limitados para o armazenamento do √≠ndice, enquanto a abordagem baseada em palavras pode ser prefer√≠vel quando a velocidade de busca √© cr√≠tica.*

### Modelos Atuais de Impact Score Learning

V√°rios modelos de *impact score learning* t√™m sido propostos, cada um com suas particularidades:

*   **DeepCT** [^38]: Explora as representa√ß√µes de palavras contextualizadas do BERT para aprender novas frequ√™ncias de termos in-document, a serem utilizadas com fun√ß√µes de ranqueamento cl√°ssicas, como o BM25.
*   **DeepImpact** [^38]: Computa diretamente um *impact score* para cada termo √∫nico em um documento, sem recorrer a fun√ß√µes de ranqueamento cl√°ssicas.
*   **TILDEv2** [^38]: Computa o impacto dos termos com uma abordagem similar ao DeepImpact, mas com diferen√ßas na arquitetura da rede neural e na t√©cnica de expans√£o de documentos.

![Example of DocT5Query model generating related queries for document expansion.](./../images/image1.png)

*   **UniCOIL** [^38]: Utiliza a abordagem COIL, projetando *embeddings* de *query* e documento em pesos de *query* e documento de dimens√£o √∫nica.

> üí° **Exemplo Num√©rico: Impact Scores e BM25**
>
> Suponha que DeepCT aprenda os seguintes impact scores para o documento 1 ( "A recupera√ß√£o de informa√ß√£o √© crucial."):
>
> | Termo        | Impact Score |
> |--------------|--------------|
> | recupera√ß√£o | 50           |
> | informa√ß√£o | 60           |
> | crucial     | 40           |
>
> Usando BM25 (simplificado para fins ilustrativos, com  $k_1 = 1.2$ e $b = 0.75$, e assumindo que o tamanho m√©dio dos documentos na cole√ß√£o √© igual ao tamanho do documento 1):
>
>  $\text{BM25 Score} = \sum_{t \in q \cap d} IDF(t) \cdot \frac{TF(t, d) \cdot (k_1 + 1)}{TF(t, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}$
>
> Se a query for "recupera√ß√£o informa√ß√£o", e assumirmos IDF("recupera√ß√£o") = 1.5, IDF("informa√ß√£o") = 2.0, TF("recupera√ß√£o", d) = 50, TF("informa√ß√£o", d) = 60:
>
> $\text{BM25 Score} = 1.5 \cdot \frac{50 \cdot (1.2 + 1)}{50 + 1.2 \cdot (1 - 0.75 + 0.75 \cdot 1)} + 2.0 \cdot \frac{60 \cdot (1.2 + 1)}{60 + 1.2 \cdot (1 - 0.75 + 0.75 \cdot 1)} = 1.5 \cdot \frac{110}{50 + 1.2} + 2.0 \cdot \frac{132}{60 + 1.2} \approx 3.2 + 4.3 = 7.5$

**Observa√ß√£o:** Uma caracter√≠stica comum a esses modelos √© a necessidade de um treinamento supervisionado ou auto-supervisionado para aprender os impact scores. A qualidade dos dados de treinamento e a escolha da fun√ß√£o de perda s√£o cruciais para o desempenho final do sistema de IR.

### Conclus√£o
O *impact score learning* oferece um caminho promissor para incorporar o poder das representa√ß√µes *dense* aprendidas por redes neurais √† efici√™ncia dos √≠ndices invertidos tradicionais. Ao aprender a representar a import√¢ncia de cada termo em um documento por meio de um √∫nico valor inteiro, essa t√©cnica possibilita a constru√ß√£o de sistemas de IR que combinam efic√°cia e escalabilidade. Modelos como DeepCT, DeepImpact, TILDEv2 e UniCOIL representam diferentes abordagens para realizar o *impact score learning*, cada um com suas vantagens e desvantagens, e continuam a ser √°reas de pesquisa ativa.

### Refer√™ncias
[^3]: Se√ß√£o 5 do documento fornecido.
[^9]: B√ºttcher, C., Clarke, C., and Cormack, G. V. 2010. *Information Retrieval: Implementing and Evaluating Search Engines*. The MIT Press.
[^37]: P√°gina 37 do documento fornecido.
[^38]: P√°gina 38 do documento fornecido.
<!-- END -->