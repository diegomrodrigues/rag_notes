## BLEU: Avalia√ß√£o Baseada em Precis√£o para Gera√ß√£o de Texto

### Introdu√ß√£o

A avalia√ß√£o de modelos de gera√ß√£o de texto, como os utilizados em sistemas de *Retrieval-Augmented Generation* (RAG), requer m√©tricas robustas e eficientes. Uma das m√©tricas mais amplamente utilizadas nesse contexto √© o **BLEU** (Bilingual Evaluation Understudy) [^3]. Este cap√≠tulo se dedica a explorar o BLEU em detalhes, abordando seus fundamentos, c√°lculos e limita√ß√µes.

### Conceitos Fundamentais

O BLEU √© uma m√©trica de avalia√ß√£o baseada em precis√£o que quantifica a sobreposi√ß√£o de *n-grams* entre o texto gerado e o texto de refer√™ncia [^3]. Em ess√™ncia, o BLEU avalia a qualidade da tradu√ß√£o (ou, mais genericamente, da gera√ß√£o de texto) contando quantas palavras (ou sequ√™ncias de palavras) na sa√≠da do modelo tamb√©m aparecem na resposta de refer√™ncia.

**C√°lculo da Precis√£o de N-gram:**

O primeiro passo no c√°lculo do BLEU √© determinar a precis√£o dos *n-grams*. Um *n-gram* √© uma sequ√™ncia cont√≠gua de *n* itens de uma dada sequ√™ncia de texto ou fala. Para calcular a precis√£o do *n-gram*, dividimos o n√∫mero de *n-grams* no texto gerado que tamb√©m aparecem no texto de refer√™ncia pelo n√∫mero total de *n-grams* no texto gerado.

Formalmente, a precis√£o do *n-gram* √© dada por:

$$
p_n = \frac{\text{N√∫mero de n-grams coincidentes}}{\text{N√∫mero total de n-grams no output gerado}}
$$

Onde $p_n$ representa a precis√£o para *n-grams* de tamanho *n*.

> üí° **Exemplo Num√©rico:**
>
> Considere o texto de refer√™ncia: "o gato est√° no tapete".
> E o texto gerado: "gato no tapete".
>
> Para *1-grams* (unigrams):
> - Texto de refer√™ncia: `[o, gato, est√°, no, tapete]`
> - Texto gerado: `[gato, no, tapete]`
> - Unigrams coincidentes: `[gato, no, tapete]` (3 unigrams)
> - N√∫mero total de unigrams no texto gerado: 3
> - $p_1 = \frac{3}{3} = 1.0$
>
> Para *2-grams* (bigrams):
> - Texto de refer√™ncia: `[o gato, gato est√°, est√° no, no tapete]`
> - Texto gerado: `[gato no, no tapete]`
> - Bigrams coincidentes: `[no tapete]` (1 bigram)
> - N√∫mero total de bigrams no texto gerado: 2
> - $p_2 = \frac{1}{2} = 0.5$

**Lema 1:** *A precis√£o de n-gram, $p_n$, est√° sempre no intervalo $[0, 1]$.*

*Prova:* O "N√∫mero de n-grams coincidentes" √©, por defini√ß√£o, n√£o negativo e menor ou igual ao "N√∫mero total de n-grams no output gerado".  Portanto, a fra√ß√£o √© sempre n√£o negativa e menor ou igual a 1. $\blacksquare$

Al√©m da precis√£o, outra m√©trica importante para avaliar a sobreposi√ß√£o de n-grams √© o *recall*. O recall de n-grams mede a propor√ß√£o de n-grams no texto de refer√™ncia que tamb√©m aparecem no texto gerado.

A f√≥rmula para o recall de n-grams √©:

$$
r_n = \frac{\text{N√∫mero de n-grams coincidentes}}{\text{N√∫mero total de n-grams no texto de refer√™ncia}}
$$

Onde $r_n$ representa o recall para *n-grams* de tamanho *n*. Embora o BLEU se concentre na precis√£o, o recall oferece uma perspectiva complementar sobre a cobertura do texto de refer√™ncia pelo texto gerado.

> üí° **Exemplo Num√©rico (Recall):**
>
> Usando os mesmos textos do exemplo anterior:
> - Texto de refer√™ncia: "o gato est√° no tapete".
> - Texto gerado: "gato no tapete".
>
> Para *1-grams* (unigrams):
> - Texto de refer√™ncia: `[o, gato, est√°, no, tapete]`
> - Texto gerado: `[gato, no, tapete]`
> - Unigrams coincidentes: `[gato, no, tapete]` (3 unigrams)
> - N√∫mero total de unigrams no texto de refer√™ncia: 5
> - $r_1 = \frac{3}{5} = 0.6$
>
> Para *2-grams* (bigrams):
> - Texto de refer√™ncia: `[o gato, gato est√°, est√° no, no tapete]`
> - Texto gerado: `[gato no, no tapete]`
> - Bigrams coincidentes: `[no tapete]` (1 bigram)
> - N√∫mero total de bigrams no texto de refer√™ncia: 4
> - $r_2 = \frac{1}{4} = 0.25$
>
> Observa-se que o recall de 1-grams √© 0.6, indicando que o texto gerado cobre 60% dos unigrams do texto de refer√™ncia.

**Brevity Penalty:**

Uma das limita√ß√µes do BLEU √© que ele tende a favorecer sa√≠das excessivamente curtas, que podem ter alta precis√£o de *n-grams* simplesmente porque cont√™m menos palavras [^3]. Para mitigar esse problema, o BLEU incorpora uma penalidade de brevidade (*Brevity Penalty*), que reduz a pontua√ß√£o se o texto gerado for muito mais curto do que o texto de refer√™ncia.

A penalidade de brevidade √© calculada como:

$$
BP =
\begin{cases}
1 & \text{se } \text{comprimento}_\text{gerado} > \text{comprimento}_\text{refer√™ncia} \\
e^{(1 - \frac{\text{comprimento}_\text{refer√™ncia}}{\text{comprimento}_\text{gerado}})} & \text{se } \text{comprimento}_\text{gerado} \leq \text{comprimento}_\text{refer√™ncia}
\end{cases}
$$

Onde $\text{comprimento}_\text{gerado}$ √© o comprimento do texto gerado e $\text{comprimento}_\text{refer√™ncia}$ √© o comprimento do texto de refer√™ncia.

> üí° **Exemplo Num√©rico (Brevity Penalty):**
>
> Usando o exemplo anterior:
> - Texto de refer√™ncia: "o gato est√° no tapete" (comprimento = 5)
> - Texto gerado: "gato no tapete" (comprimento = 3)
>
> Como $\text{comprimento}_\text{gerado} \leq \text{comprimento}_\text{refer√™ncia}$, aplicamos a segunda parte da f√≥rmula:
> $BP = e^{(1 - \frac{5}{3})} = e^{(1 - 1.6667)} = e^{-0.6667} \approx 0.513$
>
> Se o texto gerado fosse "o gato est√° no tapete e", o comprimento seria 6, e como √© maior que o comprimento da refer√™ncia, $BP = 1$.

**Proposi√ß√£o 1:** *A Brevity Penalty (BP) sempre est√° no intervalo (0, 1].*

*Prova:* Se $\text{comprimento}_\text{gerado} > \text{comprimento}_\text{refer√™ncia}$, ent√£o $BP = 1$. Caso contr√°rio, $BP = e^{(1 - \frac{\text{comprimento}_\text{refer√™ncia}}{\text{comprimento}_\text{gerado}})}$.  Como $\text{comprimento}_\text{gerado} \leq \text{comprimento}_\text{refer√™ncia}$, ent√£o $\frac{\text{comprimento}_\text{refer√™ncia}}{\text{comprimento}_\text{gerado}} \geq 1$, e portanto $1 - \frac{\text{comprimento}_\text{refer√™ncia}}{\text{comprimento}_\text{gerado}} \leq 0$.  Assim, $BP = e^{(1 - \frac{\text{comprimento}_\text{refer√™ncia}}{\text{comprimento}_\text{gerado}})} \leq e^0 = 1$. Al√©m disso, como a fun√ß√£o exponencial √© sempre positiva, $BP > 0$. Portanto, $BP \in (0, 1]$. $\blacksquare$

**Pontua√ß√£o BLEU Final:**

A pontua√ß√£o BLEU final √© calculada combinando a precis√£o dos *n-grams* com a penalidade de brevidade. Tipicamente, utiliza-se uma m√©dia geom√©trica das precis√µes dos *n-grams* para diferentes tamanhos de *n*, ponderada por pesos $w_n$.

A f√≥rmula geral do BLEU √©:

$$
BLEU = BP \cdot \exp\left(\sum_{n=1}^{N} w_n \log p_n\right)
$$

Onde:
- $BP$ √© a penalidade de brevidade.
- $p_n$ √© a precis√£o do *n-gram* de tamanho *n*.
- $w_n$ s√£o os pesos para cada precis√£o de *n-gram*, normalmente uniformes (e.g., $w_n = \frac{1}{N}$).
- $N$ √© o tamanho m√°ximo do *n-gram* considerado (tipicamente 4).

> üí° **Exemplo Num√©rico (BLEU):**
>
> Usando os c√°lculos anteriores:
> - $p_1 = 1.0$
> - $p_2 = 0.5$
> - $BP = 0.513$ (calculado anteriormente)
> - Seja $N = 2$ (consideramos at√© bigrams)
> - Pesos uniformes: $w_1 = \frac{1}{2} = 0.5$, $w_2 = \frac{1}{2} = 0.5$
>
> $BLEU = 0.513 \cdot \exp\left(0.5 \cdot \log(1.0) + 0.5 \cdot \log(0.5)\right)$
> $BLEU = 0.513 \cdot \exp\left(0 + 0.5 \cdot (-0.693)\right)$
> $BLEU = 0.513 \cdot \exp\left(-0.3465\right)$
> $BLEU = 0.513 \cdot 0.7071 \approx 0.363$
>
> Este valor de BLEU (0.363) sugere que a frase gerada tem uma sobreposi√ß√£o razo√°vel com a frase de refer√™ncia, mas √© penalizada por ser mais curta.

**Teorema 1:** *A pontua√ß√£o BLEU est√° sempre no intervalo [0, 1].*

*Prova:* Sabemos que $BP \in (0, 1]$ e $p_n \in [0, 1]$. Portanto, $\log p_n \leq 0$ (ou √© indefinido se $p_n = 0$). Assim, $\sum_{n=1}^{N} w_n \log p_n \leq 0$ (assumindo que todos os $p_n$ s√£o maiores que 0, ou que a soma √© $-\infty$ se algum $p_n = 0$).  Portanto, $\exp\left(\sum_{n=1}^{N} w_n \log p_n\right) \in (0, 1]$. Multiplicando por $BP$, que tamb√©m est√° em $(0, 1]$, o resultado final √© um valor em $(0, 1]$. Se algum $p_n=0$, BLEU = 0. Assim, BLEU $\in [0, 1]$. $\blacksquare$

**Teorema 1.1:** *Se a precis√£o de todos os n-grams ($p_n$) for 1 e o comprimento do texto gerado for maior que o comprimento do texto de refer√™ncia, ent√£o a pontua√ß√£o BLEU ser√° 1.*

*Prova:* Se $p_n = 1$ para todo $n$, ent√£o $\log p_n = 0$ para todo $n$. Portanto, $\sum_{n=1}^{N} w_n \log p_n = 0$. Assim, $\exp\left(\sum_{n=1}^{N} w_n \log p_n\right) = e^0 = 1$. Se o comprimento do texto gerado for maior que o comprimento do texto de refer√™ncia, ent√£o $BP = 1$. Portanto, $BLEU = BP \cdot \exp\left(\sum_{n=1}^{N} w_n \log p_n\right) = 1 \cdot 1 = 1$. $\blacksquare$

### Vantagens e Desvantagens

**Vantagens:**

*   **Custo-efetividade:** O BLEU √© computacionalmente eficiente e f√°cil de implementar, tornando-o uma escolha popular para avalia√ß√£o em larga escala [^3].
*   **Amplamente utilizado:** Devido √† sua popularidade, o BLEU serve como um *benchmark* comum, permitindo a compara√ß√£o de diferentes modelos e abordagens.

**Desvantagens:**

*   **Foco na precis√£o:** O BLEU se concentra principalmente na precis√£o, negligenciando outros aspectos importantes da qualidade da gera√ß√£o de texto, como a fluidez, a gram√°tica e a relev√¢ncia contextual.
*   **Penalidade de brevidade:** Apesar de tentar corrigir o problema de sa√≠das curtas, a penalidade de brevidade pode ser excessivamente punitiva em alguns casos.
*   **Limita√ß√µes com sin√¥nimos e par√°frases:** O BLEU pode penalizar sa√≠das que usam sin√¥nimos ou par√°frases, mesmo que transmitam o mesmo significado do texto de refer√™ncia.
*   **Correla√ß√£o limitada com julgamento humano:** Em alguns casos, o BLEU pode n√£o se correlacionar bem com as avalia√ß√µes humanas da qualidade da gera√ß√£o de texto.

### Varia√ß√µes do BLEU

Existem diversas varia√ß√µes do BLEU que buscam mitigar algumas de suas limita√ß√µes. Algumas das varia√ß√µes mais comuns incluem:

*   **NIST:** Similar ao BLEU, mas com uma penalidade de brevidade modificada e uma forma diferente de calcular a precis√£o dos n-grams, dando mais peso a n-grams menos frequentes.
*   **ROUGE (Recall-Oriented Understudy for Gisting Evaluation):** Ao contr√°rio do BLEU, o ROUGE √© baseado em recall em vez de precis√£o. Ele mede a sobreposi√ß√£o de n-grams, sequ√™ncias de palavras e pares de palavras entre o texto gerado e o texto de refer√™ncia, com foco em qu√£o bem o texto gerado cobre o conte√∫do do texto de refer√™ncia. Existem v√°rias m√©tricas ROUGE, como ROUGE-N (baseado em n-grams), ROUGE-L (baseado na maior subsequ√™ncia comum) e ROUGE-S (baseado em pares de palavras).

Essas varia√ß√µes oferecem diferentes perspectivas sobre a qualidade da gera√ß√£o de texto e podem ser mais adequadas para determinadas tarefas ou tipos de texto.

> üí° **Exemplo Comparativo (BLEU vs. ROUGE):**
>
> Suponha o seguinte:
> - Texto de refer√™ncia: "A empresa anunciou um novo produto inovador."
> - Texto gerado 1 (alta precis√£o, baixa cobertura): "Novo produto."
> - Texto gerado 2 (baixa precis√£o, alta cobertura): "A empresa disse que tinha um produto."
>
> | M√©trica   | Texto Gerado 1 | Texto Gerado 2 | Observa√ß√µes                                                                     |
> |-----------|-----------------|-----------------|---------------------------------------------------------------------------------|
> | BLEU       | Alto             | M√©dio           | BLEU favorece o Texto Gerado 1 por sua alta precis√£o, mesmo sendo incompleto.    |
> | ROUGE      | Baixo            | Alto            | ROUGE favorece o Texto Gerado 2 por cobrir mais conte√∫do do texto de refer√™ncia. |
>
> Este exemplo ilustra a diferen√ßa fundamental entre BLEU (foco na precis√£o) e ROUGE (foco no recall), demonstrando a import√¢ncia de usar m√∫ltiplas m√©tricas para uma avalia√ß√£o abrangente.

### Conclus√£o

O BLEU √© uma m√©trica valiosa e amplamente utilizada para avaliar modelos de gera√ß√£o de texto, especialmente em cen√°rios de tradu√ß√£o autom√°tica e sistemas RAG [^3]. Sua simplicidade e custo-efetividade o tornam uma ferramenta indispens√°vel para avaliar e comparar diferentes abordagens. No entanto, √© crucial estar ciente de suas limita√ß√µes e considerar outras m√©tricas e avalia√ß√µes humanas para obter uma avalia√ß√£o mais completa e precisa da qualidade da gera√ß√£o de texto.

### Refer√™ncias
[^3]: BLEU (Bilingual Evaluation Understudy) is a precision-based evaluation metric that quantifies the overlap of n-grams between the generated output and the reference text. It calculates precision for different n-gram sizes and applies a brevity penalty to discourage excessively short outputs. BLEU is widely used in machine translation due to its cost-effectiveness, although it needs brevity penalties to avoid inflated scores from short outputs.
<!-- END -->