## ROUGE: Avalia√ß√£o Baseada em Recall para Textos Gerados

### Introdu√ß√£o
Dentro do contexto de *Neural Information Retrieval and RAG with LLMs*, a avalia√ß√£o da qualidade dos textos gerados √© um aspecto crucial. M√©tricas como BLEU [06. RAG Patterns] focam na precis√£o do texto gerado em rela√ß√£o a um texto de refer√™ncia. No entanto, para avaliar o qu√£o bem um texto gerado *cobre* o conte√∫do essencial de um texto de refer√™ncia, empregamos m√©tricas baseadas em *recall*. ROUGE (Recall-Oriented Understudy for Gisting Evaluation) √© uma dessas m√©tricas, oferecendo uma perspectiva complementar √† precis√£o avaliada por BLEU. ROUGE quantifica a sobreposi√ß√£o de palavras entre o texto gerado e o texto de refer√™ncia [^1], sendo particularmente √∫til na avalia√ß√£o de tarefas de sumariza√ß√£o autom√°tica.

**Teorema 1:** *Complementaridade de ROUGE e BLEU*. ROUGE e BLEU avaliam diferentes aspectos da qualidade do texto gerado; enquanto BLEU avalia a precis√£o, ROUGE avalia a cobertura. Portanto, a combina√ß√£o de ambas as m√©tricas fornece uma avalia√ß√£o mais abrangente.

*Prova (Esbo√ßo):* A prova reside na defini√ß√£o das m√©tricas. BLEU penaliza a gera√ß√£o de palavras n√£o presentes na refer√™ncia, focando na fidelidade. ROUGE recompensa a inclus√£o de informa√ß√µes relevantes da refer√™ncia no texto gerado, medindo a cobertura. A otimiza√ß√£o de ambas as m√©tricas leva a textos precisos e completos. $\blacksquare$

### Conceitos Fundamentais
ROUGE √© uma fam√≠lia de m√©tricas, cada uma com um foco ligeiramente diferente na sobreposi√ß√£o de palavras. As varia√ß√µes mais comuns s√£o:

*   **ROUGE-N:** Mede a sobreposi√ß√£o de *n-gramas* (sequ√™ncias de *n* palavras) entre o texto gerado e o texto de refer√™ncia. Por exemplo, ROUGE-1 avalia a sobreposi√ß√£o de unigramas, ROUGE-2 avalia a sobreposi√ß√£o de bigramas, e assim por diante. O *recall* ROUGE-N √© calculado como:

    $$
    ROUGE-N = \frac{\sum_{S \in \{\text{reference summaries}\}} \sum_{gram_n \in S} \text{Count}_{\text{match}}(gram_n)}{\sum_{S \in \{\text{reference summaries}\}} \sum_{gram_n \in S} \text{Count}(gram_n)}
    $$

    Onde:
    *   $N$ √© o tamanho do *n-gram*.
    *   $\text{Count}_{\text{match}}(gram_n)$ √© o n√∫mero de *n-gramas* coincidentes entre o texto gerado e o texto de refer√™ncia.
    *   $\text{Count}(gram_n)$ √© o n√∫mero total de *n-gramas* no texto de refer√™ncia.

    > üí° **Exemplo Num√©rico:**
    >
    > Considere o seguinte texto de refer√™ncia e texto gerado:
    >
    > *   Texto de Refer√™ncia: "The cat sat on the mat."
    > *   Texto Gerado: "The cat sat on mat."
    >
    > Para calcular ROUGE-1:
    >
    > *   Unigramas no texto de refer√™ncia: `['the', 'cat', 'sat', 'on', 'the', 'mat']`
    > *   Unigramas coincidentes: `['the', 'cat', 'sat', 'on', 'mat']`
    > *   $\text{Count}_{\text{match}}(gram_1) = 5$
    > *   $\text{Count}(gram_1) = 6$
    > *   $ROUGE-1 = \frac{5}{6} \approx 0.833$
    >
    > Este resultado indica que o texto gerado cobre aproximadamente 83.3% dos unigramas presentes no texto de refer√™ncia.
    >
    > Para calcular ROUGE-2:
    > *   Bigramas no texto de refer√™ncia: `['the cat', 'cat sat', 'sat on', 'on the', 'the mat']`
    > *   Bigramas coincidentes: `['the cat', 'cat sat', 'sat on']`
    > *   $\text{Count}_{\text{match}}(gram_2) = 3$
    > *   $\text{Count}(gram_2) = 5$
    > *   $ROUGE-2 = \frac{3}{5} = 0.6$
    >
    > O ROUGE-2 score de 0.6 sugere que 60% dos bigramas no texto de refer√™ncia est√£o presentes no texto gerado, indicando uma cobertura razo√°vel de sequ√™ncias de duas palavras.

*   **ROUGE-L:** Baseia-se na maior subsequ√™ncia comum (Longest Common Subsequence - LCS) entre o texto gerado e o texto de refer√™ncia. O LCS considera a ordem das palavras, mas n√£o exige que as palavras sejam consecutivas. Isso √© √∫til para capturar a similaridade entre textos, mesmo quando h√° inser√ß√µes ou exclus√µes.

    Seja $X$ o texto gerado e $Y$ o texto de refer√™ncia. Seja $LCS(X, Y)$ a maior subsequ√™ncia comum entre $X$ e $Y$. O *recall* ROUGE-L √© calculado como:

    $$
    R_{lcs} = \frac{\text{length}(LCS(X, Y))}{\text{length}(Y)}
    $$

    A precis√£o ROUGE-L √©:

    $$
    P_{lcs} = \frac{\text{length}(LCS(X, Y))}{\text{length}(X)}
    $$

    E a pontua√ß√£o F √© calculada como a m√©dia harm√¥nica de $R_{lcs}$ e $P_{lcs}$:

    $$
    F_{lcs} = \frac{(1 + \beta^2)R_{lcs}P_{lcs}}{R_{lcs} + \beta^2P_{lcs}}
    $$

    Onde $\beta$ geralmente √© definido para dar igual import√¢ncia a *recall* e precis√£o.

    **Proposi√ß√£o 1:** A pontua√ß√£o $F_{lcs}$ √© maximizada quando a precis√£o e o recall s√£o iguais.

    *Prova:* Para maximizar $F_{lcs}$, podemos tomar a derivada em rela√ß√£o a $R_{lcs}$ e $P_{lcs}$ e igualar a zero. Ou, de forma mais simples, observar que a m√©dia harm√¥nica atinge seu valor m√°ximo quando os termos s√£o iguais. Portanto, a pontua√ß√£o F √© maximizada quando $R_{lcs} = P_{lcs}$. $\blacksquare$

    > üí° **Exemplo Num√©rico:**
    >
    > *   Texto de Refer√™ncia (Y): "The quick brown fox jumps over the lazy dog." (9 palavras)
    > *   Texto Gerado (X): "The brown fox jumps over the dog." (7 palavras)
    >
    > A maior subsequ√™ncia comum (LCS) √© "The brown fox jumps over the dog." (7 palavras)
    >
    > *   $\text{length}(LCS(X, Y)) = 7$
    > *   $\text{length}(Y) = 9$
    > *   $\text{length}(X) = 7$
    >
    > *Recall*: $R_{lcs} = \frac{7}{9} \approx 0.778$
    > *Precis√£o*: $P_{lcs} = \frac{7}{7} = 1.0$
    >
    > Assumindo $\beta = 1$ (igual import√¢ncia para recall e precis√£o):
    >
    > $F_{lcs} = \frac{(1 + 1^2) \times 0.778 \times 1.0}{0.778 + 1^2 \times 1.0} = \frac{2 \times 0.778}{1.778} \approx 0.875$
    >
    > Neste exemplo, o ROUGE-L F-score √© 0.875, refletindo a alta similaridade sequencial entre os textos. A precis√£o √© perfeita porque cada palavra no texto gerado est√° presente e na ordem correta dentro do texto de refer√™ncia.

*   **ROUGE-W:** Uma extens√£o do ROUGE-L que tamb√©m considera o peso de cada subsequ√™ncia comum. Isso significa que subsequ√™ncias mais longas recebem maior import√¢ncia, o que pode ser √∫til para penalizar textos gerados que apenas capturam pequenas partes do texto de refer√™ncia.

*   **ROUGE-S:** Tamb√©m conhecida como *Skip-Bigram Co-Occurrence Statistics*. ROUGE-S mede a sobreposi√ß√£o de pares de palavras, permitindo lacunas arbitr√°rias entre as palavras. Isso torna a m√©trica mais robusta a varia√ß√µes na ordem das palavras.

### Aplica√ß√µes e Interpreta√ß√µes
ROUGE √© amplamente utilizada para avaliar sistemas de sumariza√ß√£o autom√°tica, tradu√ß√£o autom√°tica e gera√ß√£o de texto em geral. Ao contr√°rio de BLEU, que penaliza a omiss√£o de palavras presentes no texto de refer√™ncia, ROUGE recompensa a cobertura do conte√∫do essencial.

*   **ROUGE-1 e ROUGE-2:** S√£o frequentemente usadas para avaliar a qualidade geral da sumariza√ß√£o. ROUGE-1 captura a sobreposi√ß√£o b√°sica de palavras, enquanto ROUGE-2 avalia a flu√™ncia e a coes√£o local.
*   **ROUGE-L:** √â √∫til para avaliar a capacidade de um sistema de capturar as rela√ß√µes sem√¢nticas de longo alcance no texto.
*   **ROUGE-S:** √â particularmente √∫til em cen√°rios onde a ordem das palavras pode variar significativamente.

A escolha da m√©trica ROUGE apropriada depende da tarefa espec√≠fica e das caracter√≠sticas dos textos a serem avaliados. Em geral, √© recomend√°vel usar uma combina√ß√£o de diferentes m√©tricas ROUGE para obter uma avalia√ß√£o mais completa.

**Teorema 2:** *Rela√ß√£o entre ROUGE-N e ROUGE-1*. Se um texto gerado tem um alto escore ROUGE-N para um N grande, ent√£o ele tamb√©m ter√° um alto escore ROUGE-1.

*Prova (Esbo√ßo):* Um alto escore ROUGE-N implica que longas sequ√™ncias de palavras do texto de refer√™ncia est√£o presentes no texto gerado. Consequentemente, cada palavra individual (unigrama) dessas sequ√™ncias tamb√©m estar√° presente, resultando em um alto escore ROUGE-1. No entanto, o inverso n√£o √© necessariamente verdadeiro. Um alto ROUGE-1 n√£o garante um alto ROUGE-N, pois as palavras individuais podem estar presentes sem formar sequ√™ncias significativas. $\blacksquare$

### Vantagens e Desvantagens
**Vantagens:**

*   Simplicidade: F√°cil de entender e implementar.
*   Boa Correla√ß√£o: Geralmente apresenta boa correla√ß√£o com avalia√ß√µes humanas, especialmente para tarefas de sumariza√ß√£o.
*   Foco no *Recall*: Complementa m√©tricas baseadas em precis√£o, fornecendo uma vis√£o mais completa da qualidade do texto gerado.

**Desvantagens:**

*   Superficialidade: Baseia-se apenas na sobreposi√ß√£o de palavras, ignorando aspectos como gramaticalidade, coer√™ncia e relev√¢ncia.
*   Limita√ß√µes em Dom√≠nios Espec√≠ficos: Pode n√£o ser adequada para avaliar textos em dom√≠nios altamente especializados, onde o vocabul√°rio √© restrito e a sem√¢ntica √© complexa.
*   Sensibilidade a Pr√©-Processamento: Os resultados podem ser afetados por etapas de pr√©-processamento como stemming e remo√ß√£o de *stop words*.

**Lema 1:** *Impacto do Stemming em ROUGE*. A aplica√ß√£o de stemming pode aumentar os escores ROUGE, ao agrupar diferentes formas da mesma palavra.

*Prova (Esbo√ßo):* Stemming reduz as palavras √† sua raiz. Por exemplo, "running", "runs" e "run" s√£o reduzidos a "run". Isso aumenta a chance de encontrar correspond√™ncias entre o texto gerado e o texto de refer√™ncia, resultando em escores ROUGE mais altos. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Considere o seguinte cen√°rio:
>
> *   Texto de Refer√™ncia: "The player is running quickly."
> *   Texto Gerado: "The player runs fast."
>
> Sem stemming:
>
> *   Unigramas de Refer√™ncia: `['the', 'player', 'is', 'running', 'quickly']`
> *   Unigramas Gerados: `['the', 'player', 'runs', 'fast']`
> *   Unigramas Coincidentes: `['the', 'player']`
> *   $ROUGE-1 = \frac{2}{5} = 0.4$
>
> Com stemming (usando um stemmer simplificado que mapeia 'running' para 'run'):
>
> *   Unigramas de Refer√™ncia (ap√≥s stemming): `['the', 'player', 'is', 'run', 'quickly']`
> *   Unigramas Gerados (ap√≥s stemming): `['the', 'player', 'run', 'fast']`
> *   Unigramas Coincidentes: `['the', 'player', 'run']`
> *   $ROUGE-1 = \frac{3}{5} = 0.6$
>
> Este exemplo ilustra como o stemming pode aumentar o ROUGE-1, identificando "running" e "runs" como a mesma palavra raiz ("run"). Note que a qualidade da sumariza√ß√£o em si n√£o mudou, apenas a forma como a m√©trica a avalia.

### Conclus√£o
ROUGE √© uma m√©trica valiosa para avaliar a cobertura e a similaridade entre textos gerados e textos de refer√™ncia. Ao complementar m√©tricas como BLEU, ROUGE oferece uma perspectiva mais abrangente da qualidade do texto, especialmente em tarefas de sumariza√ß√£o autom√°tica. A escolha da m√©trica ROUGE apropriada deve considerar as caracter√≠sticas espec√≠ficas da tarefa e dos dados a serem avaliados.

### Refer√™ncias
[^1]: Recall-Oriented Understudy for Gisting Evaluation (ROUGE) quantifies the word overlap between the generated output and the reference text.
<!-- END -->