## BERTScore: Avalia√ß√£o Sem√¢ntica Profunda em RAG

### Introdu√ß√£o

A avalia√ß√£o da performance de sistemas de Retrieval-Augmented Generation (RAG) e modelos de linguagem grandes (LLMs) √© crucial para garantir a qualidade e relev√¢ncia das respostas geradas. M√©tricas tradicionais como precis√£o e recall podem n√£o capturar nuances sem√¢nticas e varia√ß√µes de linguagem. Nesse contexto, o BERTScore emerge como uma alternativa poderosa, oferecendo uma avalia√ß√£o baseada em embeddings que leva em considera√ß√£o a similaridade sem√¢ntica entre o texto gerado e o texto de refer√™ncia. Este cap√≠tulo explorar√° em detalhes o BERTScore, suas componentes, aplica√ß√µes e vantagens na avalia√ß√£o de sistemas RAG.

### Conceitos Fundamentais

O BERTScore √© uma m√©trica de avalia√ß√£o baseada em embeddings que utiliza a similaridade do cosseno para comparar tokens ou n-grams no output gerado com a senten√ßa de refer√™ncia [^5]. Diferentemente de m√©tricas baseadas em sobreposi√ß√£o de tokens, como BLEU ou ROUGE, o BERTScore captura similaridades sem√¢nticas e parafraseamento, tornando-o particularmente √∫til em tarefas onde o significado √© mais importante do que a correspond√™ncia literal.

**Arquitetura e Funcionamento:**

1.  **Embeddings Contextualizados:** O BERTScore utiliza modelos de linguagem pr√©-treinados, como BERT, para gerar embeddings contextualizados para cada token nas senten√ßas gerada e de refer√™ncia. Isso significa que o embedding de um token √© influenciado pelo contexto em que ele aparece, capturando melhor o seu significado.

2.  **Similaridade do Cosseno:** Para cada token na senten√ßa gerada, o BERTScore encontra o token mais similar na senten√ßa de refer√™ncia, com base na similaridade do cosseno entre seus embeddings. A similaridade do cosseno √© definida como:

    $$
    \text{cosine\_similarity}(u, v) = \frac{u \cdot v}{\|u\| \|v\|}
    $$

    onde $u$ e $v$ s√£o os vetores de embedding dos tokens.

    > üí° **Exemplo Num√©rico:**
    >
    > Suponha que o embedding do token "capital" na senten√ßa gerada seja $u = [0.2, 0.3, 0.5]$ e o embedding do token "capital" na senten√ßa de refer√™ncia seja $v = [0.1, 0.4, 0.6]$.  Ent√£o a similaridade do cosseno √©:
    >
    > $\text{cosine\_similarity}(u, v) = \frac{(0.2 \cdot 0.1) + (0.3 \cdot 0.4) + (0.5 \cdot 0.6)}{\sqrt{0.2^2 + 0.3^2 + 0.5^2} \cdot \sqrt{0.1^2 + 0.4^2 + 0.6^2}} = \frac{0.02 + 0.12 + 0.3}{\sqrt{0.38} \cdot \sqrt{0.53}} = \frac{0.44}{\sqrt{0.2014}} \approx \frac{0.44}{0.448} \approx 0.982$
    >
    > Uma similaridade de cosseno pr√≥xima de 1 indica que os tokens s√£o semanticamente muito similares.

3.  **Recall, Precis√£o e F1-Score:** O BERTScore calcula m√©tricas de recall, precis√£o e F1-score baseadas nas similaridades encontradas.

    *   *Precis√£o (P)*: Mede a propor√ß√£o de tokens na senten√ßa gerada que t√™m um correspondente semanticamente similar na senten√ßa de refer√™ncia. Formalmente,

        $$
        P = \frac{1}{|y|} \sum_{y_i \in y} \max_{x_j \in x} \text{cosine\_similarity}(y_i, x_j)
        $$

        onde $x$ √© a senten√ßa de refer√™ncia e $y$ √© a senten√ßa gerada.

        > üí° **Exemplo Num√©rico:**
        >
        > Seja a senten√ßa de refer√™ncia $x$ = "The cat sat" e a senten√ßa gerada $y$ = "A feline sat". Suponha as seguintes similaridades de cosseno m√°ximas entre os tokens de $y$ e $x$:
        >
        > *   "A" (y) com "The" (x): 0.6
        > *   "feline" (y) com "cat" (x): 0.8
        > *   "sat" (y) com "sat" (x): 1.0
        >
        > Ent√£o, a precis√£o √©: $P = \frac{0.6 + 0.8 + 1.0}{3} = \frac{2.4}{3} = 0.8$
        >
        > Isso significa que, em m√©dia, os tokens na senten√ßa gerada s√£o 80% similares aos tokens na senten√ßa de refer√™ncia.

    *   *Recall (R)*: Mede a propor√ß√£o de tokens na senten√ßa de refer√™ncia que t√™m um correspondente semanticamente similar na senten√ßa gerada. Formalmente,

        $$
        R = \frac{1}{|x|} \sum_{x_i \in x} \max_{y_j \in y} \text{cosine\_similarity}(x_i, y_j)
        $$

        onde $x$ √© a senten√ßa de refer√™ncia e $y$ √© a senten√ßa gerada.

        > üí° **Exemplo Num√©rico:**
        >
        > Usando o mesmo exemplo, $x$ = "The cat sat" e $y$ = "A feline sat", suponha as seguintes similaridades de cosseno m√°ximas entre os tokens de $x$ e $y$:
        >
        > *   "The" (x) com "A" (y): 0.6
        > *   "cat" (x) com "feline" (y): 0.8
        > *   "sat" (x) com "sat" (y): 1.0
        >
        > Ent√£o, o recall √©: $R = \frac{0.6 + 0.8 + 1.0}{3} = \frac{2.4}{3} = 0.8$
        >
        > Isso significa que, em m√©dia, os tokens na senten√ßa de refer√™ncia s√£o 80% similares aos tokens na senten√ßa gerada.

    *   *F1-Score (F1)*: √â a m√©dia harm√¥nica entre precis√£o e recall, oferecendo um balan√ßo entre as duas m√©tricas. Formalmente,

        $$
        F_1 = 2 \cdot \frac{P \cdot R}{P + R}
        $$

        > üí° **Exemplo Num√©rico:**
        >
        > Usando os valores de precis√£o e recall calculados anteriormente (P = 0.8 e R = 0.8), o F1-score √©:
        >
        > $F_1 = 2 \cdot \frac{0.8 \cdot 0.8}{0.8 + 0.8} = 2 \cdot \frac{0.64}{1.6} = 2 \cdot 0.4 = 0.8$
        >
        > Neste caso, como a precis√£o e o recall s√£o iguais, o F1-score tamb√©m √© 0.8.

    **Teorema 1:** *O F1-Score √© sempre menor ou igual ao m√°ximo entre a Precis√£o e o Recall, e maior ou igual ao m√≠nimo entre a Precis√£o e o Recall.*

    *Prova:* Seja $P$ a precis√£o e $R$ o recall. Queremos mostrar que $\min(P, R) \leq F_1 \leq \max(P, R)$. Sem perda de generalidade, assuma $P \leq R$. Ent√£o, $\min(P, R) = P$ e $\max(P, R) = R$.

    $F_1 = \frac{2PR}{P + R}$.  Como $P \leq R$, $P + R \leq 2R$. Portanto, $F_1 = \frac{2PR}{P + R} \geq \frac{2PR}{2R} = P$.

    Similarmente, como $P \leq R$, $P + R \geq 2P$. Portanto, $F_1 = \frac{2PR}{P + R} \leq \frac{2PR}{2P} = R$.

    Assim, $P \leq F_1 \leq R$, o que implica $\min(P, R) \leq F_1 \leq \max(P, R)$.

**Vantagens do BERTScore:**

*   **Captura de Sem√¢ntica:** Ao utilizar embeddings contextualizados, o BERTScore captura similaridades sem√¢nticas que m√©tricas baseadas em sobreposi√ß√£o de tokens ignoram.

*   **Robustez ao Parafraseamento:** O BERTScore √© menos sens√≠vel a varia√ß√µes na escolha de palavras e estrutura das frases, desde que o significado seja preservado.

*   **Aplicabilidade:** √â √∫til em tarefas como image captioning e machine translation, onde a sem√¢ntica √© fundamental [^5].

**Limita√ß√µes do BERTScore:**

*   **Depend√™ncia de Modelos Pr√©-Treinados:** O desempenho do BERTScore depende da qualidade do modelo de linguagem pr√©-treinado utilizado. Modelos inadequados para o dom√≠nio espec√≠fico podem levar a avalia√ß√µes imprecisas.

*   **Custo Computacional:** A gera√ß√£o de embeddings contextualizados pode ser computacionalmente intensiva, especialmente para textos longos.

Al√©m dessas limita√ß√µes, √© importante notar que o BERTScore, assim como outras m√©tricas de avalia√ß√£o autom√°tica, pode n√£o capturar completamente a qualidade subjetiva de um texto. Fatores como flu√™ncia, coer√™ncia e relev√¢ncia contextual podem ser subestimados ou negligenciados. Portanto, √© recomend√°vel combinar o BERTScore com outras formas de avalia√ß√£o, incluindo a avalia√ß√£o humana, para obter uma vis√£o mais completa e precisa da performance do sistema.

### Aplica√ß√µes em Sistemas RAG

Em sistemas RAG, o BERTScore pode ser utilizado para avaliar tanto a qualidade do retrieval quanto a qualidade da gera√ß√£o.

*   **Avalia√ß√£o do Retrieval:** Comparar o conte√∫do recuperado com a consulta original para avaliar a relev√¢ncia do retrieval.

*   **Avalia√ß√£o da Gera√ß√£o:** Comparar a resposta gerada com o texto de refer√™ncia ou com o contexto recuperado para avaliar a qualidade da gera√ß√£o. Isso pode ser especialmente √∫til para garantir que a resposta gerada seja coerente com o contexto e semanticamente precisa.

    > üí° **Exemplo Num√©rico:**
    >
    > Considere um sistema RAG que recebe a consulta: "Quais s√£o os benef√≠cios do exerc√≠cio f√≠sico?" e recupera os seguintes documentos:
    >
    > *   Documento 1: "O exerc√≠cio f√≠sico regular melhora a sa√∫de cardiovascular e reduz o risco de doen√ßas card√≠acas."
    > *   Documento 2: "A pr√°tica de atividades f√≠sicas contribui para o controle do peso e o fortalecimento muscular."
    >
    > O sistema gera a seguinte resposta: "Exerc√≠cios f√≠sicos fazem bem para o cora√ß√£o e ajudam a controlar o peso."
    >
    > Para avaliar a gera√ß√£o, o BERTScore pode comparar a resposta gerada com os documentos recuperados. Podemos calcular o BERTScore entre a resposta e cada documento separadamente e, em seguida, combinar os resultados (por exemplo, calculando a m√©dia). Um BERTScore alto indicaria que a resposta √© semanticamente similar aos documentos recuperados, o que sugere uma boa qualidade da gera√ß√£o.
    >
    > Suponha que o BERTScore entre a resposta e o Documento 1 seja 0.85 e entre a resposta e o Documento 2 seja 0.90. A m√©dia dos BERTScore seria (0.85 + 0.90) / 2 = 0.875.
    >
    > Isso sugere que a resposta gerada pelo sistema RAG √© altamente relevante e coerente com o contexto fornecido pelos documentos recuperados.

Para refinar ainda mais a avalia√ß√£o da gera√ß√£o, podemos ponderar o BERTScore com base na import√¢ncia dos diferentes trechos do contexto recuperado. Por exemplo, se um trecho espec√≠fico do contexto √© mais relevante para a resposta, podemos atribuir um peso maior ao BERTScore calculado em rela√ß√£o a esse trecho. Isso permite uma avalia√ß√£o mais granular e sens√≠vel ao contexto, melhorando a precis√£o da m√©trica.

### Exemplo Pr√°tico

Considere um sistema RAG que recebe a consulta "Qual √© a capital da Fran√ßa?" e recupera o seguinte contexto: "Paris √© a capital e a cidade mais populosa da Fran√ßa." O sistema gera a resposta: "A capital da Fran√ßa √© Paris."

Nesse caso, o BERTScore compararia a resposta gerada com o contexto recuperado ou com uma senten√ßa de refer√™ncia ("Paris √© a capital da Fran√ßa."). A alta similaridade sem√¢ntica entre a resposta e a refer√™ncia resultaria em um alto BERTScore, indicando uma boa performance do sistema RAG.

Al√©m disso, podemos utilizar o BERTScore para avaliar a diversidade das respostas geradas por um sistema RAG. Ao comparar as respostas geradas para consultas semelhantes, podemos verificar se o sistema est√° explorando diferentes aspectos do conhecimento ou se est√° repetindo as mesmas informa√ß√µes. Uma alta diversidade nas respostas pode indicar uma melhor capacidade do sistema de lidar com diferentes nuances e perspectivas.

> üí° **Exemplo Num√©rico:**
>
> Suponha que para a consulta "Quais s√£o os tipos de energia renov√°vel?" um sistema RAG gere duas respostas diferentes em duas execu√ß√µes:
>
> *   Resposta 1: "Energia solar e energia e√≥lica s√£o tipos de energia renov√°vel."
> *   Resposta 2: "Fontes renov√°veis incluem a energia hidrel√©trica e a energia geot√©rmica."
>
> Para medir a diversidade, podemos calcular o BERTScore entre as duas respostas. Um BERTScore baixo indicaria que as respostas s√£o semanticamente diferentes e, portanto, o sistema est√° gerando respostas diversas. Por outro lado, um BERTScore alto indicaria que as respostas s√£o semelhantes, o que pode ser um sinal de falta de diversidade.
>
> Se o BERTScore entre as Respostas 1 e 2 for 0.6, isso sugere uma diversidade razo√°vel, pois as respostas abordam diferentes tipos de energia renov√°vel. Se o BERTScore fosse 0.9, indicaria que as duas respostas s√£o muito parecidas, e o sistema pode n√£o estar explorando diferentes aspectos da consulta.



![Illustration contrasting BERTScore's one-to-one alignment with MoverScore's many-to-one mapping of semantically related words.](./../images/image12.jpg)

### Conclus√£o

O BERTScore oferece uma abordagem avan√ßada e sens√≠vel √† sem√¢ntica para avaliar a performance de sistemas RAG e LLMs. Sua capacidade de capturar similaridades sem√¢nticas e robustez ao parafraseamento o tornam uma ferramenta valiosa em tarefas onde o significado √© crucial. Apesar de suas limita√ß√µes, o BERTScore representa um avan√ßo significativo em rela√ß√£o √†s m√©tricas tradicionais de avalia√ß√£o, permitindo uma avalia√ß√£o mais precisa e abrangente da qualidade dos sistemas de gera√ß√£o de texto.

### Refer√™ncias

[^5]: BERTScore is an embedding-based evaluation metric that uses cosine similarity to compare tokens or n-grams in the generated output with the reference sentence. It captures semantic similarities and paraphrasing by incorporating recall, precision, and F1-score components. BERTScore is useful in tasks such as image captioning and machine translation, where semantics are crucial.
<!-- END -->