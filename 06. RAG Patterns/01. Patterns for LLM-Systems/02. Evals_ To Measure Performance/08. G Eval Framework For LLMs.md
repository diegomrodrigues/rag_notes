## G-Eval: Avalia√ß√£o de Coer√™ncia em LLMs com Chain-of-Thought

### Introdu√ß√£o
Este cap√≠tulo explora o G-Eval, um framework inovador para avaliar o desempenho de Large Language Models (LLMs) [^8]. Em particular, focaremos na sua aplica√ß√£o na avalia√ß√£o de **coer√™ncia** em tarefas como sumariza√ß√£o de not√≠cias. O G-Eval utiliza a t√©cnica de **Chain-of-Thought (CoT)** e um formato estruturado para fornecer uma avalia√ß√£o detalhada e quantific√°vel, aproveitando a capacidade dos pr√≥prios LLMs para realizar a avalia√ß√£o.

### Conceitos Fundamentais

O G-Eval se distingue por empregar o pr√≥prio LLM para gerar os passos de avalia√ß√£o e, crucialmente, para atribuir uma pontua√ß√£o normalizada baseada nas probabilidades dos *tokens* de sa√≠da [^8]. Este processo elimina a necessidade de avaliadores humanos ou de m√©tricas automatizadas predefinidas, permitindo uma avalia√ß√£o mais flex√≠vel e adapt√°vel.

A espinha dorsal do G-Eval reside na aplica√ß√£o da t√©cnica Chain-of-Thought (CoT). Essencialmente, o CoT instrui o LLM a decompor o processo de avalia√ß√£o em etapas l√≥gicas e sequenciais [^8]. Estas etapas refletem o racioc√≠nio subjacente √† avalia√ß√£o e fornecem transpar√™ncia no processo de tomada de decis√£o do LLM.

![G-Eval framework using LLMs with chain-of-thought for automated NLG evaluation.](./../images/image6.jpg)

O fluxo de trabalho do G-Eval para avaliar coer√™ncia √© o seguinte [^8]:

1.  **Prompt Inicial:** O LLM √© apresentado com um *prompt* que introduz a tarefa de avalia√ß√£o e define os crit√©rios de avalia√ß√£o da coer√™ncia. Por exemplo, o *prompt* pode especificar que a coer√™ncia implica que o resumo reflita fielmente os principais pontos do artigo original, sem introduzir informa√ß√µes novas ou contradit√≥rias.

2.  **Gera√ß√£o de CoT:** O LLM √© solicitado a gerar uma cadeia de pensamento (CoT) de etapas de avalia√ß√£o. Cada etapa na CoT representa um passo no racioc√≠nio do LLM ao avaliar a coer√™ncia. Por exemplo, uma etapa pode ser "Identificar o tema principal do artigo de not√≠cias" e outra pode ser "Verificar se o resumo captura com precis√£o esse tema principal".

3.  **Concatena√ß√£o e Pontua√ß√£o:** O *prompt* inicial, a CoT gerada, o artigo de not√≠cias original e o resumo a ser avaliado s√£o concatenados em uma √∫nica entrada. Esta entrada concatenada √© ent√£o alimentada ao LLM, que √© solicitado a fornecer uma pontua√ß√£o de coer√™ncia.

4.  **Normaliza√ß√£o da Pontua√ß√£o:** A pontua√ß√£o de coer√™ncia √© derivada das probabilidades dos *tokens* de sa√≠da do LLM. Especificamente, o G-Eval utiliza as probabilidades dos *tokens* para derivar uma pontua√ß√£o normalizada. Este passo √© crucial para garantir que as pontua√ß√µes sejam compar√°veis entre diferentes artigos de not√≠cias e resumos, e para mitigar o impacto da aleatoriedade inerente na gera√ß√£o de texto do LLM.

> üí° **Exemplo Num√©rico:**
>
> Vamos supor que, ap√≥s a concatena√ß√£o e a apresenta√ß√£o ao LLM, este gera as seguintes probabilidades para os *tokens* de pontua√ß√£o:
>
> | Token | Probabilidade | Valor |
> |-------|----------------|-------|
> | "1"   | 0.01           | 1     |
> | "2"   | 0.02           | 2     |
> | "3"   | 0.05           | 3     |
> | "4"   | 0.10           | 4     |
> | "5"   | 0.20           | 5     |
> | "6"   | 0.30           | 6     |
> | "7"   | 0.20           | 7     |
> | "8"   | 0.10           | 8     |
> | "9"   | 0.02           | 9     |
> | "10"  | 0.00           | 10    |
>
> Aqui, $S = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$.  Aplicando a f√≥rmula de normaliza√ß√£o:
>
> $score_{normalizado} = \frac{(0.01 \cdot 1) + (0.02 \cdot 2) + (0.05 \cdot 3) + (0.10 \cdot 4) + (0.20 \cdot 5) + (0.30 \cdot 6) + (0.20 \cdot 7) + (0.10 \cdot 8) + (0.02 \cdot 9) + (0.00 \cdot 10)}{0.01 + 0.02 + 0.05 + 0.10 + 0.20 + 0.30 + 0.20 + 0.10 + 0.02 + 0.00}$
>
> $score_{normalizado} = \frac{0.01 + 0.04 + 0.15 + 0.40 + 1.00 + 1.80 + 1.40 + 0.80 + 0.18 + 0.00}{1.00} = \frac{5.78}{1.00} = 5.78$
>
> Portanto, a pontua√ß√£o de coer√™ncia normalizada para este resumo √© 5.78.  Este valor est√° dentro do intervalo esperado de 1 a 10, conforme o Corol√°rio 1.1.  A distribui√ß√£o de probabilidade sugere que o LLM considera o resumo como razoavelmente coerente, pendendo ligeiramente para o lado mais alto da escala.

**Formaliza√ß√£o Matem√°tica da Normaliza√ß√£o:**

Seja $p(t_i)$ a probabilidade do *token* $t_i$ de sa√≠da do LLM, e seja $S$ o conjunto de *tokens* que representam as poss√≠veis pontua√ß√µes (por exemplo, "1", "2", ..., "10"). A pontua√ß√£o normalizada $score_{normalizado}$ pode ser calculada da seguinte forma:

$$
score_{normalizado} = \frac{\sum_{t_i \in S} p(t_i) \cdot valor(t_i)}{\sum_{t_i \in S} p(t_i)}
$$

Onde $valor(t_i)$ representa o valor num√©rico associado ao *token* $t_i$. Se $S = \{1, 2, \ldots, 10\}$, ent√£o $valor(1) = 1$, $valor(2) = 2$, e assim por diante.

Essa f√≥rmula calcula uma m√©dia ponderada das poss√≠veis pontua√ß√µes, onde os pesos s√£o as probabilidades associadas a cada pontua√ß√£o. A divis√£o pela soma das probabilidades garante que a pontua√ß√£o seja normalizada entre 0 e o valor m√°ximo do intervalo de pontua√ß√µes.

**Teorema 1:** A pontua√ß√£o normalizada $score_{normalizado}$ reside sempre no intervalo $[min(valor(t_i)), max(valor(t_i))]$ para $t_i \in S$.

**Demonstra√ß√£o:** Seja $min_S = min(valor(t_i))$ e $max_S = max(valor(t_i))$ para $t_i \in S$. Ent√£o, $min_S \leq valor(t_i) \leq max_S$ para todo $t_i \in S$. Multiplicando por $p(t_i)$ (que √© n√£o-negativo) e somando sobre todos os $t_i \in S$, obtemos:

$$
\sum_{t_i \in S} p(t_i) \cdot min_S \leq \sum_{t_i \in S} p(t_i) \cdot valor(t_i) \leq \sum_{t_i \in S} p(t_i) \cdot max_S
$$

$$
min_S \cdot \sum_{t_i \in S} p(t_i) \leq \sum_{t_i \in S} p(t_i) \cdot valor(t_i) \leq max_S \cdot \sum_{t_i \in S} p(t_i)
$$

Dividindo por $\sum_{t_i \in S} p(t_i)$ (que √© positivo), obtemos:

$$
min_S \leq \frac{\sum_{t_i \in S} p(t_i) \cdot valor(t_i)}{\sum_{t_i \in S} p(t_i)} \leq max_S
$$

Portanto, $min_S \leq score_{normalizado} \leq max_S$. $\blacksquare$

**Corol√°rio 1.1:** Se $S = \{1, 2, \ldots, n\}$, ent√£o $1 \leq score_{normalizado} \leq n$.

**Observa√ß√£o:** O Teorema 1 garante que a normaliza√ß√£o produz uma pontua√ß√£o dentro dos limites definidos pelo conjunto de pontua√ß√µes poss√≠veis, fornecendo uma interpreta√ß√£o mais clara do resultado.

> üí° **Exemplo Num√©rico:**
>
> Se $S = \{0, 0.25, 0.5, 0.75, 1\}$, representando uma escala de coer√™ncia de 0 a 1 em incrementos de 0.25, e o LLM gera as seguintes probabilidades:
>
> | Token | Probabilidade | Valor |
> |-------|----------------|-------|
> | "0"   | 0.05           | 0     |
> | "0.25"| 0.10           | 0.25  |
> | "0.5" | 0.30           | 0.5   |
> | "0.75"| 0.40           | 0.75  |
> | "1"   | 0.15           | 1     |
>
> Ent√£o:
>
> $score_{normalizado} = \frac{(0.05 \cdot 0) + (0.10 \cdot 0.25) + (0.30 \cdot 0.5) + (0.40 \cdot 0.75) + (0.15 \cdot 1)}{0.05 + 0.10 + 0.30 + 0.40 + 0.15}$
>
> $score_{normalizado} = \frac{0 + 0.025 + 0.15 + 0.30 + 0.15}{1} = 0.625$
>
> Neste caso, a pontua√ß√£o normalizada √© 0.625, indicando uma coer√™ncia moderada, mais pr√≥xima de 0.75 do que de 0.5.

**Vantagens do G-Eval:**

*   **Automatiza√ß√£o:** Elimina a necessidade de avaliadores humanos, reduzindo custos e tempo.
*   **Adaptabilidade:** Pode ser facilmente adaptado a diferentes tarefas e crit√©rios de avalia√ß√£o.
*   **Transpar√™ncia:** A CoT fornece uma vis√£o detalhada do processo de racioc√≠nio do LLM.
*   **Quantificabilidade:** A pontua√ß√£o normalizada permite uma compara√ß√£o objetiva do desempenho do LLM.

Adicionalmente, para melhorar a robustez da avalia√ß√£o, podemos considerar a introdu√ß√£o de um fator de confian√ßa na pontua√ß√£o, baseado na entropia da distribui√ß√£o de probabilidade dos *tokens* de sa√≠da.

**Teorema 2:** Seja $H$ a entropia da distribui√ß√£o de probabilidade dos *tokens* de sa√≠da $S$, definida como:

$$
H = - \sum_{t_i \in S} p(t_i) \cdot log(p(t_i))
$$

Podemos definir um fator de confian√ßa $C$ como uma fun√ß√£o decrescente da entropia $H$, por exemplo:

$$
C = e^{-H}
$$

Uma pontua√ß√£o de coer√™ncia ajustada pode ser dada por:

$$
score_{ajustado} = C \cdot score_{normalizado}
$$

**Justificativa:** Uma alta entropia indica uma distribui√ß√£o de probabilidade mais uniforme, sugerindo que o LLM est√° menos confiante na sua avalia√ß√£o. Consequentemente, o fator de confian√ßa $C$ ser√° menor, reduzindo a pontua√ß√£o final. Por outro lado, uma baixa entropia indica uma distribui√ß√£o de probabilidade mais concentrada, sugerindo maior confian√ßa, e o fator $C$ ser√° pr√≥ximo de 1, resultando em uma pontua√ß√£o ajustada pr√≥xima da pontua√ß√£o normalizada.

> üí° **Exemplo Num√©rico:**
>
> Usando os dados do primeiro exemplo num√©rico (pontua√ß√µes de 1 a 10), podemos calcular a entropia e o fator de confian√ßa. As probabilidades s√£o: 0.01, 0.02, 0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.02, 0.00.
>
> $H = - (0.01 \cdot log(0.01) + 0.02 \cdot log(0.02) + 0.05 \cdot log(0.05) + 0.10 \cdot log(0.10) + 0.20 \cdot log(0.20) + 0.30 \cdot log(0.30) + 0.20 \cdot log(0.20) + 0.10 \cdot log(0.10) + 0.02 \cdot log(0.02) + 0.00 \cdot log(0.00))$
>
> *Nota:* log aqui representa o logaritmo natural.  Na pr√°tica, deve-se adicionar um pequeno valor a $p(t_i)$ quando for 0 para evitar `log(0)`. Vamos assumir que ap√≥s o c√°lculo (e lidando com o log de 0, que na pr√°tica seria tratado com um pequeno epsilon), obtemos $H \approx 1.82$.
>
> Ent√£o, o fator de confian√ßa seria:
>
> $C = e^{-1.82} \approx 0.162$
>
> A pontua√ß√£o ajustada seria:
>
> $score_{ajustado} = 0.162 \cdot 5.78 \approx 0.936$
>
> Neste caso, a entropia relativamente alta (devido √† distribui√ß√£o das probabilidades) resulta em um fator de confian√ßa baixo, penalizando a pontua√ß√£o original de 5.78 para 0.936. Isso indica que, embora o LLM tenha atribu√≠do uma pontua√ß√£o de 5.78, a distribui√ß√£o de probabilidades sugere incerteza na avalia√ß√£o, levando a uma pontua√ß√£o ajustada mais baixa.

### Conclus√£o

O G-Eval representa um avan√ßo significativo na avalia√ß√£o de LLMs, especialmente na avalia√ß√£o de coer√™ncia. Ao aproveitar o pr√≥prio LLM para gerar os passos de avalia√ß√£o e atribuir pontua√ß√µes normalizadas, o G-Eval oferece uma solu√ß√£o automatizada, adapt√°vel e transparente. A utiliza√ß√£o da t√©cnica Chain-of-Thought (CoT) melhora ainda mais a interpretabilidade do processo de avalia√ß√£o, permitindo uma compreens√£o mais profunda das capacidades e limita√ß√µes dos LLMs. O G-Eval, portanto, oferece um m√©todo promissor para avaliar e melhorar a qualidade dos LLMs em diversas tarefas de gera√ß√£o de texto. A incorpora√ß√£o de um fator de confian√ßa, baseado na entropia da distribui√ß√£o de probabilidade, pode aprimorar ainda mais a robustez e a precis√£o do framework.

### Refer√™ncias
[^8]: G-Eval is a framework for evaluating LLMs that applies the Chain-of-Thought (CoT) technique and a structured form to evaluate coherence in tasks like news summarization. It uses an LLM to generate evaluation steps and assign a normalized score based on the probabilities of the output tokens. It prompts the LLM with an introduction to the task and evaluation criteria and asks for a CoT of evaluation steps. To evaluate coherence, it concatenates the prompt, CoT, news article, and summary, asking the LLM for a score; using the probabilities of the LLM output tokens to derive a normalized score.
<!-- END -->