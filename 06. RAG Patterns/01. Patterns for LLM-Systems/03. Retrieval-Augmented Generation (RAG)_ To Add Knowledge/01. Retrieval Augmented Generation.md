## Retrieval-Augmented Generation (RAG): Uma Abordagem para Adicionar Conhecimento a LLMs

### Introdu√ß√£o

Modelos de linguagem grandes (LLMs) demonstraram capacidades not√°veis em diversas tarefas de processamento de linguagem natural. No entanto, as limita√ß√µes inerentes a esses modelos, como a incapacidade de expandir sua mem√≥ria, a falta de *insights* detalhados sobre o processo de gera√ß√£o e a propens√£o a alucina√ß√µes, motivaram o desenvolvimento de t√©cnicas para mitigar esses problemas. Retrieval-Augmented Generation (RAG) surge como uma solu√ß√£o promissora, permitindo que os LLMs acessem e incorporem conhecimento externo para aprimorar a qualidade e a precis√£o de suas respostas [^1]. Este cap√≠tulo explora em detalhes o conceito de RAG, seus benef√≠cios e a forma como ele supera as desvantagens dos LLMs pr√©-treinados.

### Conceitos Fundamentais

A t√©cnica de **Retrieval-Augmented Generation (RAG)** consiste em aumentar a capacidade de um modelo de linguagem, fornecendo-lhe informa√ß√µes contextuais relevantes obtidas de fontes externas [^1]. Essa abordagem aborda diretamente as limita√ß√µes dos LLMs pr√©-treinados, que s√£o treinados em grandes volumes de dados, mas permanecem est√°ticos ap√≥s o treinamento.

**1. Defici√™ncias dos LLMs Pr√©-Treinados:**

*   **Mem√≥ria Limitada:** LLMs pr√©-treinados possuem um conhecimento limitado ao conjunto de dados utilizado durante o treinamento. Eles n√£o conseguem acessar ou incorporar informa√ß√µes novas ou atualizadas em tempo real [^1].
*   **Falta de *Insights*:** O processo de gera√ß√£o de texto em LLMs √© frequentemente opaco, dificultando a compreens√£o das raz√µes por tr√°s de determinadas escolhas ou resultados [^1].
*   **Alucina√ß√µes:** LLMs podem gerar informa√ß√µes incorretas, inventadas ou inconsistentes com a realidade, um fen√¥meno conhecido como alucina√ß√£o [^1].

**2. Funcionamento do RAG:**

O RAG opera em duas etapas principais:

*   **Retrieval (Recupera√ß√£o):** Dada uma *query* do usu√°rio, o sistema RAG consulta uma base de conhecimento externa (e.g., um banco de dados de documentos, uma *knowledge graph*, ou a pr√≥pria internet) para identificar e recuperar informa√ß√µes relevantes [^1]. T√©cnicas de *information retrieval* (IR) s√£o comumente empregadas nesta etapa.
*   **Augmentation (Aumento):** As informa√ß√µes recuperadas s√£o ent√£o combinadas com a *query* original para criar um *prompt* aumentado. Este *prompt* aumentado √© fornecido ao LLM, que gera uma resposta com base tanto na *query* original quanto no conhecimento externo fornecido [^1].

**3. Benef√≠cios do RAG:**

*   **Conhecimento Atualizado:** RAG permite que os LLMs acessem informa√ß√µes em tempo real, superando a limita√ß√£o de conhecimento est√°tico [^1].
*   **Transpar√™ncia e Explicabilidade:** Ao fornecer as fontes das informa√ß√µes utilizadas, RAG aumenta a transpar√™ncia e a explicabilidade das respostas geradas [^1].
*   **Redu√ß√£o de Alucina√ß√µes:** Ao ancorar as respostas em fontes externas verific√°veis, RAG reduz a probabilidade de alucina√ß√µes [^1].
*   **Personaliza√ß√£o:** RAG permite a personaliza√ß√£o das respostas com base em informa√ß√µes espec√≠ficas do usu√°rio ou do contexto [^1].

**4. Arquitetura Geral de um Sistema RAG:**

Um sistema RAG t√≠pico consiste nos seguintes componentes:

1.  **Indexa√ß√£o:** Processamento e indexa√ß√£o de documentos da base de conhecimento externa para facilitar a recupera√ß√£o eficiente.
2.  **Recupera√ß√£o:** Mecanismo para identificar e recuperar os documentos mais relevantes para uma dada *query*. Isso pode envolver t√©cnicas como *vector search* ou *keyword search*.
3.  **Gera√ß√£o:** Modelo de linguagem que gera a resposta final com base na *query* e nos documentos recuperados.
4.  **P√≥s-Processamento:** Refinamento da resposta gerada, como formata√ß√£o, remo√ß√£o de redund√¢ncias ou corre√ß√£o de erros.

![RAG architecture: Enhancing language models with external knowledge retrieval for improved answer generation.](./../images/image17.jpg)

Para complementar o entendimento da etapa de recupera√ß√£o, podemos detalhar os diferentes tipos de estrat√©gias de recupera√ß√£o existentes:

**5. Estrat√©gias de Recupera√ß√£o:**

Existem diversas estrat√©gias de recupera√ß√£o que podem ser empregadas em um sistema RAG, cada uma com suas vantagens e desvantagens.

*   **Recupera√ß√£o Densa:** Utiliza modelos de *embedding* para representar tanto a *query* quanto os documentos em um espa√ßo vetorial. A similaridade sem√¢ntica entre a *query* e os documentos √© ent√£o calculada (e.g., usando similaridade do cosseno), e os documentos mais similares s√£o recuperados. Essa abordagem √© eficaz para capturar a sem√¢ntica da *query*, mesmo que as palavras exatas n√£o estejam presentes nos documentos.

> üí° **Exemplo Num√©rico:**
> Suponha que temos uma *query*: "Melhor filme de fic√ß√£o cient√≠fica de 2023".  E dois documentos:
>
> Documento 1: "O filme 'Amea√ßa Extraterrestre' lan√ßado em 2023 foi um sucesso de bilheteria."
>
> Documento 2: "Em 2023, 'Jornada nas Estrelas: Nova Gera√ß√£o' recebeu cr√≠ticas mistas."
>
> Ap√≥s aplicar um modelo de *embedding* (ex: Sentence Transformers), obtemos as seguintes representa√ß√µes vetoriais (simplificadas para 2 dimens√µes):
>
> Query: `[0.2, 0.8]`
>
> Documento 1: `[0.3, 0.7]`
>
> Documento 2: `[0.5, 0.5]`
>
> Podemos calcular a similaridade do cosseno entre a query e cada documento:
>
> $$\text{Cosine Similarity (Query, Document 1)} = \frac{(0.2 * 0.3) + (0.8 * 0.7)}{\sqrt{(0.2^2 + 0.8^2)} * \sqrt{(0.3^2 + 0.7^2)}} \approx 0.98$$
>
> $$\text{Cosine Similarity (Query, Document 2)} = \frac{(0.2 * 0.5) + (0.8 * 0.5)}{\sqrt{(0.2^2 + 0.8^2)} * \sqrt{(0.5^2 + 0.5^2)}} \approx 0.89$$
>
> Neste exemplo, o Documento 1 √© considerado mais relevante para a query do que o Documento 2, pois possui uma similaridade de cosseno maior.  Apesar de Documento 2 mencionar "fic√ß√£o cient√≠fica" ("Jornada nas Estrelas"), Documento 1 √© considerado mais relevante por capturar melhor a sem√¢ntica da *query* ("melhor filme de fic√ß√£o cient√≠fica").

*   **Recupera√ß√£o Esparsa:** Baseia-se em m√©todos tradicionais de *information retrieval*, como TF-IDF ou BM25, que contam a frequ√™ncia das palavras na *query* e nos documentos. Essa abordagem √© computacionalmente eficiente, mas pode ser menos eficaz para capturar a sem√¢ntica da *query*.

> üí° **Exemplo Num√©rico:**
>
> Consideremos a query: "gatos siameses".
>
> Documento 1: "gatos siameses s√£o origin√°rios da Tail√¢ndia".
>
> Documento 2: "c√£es s√£o animais de estima√ß√£o populares".
>
> **TF-IDF:**
>
> $$\text{TF(gatos, Documento 1)} = 1$$
> $$\text{TF(siameses, Documento 1)} = 1$$
> $$\text{TF(gatos, Documento 2)} = 0$$
> $$\text{TF(siameses, Documento 2)} = 0$$
>
> Assumindo que temos 100 documentos no total, e "gatos" aparece em 10 documentos e "siameses" em 5:
>
> $$\text{IDF(gatos)} = \log(\frac{100}{10}) = 1$$
> $$\text{IDF(siameses)} = \log(\frac{100}{5}) = 1.3$$
>
> $$\text{TF-IDF(gatos, Documento 1)} = 1 * 1 = 1$$
> $$\text{TF-IDF(siameses, Documento 1)} = 1 * 1.3 = 1.3$$
> $$\text{TF-IDF(gatos, Documento 2)} = 0 * 1 = 0$$
> $$\text{TF-IDF(siameses, Documento 2)} = 0 * 1.3 = 0$$
>
> O score TF-IDF total para Documento 1 √© 1 + 1.3 = 2.3. Para Documento 2 √© 0.  Portanto, Documento 1 seria considerado mais relevante.
>
> **BM25:** BM25 adiciona par√¢metros para ajustar a import√¢ncia da frequ√™ncia dos termos e o tamanho do documento.  Por exemplo, usando $k_1 = 1.2$ e $b = 0.75$, e assumindo que o tamanho m√©dio dos documentos √© de 20 palavras e o Documento 1 tem 15 palavras:
>
> $$BM25(Query, Documento) = \sum_{i=1}^{n} IDF(q_i) * \frac{TF(q_i, Document) * (k_1 + 1)}{TF(q_i, Document) + k_1 * (1 - b + b * \frac{|Document|}{avgdl})}$$
>
> Onde $q_i$ s√£o os termos da query, $|Document|$ √© o tamanho do documento e $avgdl$ √© o tamanho m√©dio dos documentos.
>
> $$\text{BM25(Query, Documento 1)} = 1 * \frac{1 * (1.2 + 1)}{1 + 1.2 * (1 - 0.75 + 0.75 * \frac{15}{20})} + 1.3 * \frac{1 * (1.2 + 1)}{1 + 1.2 * (1 - 0.75 + 0.75 * \frac{15}{20})} \approx 1.92$$
>
> $$\text{BM25(Query, Documento 2)} = 0$$
>
> Mesmo com o BM25, Documento 1 seria considerado mais relevante.

*   **Recupera√ß√£o H√≠brida:** Combina as abordagens densa e esparsa para obter o melhor de ambos os mundos. Por exemplo, pode-se usar a recupera√ß√£o esparsa para filtrar um conjunto inicial de documentos candidatos e, em seguida, usar a recupera√ß√£o densa para refinar a sele√ß√£o.

> üí° **Exemplo Num√©rico:**
>
> Usando os exemplos anteriores, podemos combinar os scores de recupera√ß√£o densa e esparsa.  Digamos que atribu√≠mos pesos de 0.6 para a recupera√ß√£o densa e 0.4 para a recupera√ß√£o esparsa.
>
> | Documento | Recupera√ß√£o Densa (Cosine Similarity) | Recupera√ß√£o Esparsa (TF-IDF) | Score H√≠brido |
> | --------- | --------------------------------------- | --------------------------- | ------------- |
> | 1         | 0.98                                    | 2.3                         | (0.6 * 0.98) + (0.4 * 2.3) = 1.51 |
> | 2         | 0.89                                    | 0                           | (0.6 * 0.89) + (0.4 * 0) = 0.53  |
>
> Neste caso, o Documento 1 ainda √© considerado mais relevante usando a abordagem h√≠brida. A combina√ß√£o permite balancear as vantagens de cada m√©todo: a capacidade da recupera√ß√£o densa de capturar sem√¢ntica e a efici√™ncia da recupera√ß√£o esparsa.

*   **Recupera√ß√£o Baseada em Grafos:** Representa a base de conhecimento como um grafo, onde os n√≥s representam entidades e as arestas representam rela√ß√µes entre elas. A recupera√ß√£o envolve navegar no grafo para encontrar as entidades e rela√ß√µes mais relevantes para a *query*.

Al√©m disso, a escolha da base de conhecimento externa √© crucial para o desempenho de um sistema RAG.

**6. Tipos de Base de Conhecimento:**

A escolha da base de conhecimento externa impacta significativamente a efic√°cia do RAG. As op√ß√µes incluem:

*   **Bancos de Dados de Documentos:** Cole√ß√µes de documentos de texto, como artigos cient√≠ficos, p√°ginas da web ou relat√≥rios.
*   **Knowledge Graphs:** Representa√ß√µes estruturadas do conhecimento, compostas por entidades e rela√ß√µes entre elas. Exemplos incluem Wikidata e DBpedia.
*   **Bancos de Dados Vetoriais:** Armazenam *embeddings* de documentos, permitindo a recupera√ß√£o eficiente baseada em similaridade sem√¢ntica.
*   **A Pr√≥pria Internet:** Utilizar motores de busca para recuperar informa√ß√µes relevantes em tempo real.

A qualidade e a relev√¢ncia da base de conhecimento s√£o fatores determinantes para o sucesso do RAG.

Com base na discuss√£o acima, podemos formular um teorema sobre a precis√£o das respostas geradas por um sistema RAG.

**Teorema 1** A precis√£o da resposta gerada por um sistema RAG √© diretamente proporcional √† relev√¢ncia e precis√£o das informa√ß√µes recuperadas da base de conhecimento externa e √† capacidade do LLM de integrar e sintetizar essas informa√ß√µes de forma coerente.

*Proof:* (Esbo√ßo) A precis√£o da resposta depende de dois fatores principais: a qualidade da informa√ß√£o recuperada e a habilidade do LLM. Se a informa√ß√£o recuperada for irrelevante ou imprecisa, a resposta gerada provavelmente tamb√©m ser√°. Al√©m disso, mesmo que a informa√ß√£o recuperada seja relevante e precisa, o LLM precisa ser capaz de integr√°-la de forma eficaz na resposta. Um LLM mal treinado ou inadequado para a tarefa pode gerar uma resposta incoerente ou imprecisa, mesmo com informa√ß√µes de alta qualidade. Portanto, a precis√£o da resposta √© limitada tanto pela qualidade da recupera√ß√£o quanto pela capacidade do LLM.

### Conclus√£o

Retrieval-Augmented Generation (RAG) representa um avan√ßo significativo na √°rea de processamento de linguagem natural, oferecendo uma solu√ß√£o eficaz para as limita√ß√µes inerentes aos LLMs pr√©-treinados [^1]. Ao permitir que os modelos acessem e incorporem conhecimento externo, RAG melhora a precis√£o, a transpar√™ncia e a confiabilidade das respostas geradas. √Ä medida que a pesquisa e o desenvolvimento nesta √°rea continuam, podemos esperar que o RAG se torne uma t√©cnica cada vez mais essencial para aplica√ß√µes que exigem conhecimento atualizado, respostas explic√°veis e redu√ß√£o de alucina√ß√µes.

### Refer√™ncias
[^1]: Retrieval-Augmented Generation (RAG) is a technique that enhances language models by fetching relevant data from outside the foundation model and augmenting the input with this data. This provides a richer context to improve the output, addressing disadvantages of pre-trained LLMs, such as the inability to expand memory, limited insights into generated output and hallucinations.
<!-- END -->