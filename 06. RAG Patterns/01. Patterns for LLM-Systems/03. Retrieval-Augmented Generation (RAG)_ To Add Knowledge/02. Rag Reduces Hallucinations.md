## RAG: Mitigando Alucinações e Aprimorando a Factibilidade

### Introdução

O Retrieval-Augmented Generation (RAG) surge como uma abordagem promissora para mitigar as limitações inerentes aos Large Language Models (LLMs), especialmente no que tange à geração de informações factualmente corretas. Ao introduzir um mecanismo de recuperação de informações externas, o RAG não apenas reduz as alucinações, mas também oferece vantagens significativas em termos de custo-efetividade na manutenção de dados atualizados e na correção de vieses e toxicidades [^2]. Este capítulo explora em profundidade esses aspectos, detalhando como o RAG impacta a factibilidade das respostas geradas e como se compara a outras estratégias de aprimoramento de LLMs, como o pre-training contínuo e o fine-tuning.

### Conceitos Fundamentais

**1. Alucinações e Factibilidade em LLMs:**

LLMs, apesar de sua capacidade impressionante de gerar texto coerente e relevante, são propensos a "alucinações", ou seja, a gerar informações que não são factualmente corretas ou que não se sustentam em evidências externas [^2]. Essa limitação decorre da natureza do treinamento desses modelos, que se baseia em vastos conjuntos de dados textuais, mas que nem sempre garantem a precisão e a confiabilidade das informações assimiladas. A factibilidade, portanto, torna-se um critério crucial na avaliação da qualidade das respostas geradas por LLMs.

**2. RAG como Mecanismo de Grounding:**

O RAG aborda o problema das alucinações ao "aterrar" o modelo em um contexto recuperado externamente [^2]. Em vez de depender exclusivamente do conhecimento internalizado durante o treinamento, o RAG consulta um índice de recuperação (e.g., um banco de dados vetorial) para identificar documentos relevantes à consulta do usuário. Esses documentos recuperados são então utilizados como contexto adicional para a geração da resposta, fornecendo uma base factual para o LLM.

> 💡 **Exemplo Numérico:** Imagine um usuário perguntando: "Quem ganhou a Copa do Mundo de 2022?". Sem RAG, o LLM pode alucinar e responder incorretamente. Com RAG, o sistema consulta um banco de dados de artigos esportivos, recupera um artigo que afirma: "A Argentina venceu a Copa do Mundo de 2022 ao derrotar a França nos pênaltis". Essa informação é então usada para gerar uma resposta factualmente correta.

**3. Custo-Efetividade da Manutenção do Índice de Recuperação:**

Uma das vantagens mais significativas do RAG reside na sua custo-efetividade em comparação com o pre-training contínuo de um LLM [^2]. O pre-training contínuo, que consiste em treinar o modelo com dados atualizados periodicamente, é uma operação computacionalmente intensiva e dispendiosa. Em contrapartida, a manutenção de um índice de recuperação atualizado é uma tarefa relativamente mais simples e barata, especialmente quando se utilizam técnicas de indexação eficientes e escaláveis. Isso permite que o RAG acesse dados recentes com um custo muito menor, tornando-o uma opção atraente para aplicações que exigem informações atualizadas.

> 💡 **Exemplo Numérico:** Suponha que o pre-training contínuo de um LLM custe \$ 1 milhão por ano. A manutenção de um índice de recuperação com RAG pode custar \$ 10.000 por ano. A economia é de \$ 990.000, o que demonstra a custo-efetividade do RAG.
> | Abordagem             | Custo Anual |
> | --------------------- | ----------- |
> | Pre-training Contínuo | \$ 1.000.000 |
> | RAG                   | \$ 10.000    |

**4. Facilidade de Atualização e Correção de Dados:**

Outro benefício importante do RAG é a facilidade de atualização e correção de dados no índice de recuperação [^2]. A remoção de informações enviesadas ou tóxicas, por exemplo, pode ser realizada diretamente no índice, sem a necessidade de um re-treinamento completo do modelo. Essa abordagem é muito mais eficiente e flexível do que o fine-tuning ou o prompting, que podem exigir um esforço considerável para ajustar o comportamento do modelo.

> 💡 **Exemplo Numérico:** Um artigo no índice de recuperação contém uma informação incorreta sobre a data de um evento.  Com RAG, basta corrigir essa informação no artigo indexado. Sem RAG, seria necessário um fine-tuning do modelo para corrigir a informação internalizada, o que demandaria mais tempo e recursos.

**5. Comparação com Fine-tuning e Prompting:**

Embora o fine-tuning e o prompting sejam técnicas úteis para adaptar o comportamento de LLMs, eles apresentam limitações em termos de factibilidade e manutenção de dados atualizados. O fine-tuning, por exemplo, pode ser eficaz para ensinar o modelo a seguir um estilo de resposta específico ou a realizar uma tarefa particular, mas não garante que as informações geradas serão factualmente corretas. Além disso, o fine-tuning pode ser dispendioso em termos de tempo e recursos computacionais. O prompting, por sua vez, pode influenciar o modelo a gerar respostas mais factuais, mas sua eficácia depende da qualidade e da precisão das informações fornecidas no prompt. O RAG, ao fornecer um contexto externo e factual, complementa essas técnicas e oferece uma abordagem mais robusta para garantir a factibilidade das respostas geradas.

> 💡 **Exemplo Numérico:** Considere um LLM que, sem RAG, responde a perguntas sobre um produto com informações desatualizadas. O fine-tuning pode ajudar a direcionar o modelo para um estilo de resposta mais informativo, mas não garante que as informações sejam as mais recentes. O prompting pode instruir o modelo a ser mais preciso, mas depende da inclusão de informações precisas no prompt. O RAG, ao fornecer um contexto atualizado sobre o produto, garante que as respostas sejam factualmente corretas e relevantes.

**6. Mecanismos de Avaliação da Factibilidade:**

Para avaliar a eficácia do RAG na redução das alucinações e no aumento da factibilidade, é essencial utilizar métricas e métodos de avaliação adequados. Algumas das métricas comumente utilizadas incluem a precisão factual (factual precision), que mede a proporção de informações factualmente corretas nas respostas geradas, e a cobertura factual (factual coverage), que mede a proporção de informações relevantes presentes no contexto recuperado que são incluídas na resposta. Além disso, a avaliação humana por especialistas é fundamental para verificar a precisão e a relevância das informações geradas.

> 💡 **Exemplo Numérico:** Um sistema RAG é avaliado em um conjunto de 100 perguntas. A precisão factual média das respostas geradas é de 95%, indicando que 95% das informações nas respostas são factualmente corretas. A cobertura factual média é de 80%, indicando que 80% das informações relevantes nos documentos recuperados são incluídas nas respostas.

> | Métrica           | Valor | Interpretação                                                                 |
> | ----------------- | ----- | ----------------------------------------------------------------------------- |
> | Precisão Factual | 95%   | 95% das informações nas respostas são factualmente corretas.                  |
> | Cobertura Factual | 80%   | 80% das informações relevantes nos documentos recuperados são incluídas. |

**7. Desafios e Limitações do RAG:**

Apesar de suas vantagens, o RAG também apresenta desafios e limitações. Um dos principais desafios é a seleção de documentos relevantes no índice de recuperação. Se os documentos recuperados forem irrelevantes ou imprecisos, a resposta gerada também poderá ser afetada. Além disso, o RAG pode ser menos eficaz em situações em que a resposta requer um raciocínio complexo ou a integração de informações de múltiplas fontes. Nesses casos, podem ser necessárias técnicas adicionais, como o uso de cadeias de pensamento (chain-of-thought) ou a combinação do RAG com outros mecanismos de geração de conhecimento.

**Proposição 1** A relevância dos documentos recuperados tem um impacto direto na factibilidade da resposta gerada pelo LLM.

*Demonstração:* Seja $R$ o conjunto de documentos recuperados pelo sistema RAG, e $F(R)$ a factibilidade da resposta gerada com base em $R$. Se $R$ contiver documentos irrelevantes ou factualmente incorretos, a probabilidade de $F(R)$ ser alta diminui. Portanto, existe uma relação direta entre a relevância e a correção dos documentos em $R$ e a factibilidade da resposta gerada.

> 💡 **Exemplo Numérico:**
>
> Suponha que um usuário pergunte: "Qual é a capital da Austrália?". O sistema RAG recupera os seguintes documentos:
>
> *   Documento 1: "Camberra é a capital da Austrália."
> *   Documento 2: "Sydney é a maior cidade da Austrália."
> *   Documento 3: "Melbourne já foi a capital da Austrália."
>
> O sistema RAG deve priorizar o Documento 1, pois ele contém a resposta direta à pergunta. Se o sistema priorizar Documentos 2 ou 3, a resposta gerada poderá ser irrelevante ou incorreta. Isso demonstra a importância da relevância na recuperação de documentos.

**7.1 Otimização da Recuperação de Documentos:**

Para mitigar o impacto da recuperação de documentos irrelevantes, diversas técnicas podem ser empregadas. Isso inclui a otimização dos embeddings utilizados para representar os documentos e a consulta do usuário, a utilização de estratégias de re-ranking para refinar os resultados da busca, e a implementação de filtros para remover documentos com baixa qualidade ou informações desatualizadas. Além disso, técnicas de query expansion podem ser utilizadas para enriquecer a consulta do usuário e aumentar a probabilidade de recuperar documentos relevantes.

> 💡 **Exemplo Numérico:**
>
> **TF-IDF e Cosine Similarity**
>
> *   **Query:** "Melhor carro elétrico"
> *   **Documento 1:** "O Tesla Model 3 é um carro elétrico popular."
> *   **Documento 2:** "A Ford fabrica caminhões potentes."
>
> $\text{Step 1: Calculate TF-IDF}$
>
>  Vamos simplificar e considerar apenas a frequência dos termos (TF).
>  *   Query TF("carro"): 1, TF("elétrico"): 1
>  *   Documento 1 TF("carro"): 1, TF("elétrico"): 1, TF("Tesla"): 1
>  *   Documento 2 TF("carro"): 0, TF("elétrico"): 0, TF("Ford"): 1, TF("caminhões"): 1
>
> $\text{Step 2: Calculate Cosine Similarity}$
>
> Representando os documentos e a query como vetores, e usando apenas TF para simplificar.
>
> *   Query: \[1, 1, 0, 0, 0] (carro, elétrico, Tesla, Ford, caminhões)
> *   Documento 1: \[1, 1, 1, 0, 0]
> *   Documento 2: \[0, 0, 0, 1, 1]
>
> A similaridade do cosseno é calculada como:
>
> $\text{Cosine Similarity}(A, B) = \frac{A \cdot B}{||A|| \cdot ||B||}$
>
> *   Similaridade (Query, Documento 1) = $\frac{1*1 + 1*1}{\sqrt{2} \cdot \sqrt{3}} = \frac{2}{\sqrt{6}} \approx 0.816$
> *   Similaridade (Query, Documento 2) = 0
>
> Documento 1 tem uma similaridade de cosseno muito maior com a query do que Documento 2, indicando que é mais relevante.

**8. RAG e a Geração de Respostas Contextualizadas:**

Além de aumentar a factibilidade, o RAG também melhora a capacidade do LLM de gerar respostas contextualizadas. Ao fornecer um contexto externo relevante, o RAG permite que o modelo compreenda melhor a intenção do usuário e adapte a resposta às suas necessidades específicas.

**Teorema 1** O uso de RAG aumenta a contextualização das respostas geradas por LLMs, medida pela relevância da resposta ao contexto fornecido.

*Demonstração (Esboço):* Defina a relevância contextual como uma função $C(r, q)$, onde $r$ é a resposta gerada e $q$ é a consulta do usuário, dado o contexto recuperado.  Em um cenário sem RAG, a relevância contextual depende unicamente do conhecimento interno do LLM, $C_{LLM}(r, q)$. Com RAG, a relevância contextual é influenciada tanto pelo conhecimento interno quanto pelo contexto recuperado, $C_{RAG}(r, q, R)$, onde $R$ é o conjunto de documentos recuperados.  Dado que RAG fornece informações adicionais relevantes ($R$), a contextualização da resposta, $C_{RAG}$, será geralmente maior ou igual à contextualização sem RAG, $C_{LLM}$. Métricas como a similaridade semântica entre a resposta e os documentos recuperados podem ser usadas para quantificar essa diferença.

> 💡 **Exemplo Numérico:**
>
> Sem RAG, se um usuário perguntar "Como está o tempo?", o LLM pode responder genericamente "O tempo está bom". Com RAG, o sistema recupera informações meteorológicas específicas para a localização do usuário e responde "O tempo em São Paulo é ensolarado, com temperatura de 25°C". A resposta é mais contextualizada e útil para o usuário.

![RAG architecture: Enhancing language models with external knowledge retrieval for improved answer generation.](./../images/image17.jpg)

### Conclusão

O RAG emerge como uma ferramenta poderosa para aprimorar a factibilidade das respostas geradas por LLMs, mitigando as alucinações e permitindo o acesso a informações atualizadas de forma custo-efetiva [^2]. Ao "aterrar" o modelo em um contexto recuperado externamente, o RAG fornece uma base factual para a geração da resposta, tornando-a mais precisa e confiável. Além disso, a facilidade de atualização e correção de dados no índice de recuperação torna o RAG uma opção flexível e adaptável a diferentes cenários e necessidades. Embora apresente desafios e limitações, o RAG representa um avanço significativo na busca por LLMs mais factuais e confiáveis.

### Referências
[^1]: (Assumindo que exista uma referência anterior)
[^2]: RAG reduces hallucinations by grounding the model in the retrieved context, which increases factuality. Maintaining updated retrieval indexes is more cost-effective than continuous pre-training of an LLM, facilitating access to recent data. Updating or removing biased or toxic data is easier in the retrieval index than via fine-tuning or prompting.
<!-- END -->