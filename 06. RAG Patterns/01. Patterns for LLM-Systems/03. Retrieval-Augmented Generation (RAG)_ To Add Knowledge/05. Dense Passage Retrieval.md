## Dense Passage Retrieval (DPR) para Recupera√ß√£o de Documentos

### Introdu√ß√£o

A Recupera√ß√£o Aumentada por Gera√ß√£o (RAG) depende crucialmente da capacidade de recuperar documentos relevantes para complementar e guiar a gera√ß√£o de respostas por Large Language Models (LLMs). M√©todos tradicionais de recupera√ß√£o, como TF-IDF, utilizam representa√ß√µes esparsas de vetores. O Dense Passage Retrieval (DPR) [^5] surge como uma alternativa que emprega embeddings densos para a recupera√ß√£o, demonstrando superioridade em rela√ß√£o a *baselines* robustas e estabelecendo uma correla√ß√£o entre maior precis√£o na recupera√ß√£o e melhor desempenho em tarefas de Question Answering (QA) *end-to-end*.

### Conceitos Fundamentais

O DPR difere fundamentalmente de m√©todos como TF-IDF ao representar documentos e consultas em um espa√ßo vetorial denso. Em vez de depender da frequ√™ncia de termos (TF) e da frequ√™ncia inversa de documentos (IDF) para criar vetores esparsos, o DPR utiliza redes neurais, especificamente transformadores como o BERT [^5], para gerar embeddings densos.

> üí° **Exemplo Num√©rico:** Suponha que temos um pequeno corpus com dois documentos:
>
> *   Documento 1: "O gato est√° no tapete."
> *   Documento 2: "O cachorro est√° no jardim."
>
> TF-IDF criaria vetores esparsos com base na frequ√™ncia das palavras.  DPR, por outro lado, usaria BERT para gerar um vetor denso para cada documento, por exemplo, um vetor de 768 dimens√µes. A vantagem √© que "gato" e "cachorro", que s√£o semanticamente relacionados, teriam embeddings pr√≥ximos no espa√ßo vetorial denso, mesmo que as palavras em si n√£o apare√ßam no mesmo documento.

**Arquitetura do DPR:**

O DPR √© composto por dois encoders BERT independentes:

1.  **Passage Encoder:** Respons√°vel por codificar passagens de texto em vetores densos.
2.  **Query Encoder:** Respons√°vel por codificar consultas (perguntas) em vetores densos.

Ambos os encoders s√£o *fine-tuned* em pares de pergunta-resposta [^5], otimizando a representa√ß√£o vetorial para maximizar a similaridade entre a consulta e passagens relevantes.

**Proposi√ß√£o 1:** *A independ√™ncia dos encoders permite otimiza√ß√µes espec√≠ficas para cada tarefa (codifica√ß√£o de passagens vs. codifica√ß√£o de consultas), potencialmente levando a representa√ß√µes mais eficientes.*

**Processo de Recupera√ß√£o:**

1.  Dada uma consulta, o Query Encoder gera um embedding denso da consulta.
2.  Este embedding da consulta √© comparado com os embeddings de todas as passagens de texto no √≠ndice.
3.  A similaridade entre a consulta e as passagens √© calculada usando o produto interno (inner product) [^5] entre os vetores.
4.  As *k* passagens mais similares s√£o recuperadas [^5].

**Lema 1:** *O uso do produto interno como medida de similaridade implica que a magnitude dos vetores influencia a similaridade calculada. Portanto, a normaliza√ß√£o dos embeddings pode ser crucial para um desempenho robusto.*

*Proof.* A similaridade entre dois vetores $u$ e $v$ usando o produto interno √© dada por $\text{sim}(u, v) = u \cdot v = ||u|| \cdot ||v|| \cdot \cos(\theta)$, onde $\theta$ √© o √¢ngulo entre os vetores. Se os vetores n√£o forem normalizados, a magnitude $||u||$ e $||v||$ influenciar√£o diretamente o valor da similaridade, independentemente da orienta√ß√£o relativa dos vetores. Portanto, a normaliza√ß√£o (e.g., para vetores unit√°rios) pode mitigar essa influ√™ncia e focar na similaridade direcional. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos uma consulta "animais de estima√ß√£o" com embedding $q = [0.2, 0.8, 0.1]$ e dois documentos com embeddings:
>
> *   Documento 1 (gato): $d_1 = [0.3, 0.7, 0.2]$
> *   Documento 2 (carro): $d_2 = [0.9, 0.1, 0.1]$
>
> O produto interno (similaridade) √© calculado como:
>
> *   $\text{sim}(q, d_1) = (0.2 \times 0.3) + (0.8 \times 0.7) + (0.1 \times 0.2) = 0.06 + 0.56 + 0.02 = 0.64$
> *   $\text{sim}(q, d_2) = (0.2 \times 0.9) + (0.8 \times 0.1) + (0.1 \times 0.1) = 0.18 + 0.08 + 0.01 = 0.27$
>
> Sem normaliza√ß√£o, o Documento 1 (gato) seria considerado mais similar √† consulta "animais de estima√ß√£o" do que o Documento 2 (carro).
>
> Agora, vamos normalizar os vetores:
>
> *   $||q|| = \sqrt{0.2^2 + 0.8^2 + 0.1^2} = \sqrt{0.69} \approx 0.83$
> *   $||d_1|| = \sqrt{0.3^2 + 0.7^2 + 0.2^2} = \sqrt{0.62} \approx 0.79$
> *   $||d_2|| = \sqrt{0.9^2 + 0.1^2 + 0.1^2} = \sqrt{0.83} \approx 0.91$
>
> Vetores normalizados:
>
> *   $q_{norm} = q / ||q|| = [0.24, 0.96, 0.12]$
> *   $d_{1_{norm}} = d_1 / ||d_1|| = [0.38, 0.89, 0.25]$
> *   $d_{2_{norm}} = d_2 / ||d_2|| = [0.99, 0.11, 0.11]$
>
> Similaridade com vetores normalizados (cosseno):
>
> *   $\text{sim}(q_{norm}, d_{1_{norm}}) = (0.24 \times 0.38) + (0.96 \times 0.89) + (0.12 \times 0.25) = 0.0912 + 0.8544 + 0.03 = 0.9756$
> *   $\text{sim}(q_{norm}, d_{2_{norm}}) = (0.24 \times 0.99) + (0.96 \times 0.11) + (0.12 \times 0.11) = 0.2376 + 0.1056 + 0.0132 = 0.3564$
>
> A normaliza√ß√£o garante que a similaridade se baseie na orienta√ß√£o dos vetores, n√£o na sua magnitude.
>

**Treinamento do DPR:**

O treinamento do DPR √© crucial para o desempenho do modelo. O objetivo √© aprender representa√ß√µes vetoriais que maximizem a similaridade entre consultas e passagens relevantes, enquanto minimizam a similaridade com passagens irrelevantes.

O processo de treinamento geralmente envolve as seguintes etapas:

1.  **Coleta de Dados:** Cria√ß√£o de um conjunto de dados de pares pergunta-resposta. Esses pares podem ser obtidos de *datasets* de QA existentes ou gerados por meio de *data augmentation* [^5].
2.  **Amostragem Negativa:** Para cada pergunta, selecionar passagens negativas (irrelevantes). Essa etapa √© fundamental, pois o modelo precisa aprender a distinguir entre passagens relevantes e irrelevantes. Estrat√©gias comuns para amostragem negativa incluem:
    *   Amostragem aleat√≥ria: Selecionar passagens aleatoriamente do corpus.
    *   Amostragem *hard negative*: Selecionar passagens que s√£o semanticamente similares √† pergunta, mas n√£o cont√™m a resposta correta.

    **Teorema 1:** *A escolha da estrat√©gia de amostragem negativa tem um impacto significativo no desempenho do DPR. A amostragem *hard negative* geralmente leva a um melhor desempenho, mas requer um esfor√ßo computacional maior.*

    > üí° **Exemplo Num√©rico:**
    >
    > Considere a pergunta: "Qual √© a capital da Fran√ßa?".
    >
    > *   Passagem positiva: "Paris √© a capital da Fran√ßa."
    >
    > *   Amostragem aleat√≥ria negativa: "O c√©u √© azul." (f√°cil de distinguir)
    >
    > *   Amostragem *hard negative*: "Lyon √© uma grande cidade na Fran√ßa." (mais dif√≠cil de distinguir, pois fala sobre Fran√ßa).  Esta √∫ltima for√ßar√° o modelo a aprender caracter√≠sticas mais discriminativas.

3.  **Fun√ß√£o de Perda:** Utiliza√ß√£o de uma fun√ß√£o de perda que penaliza o modelo por atribuir baixa similaridade a passagens relevantes e alta similaridade a passagens irrelevantes. Uma fun√ß√£o de perda comum √© a *negative log-likelihood* (NLL):

    $$
    \mathcal{L} = -\log \frac{\exp(\text{sim}(q, p^+))}{\sum_{p' \in P} \exp(\text{sim}(q, p'))}
    $$

    Onde:
    *   $q$ √© o embedding da consulta.
    *   $p^+$ √© o embedding de uma passagem positiva (relevante).
    *   $P$ √© o conjunto de todas as passagens, incluindo a passagem positiva e as passagens negativas.
    *   $\text{sim}(q, p)$ √© a fun√ß√£o de similaridade (produto interno) entre os embeddings da consulta e da passagem.

    **Teorema 1.1:** *A fun√ß√£o de perda NLL √© uma inst√¢ncia da fun√ß√£o de perda *softmax cross-entropy*. Minimizar a NLL equivale a maximizar a probabilidade de que a passagem positiva seja a mais similar √† consulta em rela√ß√£o a todas as outras passagens no conjunto P.*

    > üí° **Exemplo Num√©rico:**
    >
    > Suponha que $\text{sim}(q, p^+) = 5$,  $\text{sim}(q, p_1) = 1$, $\text{sim}(q, p_2) = 2$, onde $p_1$ e $p_2$ s√£o passagens negativas. Ent√£o:
    >
    > $\mathcal{L} = -\log \frac{\exp(5)}{\exp(5) + \exp(1) + \exp(2)} = -\log \frac{148.41}{148.41 + 2.72 + 7.39} = -\log \frac{148.41}{158.52} = -\log(0.936) \approx 0.066$
    >
    > Se a similaridade com a passagem positiva fosse menor, digamos $\text{sim}(q, p^+) = 3$:
    >
    > $\mathcal{L} = -\log \frac{\exp(3)}{\exp(3) + \exp(1) + \exp(2)} = -\log \frac{20.09}{20.09 + 2.72 + 7.39} = -\log \frac{20.09}{30.2} = -\log(0.665) \approx 0.408$
    >
    > Uma similaridade menor com a passagem positiva resulta em uma perda maior, incentivando o modelo a ajustar seus par√¢metros.

4.  **Otimiza√ß√£o:** Otimiza√ß√£o dos par√¢metros dos encoders usando algoritmos de otimiza√ß√£o como Adam [^5], com o objetivo de minimizar a fun√ß√£o de perda.

**Vantagens do DPR:**

*   **Representa√ß√µes Sem√¢nticas:** Ao utilizar embeddings densos, o DPR captura rela√ß√µes sem√¢nticas entre palavras e frases, indo al√©m da correspond√™ncia exata de termos.
*   **Generaliza√ß√£o:** O *fine-tuning* em pares pergunta-resposta permite que o DPR generalize para novas consultas e dom√≠nios, mesmo que n√£o tenha visto as palavras exatas durante o treinamento.
*   **Desempenho Superior:** Demonstra desempenho superior em compara√ß√£o com m√©todos de recupera√ß√£o baseados em vetores esparsos, como TF-IDF [^5].
*   **Integra√ß√£o com LLMs:** A capacidade de recuperar passagens relevantes para guiar a gera√ß√£o de respostas por LLMs resulta em um aumento na precis√£o e relev√¢ncia das respostas geradas.

**Corol√°rio 1:** *A combina√ß√£o do DPR com LLMs oferece uma abordagem modular e flex√≠vel para QA, permitindo a atualiza√ß√£o independente dos componentes de recupera√ß√£o e gera√ß√£o.*

**Desafios do DPR:**

*   **Custo Computacional:** O c√°lculo de similaridade entre a consulta e todas as passagens no √≠ndice pode ser computacionalmente caro, especialmente para grandes *corpora*. T√©cnicas de indexa√ß√£o e busca aproximada de vizinhos mais pr√≥ximos (ANN) s√£o frequentemente utilizadas para mitigar esse problema.

    **Lema 2:** *O uso de estruturas de dados como HNSW (Hierarchical Navigable Small World) para indexa√ß√£o ANN pode reduzir significativamente o tempo de busca, com um impacto aceit√°vel na precis√£o da recupera√ß√£o.*

    > üí° **Exemplo Num√©rico:**
    >
    > Sem indexa√ß√£o ANN, buscar em um corpus de 1 milh√£o de documentos pode exigir 1 segundo. Com HNSW, o tempo de busca pode ser reduzido para 0.05 segundos, com uma pequena perda de precis√£o (e.g., recall de 95% em vez de 98%). A escolha depende do trade-off entre velocidade e precis√£o.

*   **Amostragem Negativa:** A escolha de estrat√©gias eficazes de amostragem negativa √© fundamental para o desempenho do DPR. Amostras negativas de baixa qualidade podem levar a um treinamento ineficiente.
<!-- END -->