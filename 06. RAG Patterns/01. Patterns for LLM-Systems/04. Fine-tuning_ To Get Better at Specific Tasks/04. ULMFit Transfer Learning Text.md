## ULMFit: Transfer√™ncia de Aprendizagem e Fine-tuning em NLP

### Introdu√ß√£o

Este cap√≠tulo explora o Universal Language Model Fine-tuning (ULMFit), um dos trabalhos pioneiros na aplica√ß√£o de **transfer√™ncia de aprendizagem** em texto [^4]. ULMFit estabeleceu um protocolo que envolve **pr√©-treinamento auto-supervisionado** seguido por **fine-tuning**, utilizando uma variante de LSTM (Long Short-Term Memory) chamada AWS-LSTM [^4]. Este protocolo revolucionou a forma como modelos de linguagem s√£o treinados e adaptados para tarefas espec√≠ficas em Processamento de Linguagem Natural (NLP).

### Conceitos Fundamentais

O ULMFit aborda um problema crucial em NLP: a necessidade de grandes conjuntos de dados rotulados para treinar modelos eficazes [^4]. Obter e rotular esses conjuntos de dados √© caro e demorado. A transfer√™ncia de aprendizagem oferece uma solu√ß√£o, permitindo que um modelo pr√©-treinado em um grande corpus de texto n√£o rotulado seja adaptado (fine-tuned) para uma tarefa espec√≠fica com um conjunto de dados rotulado menor.

**1. Pr√©-treinamento Auto-supervisionado:**

O primeiro passo do ULMFit √© o **pr√©-treinamento** do modelo em um vasto corpus de texto n√£o rotulado [^4]. Este pr√©-treinamento √© realizado de forma **auto-supervisionada**, o que significa que o modelo aprende a prever a pr√≥xima palavra em uma sequ√™ncia de texto [^4]. O objetivo √© que o modelo capture as caracter√≠sticas gerais da linguagem, incluindo sintaxe, sem√¢ntica e nuances contextuais [^4]. Essa abordagem permite ao modelo aprender representa√ß√µes √∫teis da linguagem sem a necessidade de r√≥tulos expl√≠citos.

**2. AWS-LSTM:**

ULMFit utiliza uma variante espec√≠fica de LSTM chamada **AWS-LSTM** [^4]. LSTM √© uma arquitetura de rede neural recorrente (RNN) projetada para lidar com o problema do desaparecimento do gradiente, que dificulta o treinamento de RNNs em sequ√™ncias longas. AWS-LSTM aprimora o LSTM ao incorporar *dropout* em v√°rias portas (*gates*) da rede [^4]. Dropout √© uma t√©cnica de regulariza√ß√£o que ajuda a prevenir o overfitting, desativando aleatoriamente algumas unidades da rede durante o treinamento. A aplica√ß√£o de dropout nas portas do LSTM permite que o modelo aprenda representa√ß√µes mais robustas e generaliz√°veis.

> üí° **Exemplo Num√©rico:** Considere uma c√©lula LSTM com um gate de entrada ($i_t$). Sem dropout, a sa√≠da do gate seria simplesmente $\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})$. Com dropout (probabilidade $p=0.2$), 20% das conex√µes dentro desse gate seriam aleatoriamente zeradas durante cada passagem de treinamento. Isso for√ßa a rede a aprender representa√ß√µes mais robustas, pois n√£o pode depender excessivamente de nenhuma conex√£o espec√≠fica.

Para melhor compreendermos o papel do Dropout em portas LSTM, podemos definir formalmente a estrutura de uma c√©lula LSTM padr√£o. Uma c√©lula LSTM recebe como entrada o estado oculto anterior $h_{t-1}$ e a entrada atual $x_t$ e produz o estado oculto atual $h_t$ e o estado da c√©lula $c_t$. As equa√ß√µes para o LSTM padr√£o s√£o as seguintes:

$i_t = \sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})$
$f_t = \sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf})$
$g_t = \tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg})$
$o_t = \sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})$
$c_t = f_t \odot c_{t-1} + i_t \odot g_t$
$h_t = o_t \odot \tanh(c_t)$

onde:
* $i_t$ √© o gate de entrada (input gate).
* $f_t$ √© o gate de esquecimento (forget gate).
* $g_t$ √© o gate de c√©lula (cell gate ou input modulation gate).
* $o_t$ √© o gate de sa√≠da (output gate).
* $c_t$ √© o estado da c√©lula.
* $h_t$ √© o estado oculto.
* $\sigma$ √© a fun√ß√£o sigmoide.
* $\tanh$ √© a fun√ß√£o tangente hiperb√≥lica.
* $W$ s√£o as matrizes de peso.
* $b$ s√£o os vetores de bias.
* $\odot$ denota a multiplica√ß√£o elemento a elemento.

A AWS-LSTM introduz dropout nas portas, aplicando m√°scaras de dropout aos gates de entrada, esquecimento, c√©lula e sa√≠da. Isso ajuda a regularizar a rede e evitar o overfitting.

**3. Fine-tuning:**

Ap√≥s o pr√©-treinamento, o modelo √© **fine-tuned** em um conjunto de dados rotulado espec√≠fico para a tarefa desejada [^4]. Este processo de fine-tuning envolve ajustar os pesos do modelo pr√©-treinado para otimizar o desempenho na tarefa espec√≠fica. ULMFit introduz t√©cnicas de fine-tuning que evitam a *catastrophic forgetting*, que ocorre quando o modelo esquece o conhecimento adquirido durante o pr√©-treinamento ao ser treinado em uma nova tarefa.

**4. T√©cnicas de Fine-tuning do ULMFit:**

ULMFit utiliza v√°rias t√©cnicas de fine-tuning para maximizar o desempenho e evitar o *catastrophic forgetting*:

*   **Discriminative Fine-tuning:** Diferentes camadas da rede s√£o fine-tuned com diferentes taxas de aprendizado [^4]. As camadas inferiores, que capturam caracter√≠sticas mais gerais da linguagem, s√£o fine-tuned com taxas de aprendizado menores, enquanto as camadas superiores, que s√£o mais espec√≠ficas para a tarefa, s√£o fine-tuned com taxas de aprendizado maiores. Isso permite que o modelo preserve o conhecimento aprendido durante o pr√©-treinamento enquanto adapta as camadas superiores √† tarefa espec√≠fica.

> üí° **Exemplo Num√©rico:** Suponha que tenhamos um modelo com 3 camadas LSTM.  Se a taxa de aprendizado base for $\eta = 0.01$, ent√£o, usando a f√≥rmula $\eta_l = \eta / (2.6)^{L-l}$, ter√≠amos:
>
> *   Camada 1 (inferior): $\eta_1 = 0.01 / (2.6)^{3-1} = 0.01 / 6.76 \approx 0.0015$
> *   Camada 2 (intermedi√°ria): $\eta_2 = 0.01 / (2.6)^{3-2} = 0.01 / 2.6 \approx 0.0038$
> *   Camada 3 (superior): $\eta_3 = 0.01 / (2.6)^{3-3} = 0.01 / 1 = 0.01$
>
> Isso demonstra como as camadas inferiores recebem taxas de aprendizado significativamente menores em compara√ß√£o com a camada superior. Isso ajuda a preservar o conhecimento geral da linguagem aprendido durante o pr√©-treinamento.

*   **Slanted Triangular Learning Rates (STLR):** A taxa de aprendizado √© aumentada linearmente durante as primeiras itera√ß√µes do fine-tuning e, em seguida, diminu√≠da linearmente [^4]. Isso permite que o modelo explore o espa√ßo de busca de forma mais eficiente e encontre um m√≠nimo local adequado para a tarefa.

> üí° **Exemplo Num√©rico:** Seja $T = 1000$ o n√∫mero total de itera√ß√µes de fine-tuning e $cutoff = 0.1$. Isso significa que a taxa de aprendizado aumentar√° linearmente durante as primeiras 100 itera√ß√µes (10% de 1000) e diminuir√° linearmente durante as 900 itera√ß√µes restantes. Se $\eta_{max} = 0.01$, ent√£o na itera√ß√£o $t=50$, a taxa de aprendizado seria $\eta(50) = 0.01 \cdot \frac{50}{1000 \cdot 0.1} = 0.005$. Na itera√ß√£o $t=500$, a taxa de aprendizado seria $\eta(500) = 0.01 \cdot \frac{1000 - 500}{1000 \cdot (1 - 0.1)} = 0.01 \cdot \frac{500}{900} \approx 0.0056$.

*   **Gradual Unfreezing:** As camadas da rede s√£o gradualmente descongeladas durante o fine-tuning [^4]. Inicialmente, apenas as camadas superiores s√£o fine-tuned, enquanto as camadas inferiores permanecem congeladas. Em seguida, as camadas intermedi√°rias s√£o descongeladas e fine-tuned, e, finalmente, as camadas inferiores s√£o descongeladas e fine-tuned. Isso permite que o modelo se adapte gradualmente √† tarefa espec√≠fica, evitando o *catastrophic forgetting*.

> üí° **Exemplo Num√©rico:** Num modelo de 3 camadas, poder√≠amos seguir este cronograma:
>
> *   **Fase 1 (√âpocas 1-5):** Descongelar apenas a camada 3 (superior). Camadas 1 e 2 permanecem congeladas.
> *   **Fase 2 (√âpocas 6-10):** Descongelar a camada 2 (intermedi√°ria). A camada 1 permanece congelada.
> *   **Fase 3 (√âpocas 11-15):** Descongelar a camada 1 (inferior). Todas as camadas s√£o agora descongeladas e fine-tuned.
>
> Essa abordagem gradual permite que o modelo se adapte √† tarefa espec√≠fica, come√ßando com os aspectos mais espec√≠ficos da tarefa e, em seguida, ajustando gradualmente as representa√ß√µes mais gerais.

Para formalizar a ideia de *discriminative fine-tuning*, considere que o modelo possui $L$ camadas. Seja $\eta$ a taxa de aprendizado base. Ent√£o, a taxa de aprendizado para a camada $l$ √© dada por $\eta_l = \eta / (2.6)^{L-l}$. Isso significa que as camadas inferiores t√™m taxas de aprendizado exponencialmente menores do que as camadas superiores.

**Teorema 1:** *Discriminative fine-tuning* garante que o modelo preserve informa√ß√µes aprendidas durante o pre-treinamento ao aplicar taxas de aprendizado menores nas camadas inferiores, permitindo que as camadas superiores se adaptem √† nova tarefa sem comprometer a representa√ß√£o geral da linguagem.

*Prova (Esbo√ßo):* A prova se baseia no fato de que as camadas inferiores capturam caracter√≠sticas mais gerais e est√°veis da linguagem. Ao usar taxas de aprendizado menores, evitamos modificar drasticamente essas representa√ß√µes, preservando assim o conhecimento pr√©-treinado. As camadas superiores, com taxas de aprendizado maiores, podem se adaptar mais rapidamente √† nova tarefa, ajustando-se aos detalhes espec√≠ficos do novo conjunto de dados.

Al√©m disso, podemos generalizar o conceito de *Slanted Triangular Learning Rates (STLR)*.

**Teorema 2:** Seja $T$ o n√∫mero total de itera√ß√µes de fine-tuning. No STLR, a taxa de aprendizado $\eta(t)$ na itera√ß√£o $t$ √© definida como:

$$\eta(t) = \begin{cases} \eta_{max} \cdot \frac{t}{T \cdot cutoff} & \text{se } t \le T \cdot cutoff \\ \eta_{max} \cdot \frac{T - t}{T \cdot (1 - cutoff)} & \text{se } t > T \cdot cutoff \end{cases}$$

onde $\eta_{max}$ √© a taxa de aprendizado m√°xima e $cutoff$ √© a propor√ß√£o de itera√ß√µes durante as quais a taxa de aprendizado aumenta linearmente.

Este teorema formaliza a descri√ß√£o de STLR, fornecendo uma defini√ß√£o precisa da taxa de aprendizado em fun√ß√£o do tempo.





![Diagrama das etapas de pre-treinamento e ajuste fino do modelo de linguagem ULMFiT.](./../images/image20.jpg)

### Conclus√£o

ULMFit representou um avan√ßo significativo na √°rea de NLP, demonstrando o poder da transfer√™ncia de aprendizagem e do fine-tuning [^4]. O protocolo estabelecido pelo ULMFit, que consiste em pr√©-treinamento auto-supervisionado seguido por fine-tuning com t√©cnicas espec√≠ficas, tornou-se uma pr√°tica comum no treinamento de modelos de linguagem. As t√©cnicas de fine-tuning introduzidas pelo ULMFit, como *discriminative fine-tuning*, *slanted triangular learning rates* e *gradual unfreezing*, continuam sendo relevantes e influenciam as abordagens modernas de transfer√™ncia de aprendizagem em NLP. Ao fornecer um framework para adaptar modelos de linguagem pr√©-treinados a tarefas espec√≠ficas com dados limitados, ULMFit abriu caminho para o desenvolvimento de modelos de NLP mais eficazes e eficientes.

### Refer√™ncias
[^4]: Trecho do contexto: ULMFit was one of the first works to apply transfer learning to text, establishing a protocol of self-supervised pre-training followed by fine-tuning, using AWS-LSTM, an LSTM variant with dropout in several gates.
<!-- END -->