## Prefix-tuning: Fine-tuning Eficiente para Large Language Models

### Introdu√ß√£o
Em cen√°rios de **Retrieval-Augmented Generation (RAG)** e **Neural Information Retrieval (NIR)**, a adapta√ß√£o de *Large Language Models (LLMs)* a tarefas espec√≠ficas √© crucial para otimizar o desempenho. Embora o *fine-tuning* completo seja uma abordagem comum, ele pode ser computacionalmente caro e exigir um grande n√∫mero de par√¢metros atualizados. Prefix-tuning surge como uma alternativa eficiente, que busca alcan√ßar desempenho compar√°vel ao *fine-tuning* completo com uma fra√ß√£o significativamente menor de par√¢metros trein√°veis [^1]. Este cap√≠tulo explora em detalhes a t√©cnica de prefix-tuning, suas vantagens e desvantagens.

### Conceitos Fundamentais
**Prefix-tuning** √© uma t√©cnica de *fine-tuning* que introduz par√¢metros trein√°veis adicionais nos *hidden states* de todos os blocos *transformer* de um *Language Model* (LM), enquanto mant√©m os par√¢metros originais do LM congelados [^1]. Em vez de ajustar todos os pesos da rede neural, apenas um conjunto menor de vetores "prefixo" √© otimizado. Esses prefixos atuam como "condicionadores", guiando o modelo para gerar as sa√≠das desejadas para a tarefa espec√≠fica.

Mais formalmente, considere um *transformer* com $L$ camadas. Para cada camada $l$, seja $h_l$ o *hidden state* resultante. No *fine-tuning* tradicional, todos os par√¢metros do *transformer* seriam atualizados durante o treinamento. Em contraste, o prefix-tuning introduz um prefixo de comprimento $P$ para cada camada. O *hidden state* modificado, $\hat{h}_l$, √© ent√£o calculado da seguinte forma:

$$
\hat{h}_l =
\begin{cases}
[Prefix_l; h_l], & \text{se } i \leq P \\
h_l, & \text{se } i > P
\end{cases}
$$

onde $i$ representa a posi√ß√£o no *hidden state* e $Prefix_l$ √© o prefixo trein√°vel para a camada $l$. O operador $[;]$ denota concatena√ß√£o.

A principal vantagem do prefix-tuning reside na drasticamente reduzida quantidade de par√¢metros a serem treinados. Tipicamente, prefix-tuning consegue alcan√ßar performance compar√°vel ao *fine-tuning* completo com apenas 0.1% dos par√¢metros atualizados [^1]. Isso torna o prefix-tuning uma op√ß√£o atraente em cen√°rios com recursos computacionais limitados ou quando o modelo original √© muito grande para ser totalmente *fine-tuned*.

> üí° **Exemplo Num√©rico:**
>
> Considere um modelo Transformer com 12 camadas ($L = 12$) e uma dimens√£o de *hidden state* de 768 ($d = 768$). Se utilizarmos um prefixo de comprimento 10 ($P = 10$), o n√∫mero total de par√¢metros trein√°veis no prefix-tuning seria:
>
> $L \times P \times d = 12 \times 10 \times 768 = 92160$
>
> Agora, suponha que o modelo Transformer completo tenha 110 milh√µes de par√¢metros. O prefix-tuning, neste caso, ajustaria apenas 92.160 par√¢metros, o que representa aproximadamente 0.08% do total de par√¢metros do modelo.
>
> $\text{Porcentagem de par√¢metros trein√°veis} = \frac{92160}{110000000} \times 100\% \approx 0.084\%$
>
> Este exemplo ilustra a efici√™ncia param√©trica do prefix-tuning, onde uma pequena fra√ß√£o dos par√¢metros √© ajustada para adaptar o modelo a uma tarefa espec√≠fica.

**Teorema 1** *Complexidade Param√©trica*. Seja $d$ a dimens√£o do *hidden state*. O n√∫mero total de par√¢metros trein√°veis no prefix-tuning √© $L \times P \times d$.

*Prova*. Para cada uma das $L$ camadas, um prefixo de comprimento $P$ √© introduzido. Cada elemento do prefixo √© um vetor de dimens√£o $d$. Portanto, o n√∫mero de par√¢metros trein√°veis por camada √© $P \times d$, e o n√∫mero total de par√¢metros trein√°veis √© $L \times P \times d$.

**Corol√°rio 1** A redu√ß√£o no n√∫mero de par√¢metros trein√°veis em compara√ß√£o com o *fine-tuning* completo √© significativa quando $L \times P \times d$ √© muito menor do que o n√∫mero total de par√¢metros no modelo *transformer*.

**Observa√ß√£o:** Uma escolha adequada de $P$ √© crucial. Um $P$ muito pequeno pode limitar a capacidade do modelo de se adaptar √† tarefa, enquanto um $P$ muito grande pode levar a overfitting.

**Vantagens do Prefix-tuning:**

*   **Efici√™ncia Param√©trica:** Requer apenas o ajuste de uma pequena fra√ß√£o dos par√¢metros do modelo.
*   **Custo Computacional Reduzido:** Menos par√¢metros a serem atualizados implicam em menor tempo de treinamento e menor demanda de mem√≥ria.
*   **Preserva√ß√£o do Conhecimento Pr√©-existente:** Ao manter os par√¢metros originais do LM congelados, o prefix-tuning tende a preservar melhor o conhecimento pr√©-existente no modelo.
*   **Adaptabilidade:** O prefixo pode ser projetado para diversas tarefas, permitindo a reutiliza√ß√£o do modelo base para diferentes aplica√ß√µes.

**Desvantagens do Prefix-tuning:**

*   **Desempenho Sub-√≥timo:** Embora o prefix-tuning possa alcan√ßar desempenho compar√°vel ao *fine-tuning* completo, ele pode n√£o atingir o mesmo n√≠vel de precis√£o em algumas tarefas.
*   **Complexidade de Implementa√ß√£o:** A implementa√ß√£o do prefix-tuning pode ser mais complexa do que o *fine-tuning* completo, exigindo modifica√ß√µes na arquitetura do modelo.
*   **Suscetibilidade a Overfitting:** Apesar de treinar menos par√¢metros, existe o risco de overfitting nos prefixos, especialmente com conjuntos de dados pequenos.

Para mitigar a complexidade de implementa√ß√£o, as seguintes estrat√©gias podem ser consideradas:
1. **Inicializa√ß√£o Cuidadosa:** Inicializar os prefixos com valores apropriados pode acelerar o treinamento e melhorar o desempenho.
2. **Regulariza√ß√£o:** Aplicar t√©cnicas de regulariza√ß√£o, como *dropout* ou *weight decay*, pode ajudar a prevenir o overfitting.
3. **Ajuste do Comprimento do Prefixo:** O comprimento do prefixo ($P$) √© um hiperpar√¢metro importante que deve ser ajustado para cada tarefa.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar o efeito da regulariza√ß√£o com *weight decay*. Suponha que, sem regulariza√ß√£o, um modelo prefix-tuned atinja uma precis√£o de 82% no conjunto de valida√ß√£o. Ap√≥s aplicar *weight decay* com um fator de 0.01, a precis√£o no conjunto de valida√ß√£o sobe para 84%, enquanto a precis√£o no conjunto de treinamento diminui de 95% para 90%. Isso indica que o *weight decay* est√° ajudando a reduzir o overfitting, melhorando a generaliza√ß√£o do modelo para dados n√£o vistos.
>
> | Modelo                       | Precis√£o (Treinamento) | Precis√£o (Valida√ß√£o) |
> | ----------------------------- | ----------------------- | --------------------- |
> | Prefix-tuning (sem regulariza√ß√£o) | 95%                    | 82%                  |
> | Prefix-tuning (weight decay 0.01) | 90%                    | 84%                  |

Al√©m disso, a escolha da fun√ß√£o de ativa√ß√£o utilizada na proje√ß√£o dos prefixos pode impactar o desempenho.

**Proposi√ß√£o 2** A escolha da fun√ß√£o de ativa√ß√£o para projetar os prefixos pode influenciar a capacidade do modelo de aprender representa√ß√µes √∫teis para a tarefa alvo.

*Discuss√£o*. Fun√ß√µes de ativa√ß√£o n√£o lineares, como ReLU ou Tanh, permitem que o modelo aprenda rela√ß√µes mais complexas entre os prefixos e os *hidden states* originais. No entanto, o uso de fun√ß√µes de ativa√ß√£o lineares pode simplificar o treinamento e reduzir o risco de overfitting, especialmente em conjuntos de dados pequenos. A escolha ideal depende da complexidade da tarefa e do tamanho do conjunto de dados.

> üí° **Exemplo Num√©rico:**
>
> Considere a compara√ß√£o do uso de ReLU e uma fun√ß√£o de ativa√ß√£o linear na proje√ß√£o dos prefixos. Em uma tarefa de sumariza√ß√£o, utilizando ReLU, o modelo pode gerar resumos mais concisos e informativos (medido por ROUGE score de 0.45), enquanto com uma fun√ß√£o linear, os resumos podem ser mais literais e menos abstratos (ROUGE score de 0.40). No entanto, em tarefas mais simples, como classifica√ß√£o de sentimentos, a diferen√ßa no desempenho pode ser m√≠nima.
>
> | Fun√ß√£o de Ativa√ß√£o | ROUGE Score (Sumariza√ß√£o) | Precis√£o (Classifica√ß√£o de Sentimentos) |
> | ------------------- | -------------------------- | -------------------------------------- |
> | ReLU                | 0.45                       | 0.88                                   |
> | Linear               | 0.40                       | 0.87                                   |
>
> A escolha da fun√ß√£o de ativa√ß√£o deve ser avaliada empiricamente com base na tarefa espec√≠fica.





![Compara√ß√£o entre 'Fine-tuning' e 'Prefix-tuning' em modelos Transformer, mostrando a otimiza√ß√£o de par√¢metros em cada abordagem.](./../images/image18.jpg)

### Conclus√£o

### Refer√™ncias
[^1]: Li, X., & Liang, P. (2021). Prefix-tuning: Optimizing continuous prompts for generation. *arXiv preprint arXiv:2101.00190*.
<!-- END -->