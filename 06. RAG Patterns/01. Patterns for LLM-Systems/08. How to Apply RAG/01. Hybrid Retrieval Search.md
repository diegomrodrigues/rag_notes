## Recupera√ß√£o H√≠brida: Combinando Abordagens Tradicionais e Sem√¢nticas em RAG

### Introdu√ß√£o

Em sistemas de Recupera√ß√£o Aumentada de Gera√ß√£o (RAG), a fase de recupera√ß√£o desempenha um papel crucial na qualidade e relev√¢ncia das respostas geradas pelos modelos de linguagem grandes (LLMs). Enquanto a recupera√ß√£o baseada em embeddings (semantic search) tem ganho destaque, a combina√ß√£o desta com m√©todos tradicionais, como o BM25, frequentemente oferece resultados superiores. Este cap√≠tulo explora o conceito de **recupera√ß√£o h√≠brida**, detalhando as vantagens de complementar a busca cl√°ssica com a busca sem√¢ntica e fornecendo insights sobre a sua aplica√ß√£o pr√°tica [^1].

### Conceitos Fundamentais

A **recupera√ß√£o h√≠brida** √© uma estrat√©gia que visa combinar os pontos fortes de diferentes m√©todos de recupera√ß√£o para obter resultados mais robustos e precisos. Tradicionalmente, algoritmos como o **BM25** (Best Matching 25) t√™m sido utilizados para indexar e recuperar documentos baseando-se na frequ√™ncia de termos e no comprimento dos documentos. Estes m√©todos s√£o eficientes e bem compreendidos, mas podem falhar em capturar nuances sem√¢nticas e rela√ß√µes contextuais entre os termos [^1].

> üí° **Exemplo Num√©rico: BM25**
>
> Considere dois documentos e uma consulta:
>
> *   **Documento 1:** "O imposto de renda √© um tributo federal."
> *   **Documento 2:** "C√°lculo do IRPF para pessoa f√≠sica."
> *   **Consulta:** "Imposto de renda"
>
> Para simplificar, vamos ignorar o comprimento dos documentos e focar na frequ√™ncia dos termos. Suponha que o BM25 atribui um score maior a documentos que cont√™m os termos da consulta. Neste caso, o Documento 1 e o Documento 2 s√£o relevantes, mas o BM25 pode favorecer o Documento 1, pois cont√©m os termos exatos da consulta, enquanto o Documento 2, embora relevante, usa a abrevia√ß√£o "IRPF".
>
> Um exemplo simplificado de c√°lculo de BM25 (sem os detalhes da f√≥rmula completa) pode ser:
>
> $\text{BM25 Score (Doc1)} = \text{frequ√™ncia("imposto", Doc1)} + \text{frequ√™ncia("de", Doc1)} + \text{frequ√™ncia("renda", Doc1)} = 1 + 1 + 1 = 3$
>
> $\text{BM25 Score (Doc2)} = \text{frequ√™ncia("imposto", Doc2)} + \text{frequ√™ncia("de", Doc2)} + \text{frequ√™ncia("renda", Doc2)} = 0 + 1 + 0 = 1 + \text{frequ√™ncia("IRPF", Doc2)} = 1$.
>
> Portanto, BM25(Doc1) > BM25(Doc2)

Por outro lado, a **busca sem√¢ntica**, que utiliza embeddings vetoriais para representar documentos e consultas, permite capturar o significado por tr√°s das palavras. Modelos como o **e5-small-v2** s√£o treinados para gerar embeddings que refletem a sem√¢ntica do texto, possibilitando a recupera√ß√£o de documentos relevantes mesmo que n√£o contenham os mesmos termos exatos da consulta [^1].

> üí° **Exemplo Num√©rico: Busca Sem√¢ntica com Embeddings**
>
> Suponha que temos as seguintes representa√ß√µes vetoriais (embeddings) para a consulta e os documentos do exemplo anterior:
>
> *   **Consulta Embedding:** `[0.2, 0.5, 0.1, 0.7]`
> *   **Documento 1 Embedding:** `[0.3, 0.4, 0.2, 0.6]`
> *   **Documento 2 Embedding:** `[0.1, 0.6, 0.0, 0.8]`
>
> Podemos calcular a similaridade de cosseno entre a consulta e cada documento:
>
> $\text{Cosine Similarity (Consulta, Doc1)} = \frac{(0.2*0.3 + 0.5*0.4 + 0.1*0.2 + 0.7*0.6)}{\sqrt{(0.2^2 + 0.5^2 + 0.1^2 + 0.7^2)} * \sqrt{(0.3^2 + 0.4^2 + 0.2^2 + 0.6^2)}} \approx 0.965$
>
> $\text{Cosine Similarity (Consulta, Doc2)} = \frac{(0.2*0.1 + 0.5*0.6 + 0.1*0.0 + 0.7*0.8)}{\sqrt{(0.2^2 + 0.5^2 + 0.1^2 + 0.7^2)} * \sqrt{(0.1^2 + 0.6^2 + 0.0^2 + 0.8^2)}} \approx 0.985$
>
> Neste caso, a busca sem√¢ntica atribui uma maior similaridade ao Documento 2, capturando a sua relev√¢ncia mesmo que n√£o contenha os termos exatos da consulta.

A **complementaridade** entre estes dois m√©todos reside no fato de que o BM25 se destaca na identifica√ß√£o de documentos que cont√™m os termos da consulta com alta frequ√™ncia, enquanto a busca sem√¢ntica √© capaz de encontrar documentos que abordam o mesmo t√≥pico, mesmo que usem uma linguagem diferente. Ao combinar estes dois m√©todos, √© poss√≠vel mitigar as limita√ß√µes de cada um e obter um conjunto de resultados mais abrangente e relevante [^1].

**Exemplo:** Considere uma consulta como "como calcular o imposto de renda?". Um sistema baseado apenas em BM25 procuraria por documentos que cont√™m as palavras "calcular", "imposto" e "renda". Um sistema baseado em embeddings procuraria por documentos semanticamente relacionados, mesmo que usem sin√¥nimos ou frases diferentes para expressar a mesma ideia. Um sistema h√≠brido combinaria os resultados de ambos, priorizando documentos que s√£o relevantes tanto em termos de palavras-chave quanto de significado.

**Implementa√ß√£o da Recupera√ß√£o H√≠brida:**

A implementa√ß√£o da recupera√ß√£o h√≠brida envolve os seguintes passos:

1.  **Indexa√ß√£o:** Indexar os documentos utilizando tanto um √≠ndice tradicional (e.g., OpenSearch com BM25) quanto um √≠ndice vetorial (e.g., utilizando FAISS ou Annoy com embeddings gerados por um modelo como e5-small-v2) [^1].
2.  **Consulta:** Ao receber uma consulta, realizar tanto a busca tradicional quanto a busca sem√¢ntica, obtendo dois conjuntos de resultados [^1].
3.  **Combina√ß√£o:** Combinar os dois conjuntos de resultados utilizando uma estrat√©gia de *re-ranking* ou *fusion*.

**Estrat√©gias de Combina√ß√£o:**

Existem diversas estrat√©gias para combinar os resultados da busca tradicional e da busca sem√¢ntica. Algumas das mais comuns incluem:

*   **Re-ranking:** Utilizar um modelo para reordenar os resultados da busca tradicional, levando em conta a similaridade sem√¢ntica dos documentos em rela√ß√£o √† consulta. Por exemplo, os resultados obtidos pelo BM25 podem ser reordenados com base em um escore calculado a partir da similaridade dos embeddings do documento e da consulta.
*   **Fusion:** Combinar os resultados da busca tradicional e da busca sem√¢ntica utilizando uma fun√ß√£o de agrega√ß√£o. Uma abordagem comum √© o **Reciprocal Rank Fusion (RRF)**, que atribui um peso maior aos documentos que aparecem nas primeiras posi√ß√µes de cada lista [^1].  O RRF √© definido como:

$$RRF\_score(d) = \sum_{i=1}^{k} \frac{1}{rank_i(d) + k}$$

onde $rank_i(d)$ √© a posi√ß√£o do documento $d$ na lista de resultados do sistema $i$, e $k$ √© um par√¢metro que controla a influ√™ncia das posi√ß√µes mais altas.

> üí° **Exemplo Num√©rico: Reciprocal Rank Fusion (RRF)**
>
> Suponha que temos os seguintes rankings para dois documentos (Doc1 e Doc2) vindos de dois sistemas de recupera√ß√£o (BM25 e Busca Sem√¢ntica):
>
> | Documento | BM25 Rank | Busca Sem√¢ntica Rank |
> | --------- | --------- | -------------------- |
> | Doc1      | 1         | 3                    |
> | Doc2      | 2         | 1                    |
>
> Usando RRF com $k = 2$:
>
> $RRF\_score(Doc1) = \frac{1}{1 + 2} + \frac{1}{3 + 2} = \frac{1}{3} + \frac{1}{5} = 0.33 + 0.2 = 0.53$
>
> $RRF\_score(Doc2) = \frac{1}{2 + 2} + \frac{1}{1 + 2} = \frac{1}{4} + \frac{1}{3} = 0.25 + 0.33 = 0.58$
>
> Neste caso, o RRF atribui um score ligeiramente maior ao Documento 2, dando mais peso ao fato de que ele est√° na primeira posi√ß√£o na busca sem√¢ntica.

Para complementar a discuss√£o sobre estrat√©gias de combina√ß√£o, podemos introduzir uma outra t√©cnica comum:

*   **Weighted Sum:** Esta t√©cnica atribui pesos diferentes aos scores obtidos pelos m√©todos de busca tradicional e sem√¢ntica, combinando-os em um √∫nico score final. A f√≥rmula geral para a soma ponderada √©:

$$Score(d) = w_1 \cdot BM25\_score(d) + w_2 \cdot Semantic\_score(d)$$

onde $w_1$ e $w_2$ s√£o os pesos atribu√≠dos aos scores do BM25 e da busca sem√¢ntica, respectivamente, e a soma de $w_1$ e $w_2$ deve ser igual a 1. A escolha dos pesos $w_1$ e $w_2$ pode ser feita atrav√©s de experimenta√ß√£o ou otimiza√ß√£o em um conjunto de dados de valida√ß√£o.

> üí° **Exemplo Num√©rico: Weighted Sum**
>
> Suponha que temos os seguintes scores normalizados para dois documentos (Doc1 e Doc2) vindos de dois sistemas de recupera√ß√£o (BM25 e Busca Sem√¢ntica):
>
> | Documento | BM25 Score | Busca Sem√¢ntica Score |
> | --------- | ---------- | --------------------- |
> | Doc1      | 0.8        | 0.3                     |
> | Doc2      | 0.5        | 0.9                     |
>
> Usando Weighted Sum com $w_1 = 0.6$ e $w_2 = 0.4$:
>
> $Score(Doc1) = 0.6 * 0.8 + 0.4 * 0.3 = 0.48 + 0.12 = 0.60$
>
> $Score(Doc2) = 0.6 * 0.5 + 0.4 * 0.9 = 0.30 + 0.36 = 0.66$
>
> Neste caso, o Weighted Sum atribui um score maior ao Documento 2, refletindo a import√¢ncia da busca sem√¢ntica neste cen√°rio. A escolha dos pesos impacta diretamente no resultado final e deve ser ajustada de acordo com as caracter√≠sticas do dataset.

**Vantagens da Recupera√ß√£o H√≠brida:**

*   **Maior precis√£o:** Ao combinar diferentes m√©todos, a recupera√ß√£o h√≠brida tende a produzir resultados mais precisos e relevantes.
*   **Maior robustez:** A combina√ß√£o de m√©todos mitiga as limita√ß√µes de cada um, tornando o sistema mais robusto a varia√ß√µes na linguagem e no estilo de escrita.
*   **Melhor cobertura:** A recupera√ß√£o h√≠brida √© capaz de encontrar documentos que seriam perdidos por m√©todos individuais, aumentando a cobertura do sistema.

Para analisar mais a fundo a performance da recupera√ß√£o h√≠brida, podemos definir algumas m√©tricas relevantes.

**M√©tricas para Avalia√ß√£o da Recupera√ß√£o H√≠brida:**

A avalia√ß√£o da efic√°cia de um sistema de recupera√ß√£o h√≠brida requer o uso de m√©tricas adequadas. Algumas das m√©tricas mais comuns incluem:

*   **Precis√£o@K (Precision@K):** A precis√£o@K mede a propor√ß√£o de documentos relevantes entre os K primeiros documentos recuperados. √â definida como:

$$Precision@K = \frac{\text{N√∫mero de documentos relevantes nos K primeiros resultados}}{K}$$

*   **Recall@K (Recall@K):** O recall@K mede a propor√ß√£o de documentos relevantes que foram recuperados entre os K primeiros documentos. √â definido como:

$$Recall@K = \frac{\text{N√∫mero de documentos relevantes recuperados nos K primeiros resultados}}{\text{N√∫mero total de documentos relevantes}}$$

*   **Mean Average Precision (MAP):** O MAP calcula a m√©dia das precis√µes m√©dias para um conjunto de consultas. A precis√£o m√©dia para uma consulta √© a m√©dia das precis√µes em cada ponto em que um documento relevante √© recuperado.

*   **Normalized Discounted Cumulative Gain (NDCG):** O NDCG mede a relev√¢ncia dos documentos recuperados, dando mais peso aos documentos relevantes que aparecem nas primeiras posi√ß√µes. Ele leva em considera√ß√£o a ordem dos resultados e atribui um ganho maior aos documentos mais relevantes nas primeiras posi√ß√µes.

> üí° **Exemplo Num√©rico: Precision@K, Recall@K, MAP, e NDCG**
>
> Considere uma consulta e os seguintes resultados de um sistema de recupera√ß√£o, onde 'R' indica um documento relevante e 'N' indica um documento n√£o relevante:
>
> `[R, N, R, N, N, R, N, R, N, N]`
>
> Avaliando para K = 5:
>
> *   Precision@5 = (N√∫mero de documentos relevantes nos 5 primeiros resultados) / 5 = 2 / 5 = 0.4
> *   Recall@5 = (N√∫mero de documentos relevantes recuperados nos 5 primeiros resultados) / (N√∫mero total de documentos relevantes)
>
> Suponha que existam 5 documentos relevantes no total. Ent√£o, Recall@5 = 2 / 5 = 0.4
>
> Para calcular MAP, precisamos da precis√£o em cada posi√ß√£o onde um documento relevante √© encontrado:
>
> *   Precis√£o no primeiro documento relevante (posi√ß√£o 1): 1/1 = 1.0
> *   Precis√£o no segundo documento relevante (posi√ß√£o 3): 2/3 = 0.67
> *   Precis√£o no terceiro documento relevante (posi√ß√£o 6): 3/6 = 0.5
> *   Precis√£o no quarto documento relevante (posi√ß√£o 8): 4/8 = 0.5
>
> Average Precision (AP) = (1.0 + 0.67 + 0.5 + 0.5) / 4 = 0.6675
>
> Se tivermos v√°rias consultas, o MAP √© a m√©dia dos APs de cada consulta.
>
> Para o c√°lculo do NDCG, √© necess√°rio atribuir um ganho (relev√¢ncia) para cada documento. Suponha que documentos relevantes t√™m ganho 1 e n√£o relevantes t√™m ganho 0. O DCG √© calculado como:
>
> $DCG = \sum_{i=1}^{K} \frac{rel_i}{\log_2(i+1)}$
>
> $DCG@5 = \frac{1}{\log_2(1+1)} + \frac{0}{\log_2(2+1)} + \frac{1}{\log_2(3+1)} + \frac{0}{\log_2(4+1)} + \frac{0}{\log_2(5+1)} = 1 + 0 + 0.5 + 0 + 0 = 1.5$
>
> O ideal DCG (IDCG) √© calculado ordenando os documentos por relev√¢ncia:
>
> $IDCG@5 = \frac{1}{\log_2(1+1)} + \frac{1}{\log_2(2+1)} + \frac{1}{\log_2(3+1)} + \frac{0}{\log_2(4+1)} + \frac{0}{\log_2(5+1)} = 1 + 0.63 + 0.5 = 2.13$
>
> $NDCG@5 = \frac{DCG@5}{IDCG@5} = \frac{1.5}{2.13} = 0.70$
>
> Essas m√©tricas ajudam a quantificar a efic√°cia do sistema de recupera√ß√£o. Uma an√°lise comparativa entre diferentes sistemas ou configura√ß√µes pode ser feita utilizando estes resultados.

A escolha da m√©trica apropriada depende dos objetivos espec√≠ficos do sistema de recupera√ß√£o e da natureza dos dados.

### Conclus√£o

A recupera√ß√£o h√≠brida representa uma abordagem eficaz para melhorar a qualidade da fase de recupera√ß√£o em sistemas RAG. Ao combinar a precis√£o e efici√™ncia dos m√©todos tradicionais com a capacidade de compreens√£o sem√¢ntica da busca baseada em embeddings, √© poss√≠vel obter resultados mais robustos e relevantes. A escolha da estrat√©gia de combina√ß√£o e dos modelos espec√≠ficos a serem utilizados depender√° das caracter√≠sticas do dom√≠nio e dos dados, mas a recupera√ß√£o h√≠brida se consolida como uma pr√°tica recomendada para sistemas RAG de alto desempenho [^1].

### Refer√™ncias

[^1]: Informa√ß√£o presente no contexto: "Hybrid retrieval (traditional search index + embedding-based search) often works better than either alone. Complementing classic retrieval (BM25 via OpenSearch) with semantic search (e.g., e5-small-v2) is a common and effective approach."
<!-- END -->