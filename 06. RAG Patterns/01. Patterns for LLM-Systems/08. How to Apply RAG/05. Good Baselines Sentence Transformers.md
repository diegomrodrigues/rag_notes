## Sentence-Transformers como Baselines Eficazes em RAG

### Introdu√ß√£o
A efic√°cia dos sistemas Retrieval-Augmented Generation (RAG) depende crucialmente da qualidade da etapa de recupera√ß√£o (retrieval). Para avaliar e otimizar o desempenho de um sistema RAG, √© essencial estabelecer baselines s√≥lidas [^5]. **Sentence-transformers** emergem como uma op√ß√£o proeminente devido √† sua capacidade de simplificar a computa√ß√£o de embeddings para diversos tipos de dados, como senten√ßas, par√°grafos e at√© imagens. Este cap√≠tulo detalha a relev√¢ncia dos sentence-transformers como baselines, explorando suas caracter√≠sticas, aplica√ß√µes e vantagens no contexto de sistemas RAG.

### Conceitos Fundamentais
**Sentence-transformers** s√£o modelos de *transformers* projetados especificamente para gerar embeddings de alta qualidade para textos, capturando o significado sem√¢ntico de senten√ßas e par√°grafos [^5]. Eles s√£o baseados em arquiteturas amplamente utilizadas, como **BERT** e **RoBERTa**, e est√£o dispon√≠veis em mais de 100 idiomas, tornando-os altamente vers√°teis e aplic√°veis em diversos cen√°rios multilingu√≠sticos [^5].

A principal vantagem dos sentence-transformers reside na sua capacidade de gerar embeddings que podem ser comparados de forma eficiente usando medidas de similaridade, como a similaridade do cosseno. Isso simplifica a tarefa de encontrar os documentos mais relevantes para uma determinada query em um sistema RAG.

> üí° **Exemplo Num√©rico:** Suponha que temos dois documentos: Documento 1: "O gato est√° no tapete." e Documento 2: "O cachorro est√° dormindo na cama.". Ap√≥s passarmos esses documentos por um sentence-transformer, obtemos os seguintes embeddings (representados aqui como vetores simplificados de duas dimens√µes para ilustra√ß√£o):
>
> Embedding do Documento 1: $\vec{d_1} = [0.8, 0.6]$
>
> Embedding do Documento 2: $\vec{d_2} = [0.2, 0.9]$
>
> Agora, considere uma query: "Onde o gato est√°?". O sentence-transformer gera o seguinte embedding para a query: $\vec{q} = [0.7, 0.5]$.
>
> Para calcular a similaridade do cosseno entre a query e cada documento, usamos a f√≥rmula:
>
> $\text{Cosine Similarity}(\vec{a}, \vec{b}) = \frac{\vec{a} \cdot \vec{b}}{||\vec{a}|| \cdot ||\vec{b}||}$
>
> $\text{Cosine Similarity}(\vec{q}, \vec{d_1}) = \frac{(0.7 \cdot 0.8) + (0.5 \cdot 0.6)}{\sqrt{0.7^2 + 0.5^2} \cdot \sqrt{0.8^2 + 0.6^2}} = \frac{0.56 + 0.30}{\sqrt{0.74} \cdot \sqrt{1}} = \frac{0.86}{0.86} \approx 0.997$
>
> $\text{Cosine Similarity}(\vec{q}, \vec{d_2}) = \frac{(0.7 \cdot 0.2) + (0.5 \cdot 0.9)}{\sqrt{0.7^2 + 0.5^2} \cdot \sqrt{0.2^2 + 0.9^2}} = \frac{0.14 + 0.45}{\sqrt{0.74} \cdot \sqrt{0.85}} = \frac{0.59}{0.86 \cdot 0.92} \approx 0.745$
>
> Neste caso, a similaridade do cosseno entre a query e o Documento 1 (0.997) √© maior do que a similaridade entre a query e o Documento 2 (0.745). Portanto, o sistema RAG recuperaria o Documento 1 como o mais relevante para a query.

Para entender melhor, vamos analisar os passos envolvidos no uso de sentence-transformers como baseline:

1.  **Indexa√ß√£o:** Inicialmente, cada documento no corpus √© processado pelo sentence-transformer para gerar um embedding vetorial. Esses embeddings s√£o ent√£o indexados em uma estrutura de dados eficiente para busca vetorial, como FAISS ou Annoy.
2.  **Consulta:** Quando uma query √© recebida, ela tamb√©m √© processada pelo mesmo sentence-transformer para gerar um embedding de query.
3.  **Recupera√ß√£o:** O embedding da query √© usado para buscar os embeddings de documentos mais similares na estrutura de dados indexada. A similaridade do cosseno √© comumente usada para medir a similaridade entre os embeddings da query e dos documentos.
4.  **Gera√ß√£o:** Os documentos recuperados s√£o ent√£o combinados com a query original e alimentados em um LLM para gerar a resposta final.

A escolha de sentence-transformers como baseline oferece diversas vantagens:

*   **Simplicidade:** A implementa√ß√£o √© relativamente simples, permitindo uma r√°pida prototipagem e avalia√ß√£o do sistema RAG.
*   **Efici√™ncia:** Os sentence-transformers s√£o otimizados para gerar embeddings de forma eficiente, o que √© crucial para sistemas RAG que precisam processar grandes volumes de dados.
*   **Desempenho:** Os sentence-transformers alcan√ßam um desempenho competitivo em diversas tarefas de recupera√ß√£o de informa√ß√£o, tornando-os uma escolha s√≥lida como baseline.
*   **Multilinguismo:** A disponibilidade em mais de 100 idiomas permite a constru√ß√£o de sistemas RAG multilingu√≠sticos.

Para ilustrar, considere a seguinte situa√ß√£o. Temos um sistema RAG que visa responder perguntas sobre artigos cient√≠ficos. Usando sentence-transformers, podemos indexar os embeddings de todos os artigos em nossa base de dados. Quando um usu√°rio faz uma pergunta, calculamos o embedding dessa pergunta e buscamos os artigos mais relevantes com base na similaridade do cosseno entre os embeddings. Esses artigos s√£o ent√£o usados para fornecer contexto ao LLM, que gera a resposta final para o usu√°rio.



![RAG architecture: Enhancing language models with external knowledge retrieval for improved answer generation.](./../images/image17.jpg)

**Teorema 1:** A utiliza√ß√£o da similaridade do cosseno entre embeddings gerados por sentence-transformers para recupera√ß√£o de documentos em sistemas RAG garante que os documentos semanticamente mais relevantes sejam priorizados, desde que o sentence-transformer seja treinado adequadamente para o dom√≠nio espec√≠fico.

*Proof:* A similaridade do cosseno mede o √¢ngulo entre dois vetores. No contexto de embeddings de sentence-transformers, vetores com menor √¢ngulo (maior similaridade do cosseno) representam textos semanticamente mais similares. Portanto, ao priorizar documentos com maior similaridade do cosseno em rela√ß√£o √† query, o sistema RAG tende a recuperar documentos que abordam o mesmo t√≥pico ou conceito da query. A condi√ß√£o de treinamento adequado do sentence-transformer para o dom√≠nio espec√≠fico √© crucial, pois um modelo mal treinado pode gerar embeddings que n√£o refletem a verdadeira similaridade sem√¢ntica entre os textos.

**Lema 1.1:** A qualidade dos embeddings gerados por sentence-transformers √© diretamente proporcional √† qualidade e quantidade dos dados de treinamento utilizados para ajustar o modelo.

*Proof:* (Sketch) Sentence-transformers s√£o modelos de aprendizado profundo que ajustam seus par√¢metros para mapear textos em vetores de embeddings. A capacidade do modelo de capturar a sem√¢ntica do texto depende da informa√ß√£o contida nos dados de treinamento. Dados de treinamento de alta qualidade e em grande quantidade fornecem ao modelo uma representa√ß√£o mais completa e precisa do dom√≠nio do texto, resultando em embeddings mais informativos e semanticamente relevantes.

Al√©m disso, √© importante considerar as limita√ß√µes dos sentence-transformers. Eles podem ter dificuldades em lidar com consultas complexas que envolvem racioc√≠nio sobre m√∫ltiplas fontes de informa√ß√£o. Nesses casos, t√©cnicas mais avan√ßadas de recupera√ß√£o, como a recupera√ß√£o baseada em grafos de conhecimento, podem ser mais adequadas.

**Teorema 1.2:** Para consultas complexas que exigem racioc√≠nio sobre m√∫ltiplas fontes de informa√ß√£o, a combina√ß√£o de sentence-transformers com t√©cnicas de recupera√ß√£o baseadas em grafos de conhecimento pode superar o desempenho de sentence-transformers isoladamente.

*Proof:* (Sketch) Sentence-transformers, por si s√≥, capturam principalmente a similaridade sem√¢ntica direta entre textos. T√©cnicas baseadas em grafos de conhecimento, por outro lado, permitem modelar rela√ß√µes complexas entre entidades e conceitos. Ao combinar as duas abordagens, o sistema RAG pode primeiro usar sentence-transformers para recuperar documentos relevantes com base na similaridade sem√¢ntica e, em seguida, usar o grafo de conhecimento para identificar rela√ß√µes adicionais e infer√™ncias relevantes para responder √† consulta complexa.

> üí° **Exemplo Num√©rico:** Considere uma consulta: "Quais s√£o os efeitos da vacina X no tratamento da doen√ßa Y em pacientes idosos com diabetes?". Um sentence-transformer pode recuperar documentos que mencionam "vacina X", "doen√ßa Y", "pacientes idosos" e "diabetes" separadamente. No entanto, um grafo de conhecimento poderia conectar essas entidades e identificar documentos que discutem especificamente a intera√ß√£o entre todos esses fatores, o que um sentence-transformer isoladamente poderia n√£o conseguir.

√â crucial tamb√©m considerar a escolha do modelo sentence-transformer espec√≠fico para a tarefa em quest√£o. Modelos pr√©-treinados em grandes corpora gen√©ricos podem n√£o ser ideais para dom√≠nios espec√≠ficos. Nesses casos, o fine-tuning do modelo em dados espec√≠ficos do dom√≠nio pode melhorar significativamente o desempenho do sistema RAG.

**Proposi√ß√£o 1.3:** O fine-tuning de um sentence-transformer pr√©-treinado em dados espec√≠ficos do dom√≠nio resulta em um aumento na precis√£o e relev√¢ncia dos documentos recuperados para consultas relacionadas a esse dom√≠nio.

*Proof:* (Sketch) O fine-tuning adapta os par√¢metros do modelo pr√©-treinado para melhor representar as caracter√≠sticas espec√≠ficas do dom√≠nio em quest√£o. Ao treinar o modelo em dados relevantes para o dom√≠nio, ele aprende a gerar embeddings que capturam as nuances e a terminologia espec√≠ficas desse dom√≠nio, resultando em uma melhor correspond√™ncia entre as consultas e os documentos relevantes.

> üí° **Exemplo Num√©rico:** Imagine que estamos construindo um sistema RAG para responder perguntas sobre literatura jur√≠dica brasileira. Um sentence-transformer gen√©rico pode n√£o estar familiarizado com a terminologia espec√≠fica utilizada em textos jur√≠dicos. Ao fazer o fine-tuning desse modelo com uma cole√ß√£o de artigos e decis√µes judiciais brasileiras, o modelo se tornar√° mais apto a identificar documentos relevantes para consultas sobre temas jur√≠dicos espec√≠ficos.
>
> Suponha que, antes do fine-tuning, uma consulta como "O que √© o princ√≠pio da legalidade?" retornasse documentos gen√©ricos sobre o conceito de legalidade. Ap√≥s o fine-tuning, o sistema retornaria documentos espec√≠ficos sobre a aplica√ß√£o do princ√≠pio da legalidade no direito brasileiro, citando artigos da Constitui√ß√£o e exemplos de jurisprud√™ncia.
>
> Para quantificar essa melhoria, podemos medir a precis√£o e o recall do sistema antes e depois do fine-tuning:
>
> | M√©trica     | Antes do Fine-tuning | Ap√≥s o Fine-tuning |
> |-------------|----------------------|----------------------|
> | Precis√£o    | 0.6                  | 0.85                 |
> | Recall      | 0.5                  | 0.75                 |
>
> Isso indica que o fine-tuning aumentou a capacidade do sistema de retornar documentos relevantes (recall) e a propor√ß√£o de documentos retornados que s√£o realmente relevantes (precis√£o).

### Conclus√£o

Sentence-transformers representam uma baseline eficaz e acess√≠vel para sistemas Retrieval-Augmented Generation. Sua capacidade de simplificar a gera√ß√£o de embeddings de alta qualidade, combinada com sua efici√™ncia e disponibilidade em m√∫ltiplos idiomas, os torna uma ferramenta valiosa para a prototipagem, avalia√ß√£o e otimiza√ß√£o de sistemas RAG. Ao estabelecer sentence-transformers como baseline, podemos avaliar o impacto de t√©cnicas mais avan√ßadas e identificar √°reas para melhoria no processo de recupera√ß√£o, contribuindo para o desenvolvimento de sistemas RAG mais robustos e precisos.

### Refer√™ncias
[^5]: Sentence-transformers simplify the computation of embeddings for sentences, paragraphs, and even images. They are based on workhorse transformers like BERT and ROBERTa and are available in over 100 languages.
<!-- END -->