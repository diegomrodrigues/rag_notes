## Caching em Retrieval-Augmented Generation: Redu√ß√£o de Lat√™ncia e Custo

### Introdu√ß√£o
O uso de **caching** √© uma t√©cnica fundamental para otimizar sistemas de *Retrieval-Augmented Generation* (RAG) que utilizam *Large Language Models* (LLMs). Em ess√™ncia, o caching visa armazenar dados previamente computados ou recuperados, permitindo que solicita√ß√µes futuras pelos mesmos dados sejam atendidas de forma mais r√°pida e eficiente [^1]. Este cap√≠tulo explorar√° os princ√≠pios do caching, suas aplica√ß√µes espec√≠ficas em sistemas RAG e os benef√≠cios que ele oferece em termos de redu√ß√£o de lat√™ncia e custo.

### Conceitos Fundamentais
O **caching** √© uma estrat√©gia amplamente utilizada em diversas √°reas da computa√ß√£o, desde sistemas de hardware at√© aplica√ß√µes de software complexas. O princ√≠pio b√°sico √© simples: em vez de recalcular ou recuperar dados repetidamente, armazene os resultados em um local de acesso r√°pido (o *cache*) e, quando a mesma solicita√ß√£o for feita novamente, sirva os dados diretamente do cache.

Em sistemas RAG, o caching pode ser aplicado em v√°rias etapas do processo, incluindo:

*   **Caching de Resultados de Recupera√ß√£o:** A fase de *retrieval* em RAG envolve a busca por documentos relevantes em um √≠ndice de conhecimento. Se a mesma consulta for feita repetidamente, os resultados da busca podem ser armazenados em cache. Isso evita a necessidade de realizar a busca novamente, reduzindo a lat√™ncia e o custo computacional.
*   **Caching de Embeddings:** O processo de transformar texto em representa√ß√µes vetoriais (embeddings) √© computacionalmente intensivo. Se os embeddings para determinados trechos de texto j√° foram calculados, eles podem ser armazenados em cache para uso futuro.
*   **Caching de Respostas Geradas:** As respostas geradas pelos LLMs tamb√©m podem ser armazenadas em cache. Se a mesma pergunta for feita repetidamente, a resposta armazenada em cache pode ser retornada instantaneamente, sem a necessidade de consultar o LLM novamente.

> üí° **Exemplo Num√©rico:** Imagine um sistema RAG que responde perguntas sobre documentos de texto. Se a pergunta "Qual a capital da Fran√ßa?" √© feita, o sistema consulta os documentos, gera a resposta "Paris" e armazena a pergunta e a resposta no cache. Se a mesma pergunta for feita novamente, o sistema retorna "Paris" diretamente do cache, sem precisar consultar os documentos ou o LLM. Isso economiza tempo e recursos computacionais.

**Benef√≠cios do Caching:**

*   **Redu√ß√£o de Lat√™ncia:** O principal benef√≠cio do caching √© a redu√ß√£o da lat√™ncia. Servir dados do cache √© significativamente mais r√°pido do que recalcular ou recuperar os dados originais. Isso √© especialmente importante em aplica√ß√µes interativas, onde os usu√°rios esperam respostas r√°pidas.
*   **Redu√ß√£o de Custo:** A redu√ß√£o da lat√™ncia tamb√©m leva √† redu√ß√£o do custo. Ao evitar a necessidade de realizar c√°lculos ou buscas repetidas, o caching reduz o uso de recursos computacionais, como CPU, mem√≥ria e largura de banda. Em sistemas baseados em nuvem, isso pode se traduzir em economias significativas.
*   **Escalabilidade:** O caching pode melhorar a escalabilidade de sistemas RAG. Ao reduzir a carga nos componentes mais lentos do sistema, o caching permite que o sistema suporte um n√∫mero maior de usu√°rios e solicita√ß√µes.

> üí° **Exemplo Num√©rico:** Suponha que uma consulta ao LLM custe \$0.01 e leve 1 segundo. Se o caching reduzir o n√∫mero de consultas ao LLM em 50%, o custo total ser√° reduzido em 50%, e a lat√™ncia m√©dia ser√° reduzida. Se 1000 consultas s√£o feitas, o custo original seria \$10 e 1000 segundos. Com caching de 50%, o custo seria \$5 e a lat√™ncia *efetiva* cairia.

**Estrat√©gias de Caching:**

Existem diversas estrat√©gias de caching que podem ser utilizadas em sistemas RAG. Algumas das mais comuns incluem:

*   **Cache baseado em chave:** A estrat√©gia mais simples √© usar a consulta (ou um hash da consulta) como a chave do cache. Quando uma consulta √© feita, o sistema verifica se a chave correspondente existe no cache. Se existir, os dados armazenados s√£o retornados. Caso contr√°rio, os dados s√£o calculados ou recuperados, armazenados no cache e, em seguida, retornados.
*   **Cache baseado em tempo:** Os dados armazenados no cache podem ser invalidados ap√≥s um determinado per√≠odo de tempo. Isso garante que o cache n√£o fique obsoleto e que os usu√°rios recebam informa√ß√µes atualizadas.
*   **Cache baseado em frequ√™ncia:** Os dados que s√£o acessados com mais frequ√™ncia s√£o mantidos no cache por mais tempo. Isso garante que os dados mais relevantes estejam sempre dispon√≠veis de forma r√°pida.
*   **Cache distribu√≠do:** Em sistemas RAG de grande escala, o cache pode ser distribu√≠do em v√°rios servidores. Isso permite que o sistema lide com um n√∫mero maior de solicita√ß√µes e garante que o cache esteja sempre dispon√≠vel, mesmo se um servidor falhar.

> üí° **Exemplo Num√©rico:** Considere um cache baseado em tempo com um tempo de vida (TTL) de 1 hora. Se uma pergunta for feita √†s 9:00, a resposta ser√° armazenada no cache at√© as 10:00. Se a mesma pergunta for feita novamente √†s 9:30, a resposta ser√° retornada do cache. Se for feita novamente √†s 10:30, a resposta ter√° que ser recalculada, pois o TTL expirou.

**Lema 1:** *Cache baseado em frequ√™ncia com limiar.* Uma estrat√©gia de cache baseada em frequ√™ncia pode ser aprimorada com um limiar m√≠nimo de acessos. Dados s√≥ s√£o adicionados ao cache se sua frequ√™ncia de acesso exceder este limiar.

*Proof:* Esta estrat√©gia combina os benef√≠cios do cache baseado em frequ√™ncia, evitando que dados raramente acessados ocupem espa√ßo no cache. Ao exigir um n√∫mero m√≠nimo de acessos antes de adicionar um item ao cache, asseguramos que apenas dados com alta probabilidade de serem reutilizados sejam armazenados.

> üí° **Exemplo Num√©rico:** Imagine que um sistema registra a frequ√™ncia de acesso a diferentes consultas. Definimos um limiar de 5 acessos. Se uma consulta for feita 3 vezes em um dia, ela n√£o ser√° adicionada ao cache. Se outra consulta for feita 7 vezes no mesmo dia, ela ser√° adicionada ao cache.

**Implementa√ß√£o do Caching:**

A implementa√ß√£o do caching pode ser feita de diversas formas, dependendo da arquitetura do sistema RAG e dos requisitos espec√≠ficos da aplica√ß√£o. Algumas op√ß√µes comuns incluem:

*   **Caches em mem√≥ria:** O cache √© armazenado na mem√≥ria do servidor. Essa op√ß√£o √© a mais r√°pida, mas tamb√©m a mais cara, pois a mem√≥ria √© um recurso limitado. Exemplos incluem o uso de dicion√°rios em Python ou bibliotecas de caching como `cachetools`.
*   **Caches em disco:** O cache √© armazenado no disco r√≠gido do servidor. Essa op√ß√£o √© mais barata do que o caching em mem√≥ria, mas tamb√©m mais lenta. Exemplos incluem o uso de bancos de dados NoSQL como Redis ou Memcached.
*   **Caches distribu√≠dos:** O cache √© distribu√≠do em v√°rios servidores. Essa op√ß√£o √© a mais escal√°vel, mas tamb√©m a mais complexa de implementar. Exemplos incluem o uso de servi√ßos de caching como Amazon ElastiCache ou Google Cloud Memorystore.



![A caching system architecture for LLM-based applications using embedding similarity.](./../images/image3.jpg)

> üí° **Exemplo Num√©rico:** Considere um sistema que usa um cache em mem√≥ria (RAM) com capacidade de 10GB e um cache em disco (SSD) com capacidade de 100GB. O cache em mem√≥ria √© usado para armazenar as respostas mais recentes e mais frequentemente acessadas, enquanto o cache em disco √© usado para armazenar um hist√≥rico maior de respostas.

**Teorema 1:** *Impacto do tamanho do cache na taxa de acerto (hit rate).* A taxa de acerto do cache (propor√ß√£o de requisi√ß√µes atendidas pelo cache) aumenta monotonicamente com o tamanho do cache, at√© um ponto de satura√ß√£o.

*Proof (Estrat√©gia):* Inicialmente, √† medida que o tamanho do cache aumenta, mais dados podem ser armazenados, elevando a probabilidade de encontrar a informa√ß√£o desejada no cache. No entanto, ap√≥s um determinado ponto, o cache come√ßa a armazenar dados menos frequentemente acessados, o que contribui menos para a taxa de acerto e eventualmente leva a um ganho marginal decrescente no desempenho. Formalmente, podemos modelar a taxa de acerto $H(C)$ como uma fun√ß√£o do tamanho do cache $C$.  A derivada $\frac{dH}{dC}$ √© positiva, indicando que aumentar $C$ aumenta $H$.  Contudo, $\frac{d^2H}{dC^2}$ √© negativa, indicando que o aumento de $H$ com $C$ diminui √† medida que $C$ aumenta, ilustrando a lei dos retornos decrescentes.

> üí° **Exemplo Num√©rico:** Suponha que um sistema RAG tenha um cache com diferentes tamanhos.
>
> | Tamanho do Cache (GB) | Taxa de Acerto (%) |
> | ---------------------- | ------------------- |
> | 1                      | 20                  |
> | 5                      | 50                  |
> | 10                     | 70                  |
> | 20                     | 75                  |
> | 50                     | 78                  |
>
> Como podemos ver, aumentar o tamanho do cache de 1GB para 10GB aumenta significativamente a taxa de acerto. No entanto, aumentar o tamanho do cache de 20GB para 50GB tem um impacto muito menor. Isso demonstra o ponto de satura√ß√£o mencionado no teorema.

**Exemplo:**

Considere um sistema RAG para responder a perguntas sobre artigos cient√≠ficos. O sistema recebe uma pergunta do usu√°rio, recupera os artigos relevantes usando um √≠ndice de busca e, em seguida, usa um LLM para gerar uma resposta.

Para implementar o caching neste sistema, podemos usar uma estrat√©gia baseada em chave. A chave do cache pode ser um hash da pergunta do usu√°rio. Quando uma pergunta √© feita, o sistema verifica se a chave correspondente existe no cache. Se existir, a resposta armazenada em cache √© retornada. Caso contr√°rio, o sistema realiza a busca, gera a resposta e armazena a resposta no cache, juntamente com a chave correspondente.

Al√©m disso, podemos implementar um cache baseado em tempo para garantir que as respostas armazenadas em cache n√£o fiquem obsoletas. Por exemplo, podemos invalidar as respostas armazenadas em cache ap√≥s 24 horas.

**Teorema 1.1:** *Cache H√≠brido: Combina√ß√£o de Cache em Mem√≥ria e em Disco.* Um sistema de caching h√≠brido que utiliza tanto cache em mem√≥ria quanto em disco oferece um compromisso entre velocidade e capacidade.

*Proof (Estrat√©gia):* O cache em mem√≥ria √© usado para armazenar os dados acessados com mais frequ√™ncia (seguindo uma pol√≠tica de substitui√ß√£o como LRU - Least Recently Used), enquanto o cache em disco √© usado para dados acessados com menos frequ√™ncia. Quando uma requisi√ß√£o chega, o cache em mem√≥ria √© consultado primeiro. Se a informa√ß√£o estiver presente, ela √© retornada imediatamente. Caso contr√°rio, o cache em disco √© consultado. Se a informa√ß√£o for encontrada no cache em disco, ela √© retornada e movida para o cache em mem√≥ria, substituindo o item menos recentemente usado. Se a informa√ß√£o n√£o for encontrada em nenhum dos caches, ela √© calculada/recuperada e armazenada tanto no cache em mem√≥ria quanto no cache em disco. Este esquema aproveita a velocidade do cache em mem√≥ria para acessos frequentes e a capacidade do cache em disco para reter um conjunto maior de dados, otimizando o desempenho geral.

> üí° **Exemplo Num√©rico:**
>
> Suponha que o tempo de acesso ao cache em mem√≥ria seja de 1ms, ao cache em disco seja de 10ms, e o tempo para gerar uma resposta do LLM seja de 1000ms. Se a taxa de acerto no cache em mem√≥ria for de 60% e a taxa de acerto no cache em disco (considerando os acessos que n√£o foram encontrados na mem√≥ria) for de 30%, a lat√™ncia m√©dia ser√°:
>
> $$\text{Lat√™ncia M√©dia} = 0.60 \times 1\text{ms} + 0.40 \times (0.30 \times 10\text{ms} + 0.70 \times 1000\text{ms}) = 0.6 + 0.4(3 + 700) = 0.6 + 0.4(703) = 0.6 + 281.2 = 281.8\text{ms}$$
>
> Sem caching, a lat√™ncia seria de 1000ms. O cache h√≠brido reduz a lat√™ncia significativamente.

### Conclus√£o
O **caching** √© uma t√©cnica poderosa para otimizar sistemas RAG, reduzindo a lat√™ncia e o custo. Ao armazenar dados previamente computados ou recuperados, o caching permite que solicita√ß√µes futuras sejam atendidas de forma mais r√°pida e eficiente. A escolha da estrat√©gia de caching e da implementa√ß√£o depender√° da arquitetura do sistema RAG e dos requisitos espec√≠ficos da aplica√ß√£o. A implementa√ß√£o cuidadosa do caching pode levar a melhorias significativas no desempenho e na escalabilidade de sistemas RAG.

### Refer√™ncias
[^1]: Caching is a technique for storing previously retrieved or computed data, allowing future requests for the same data to be served faster.
<!-- END -->