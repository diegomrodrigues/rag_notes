## Cap√≠tulo 6.1: Context Enrichment em Retrieval Augmented Generation (RAG)

### Introdu√ß√£o
Em Retrieval Augmented Generation (RAG), a qualidade do contexto fornecido ao Large Language Model (LLM) √© crucial para a gera√ß√£o de respostas precisas e relevantes. O processo de *context enrichment* visa melhorar a qualidade da busca, recuperando inicialmente trechos menores e, em seguida, suplementando-os com informa√ß√µes contextuais adicionais relevantes para o LLM [^1]. Este cap√≠tulo explora as t√©cnicas de *context enrichment*, focando na expans√£o do contexto com senten√ßas vizinhas e na divis√£o recursiva de documentos em *parent chunks* e *child chunks*. O objetivo √© fornecer um entendimento profundo das estrat√©gias que permitem otimizar o contexto fornecido aos LLMs em sistemas RAG.

### Conceitos Fundamentais

O *context enrichment* surge como uma abordagem para mitigar as limita√ß√µes de sistemas de busca que, ao recuperarem trechos de documentos, podem isolar informa√ß√µes cruciais do seu contexto original [^1]. A estrat√©gia central consiste em, primeiramente, identificar e recuperar trechos menores, que s√£o presumivelmente mais relevantes para a consulta do usu√°rio, e posteriormente expandir esses trechos com informa√ß√µes contextuais adjacentes. Essa expans√£o pode envolver a inclus√£o de senten√ßas vizinhas, par√°grafos ou at√© mesmo se√ß√µes inteiras do documento original.

**Expans√£o do Contexto com Senten√ßas Vizinhas:**

Esta t√©cnica √© uma das formas mais simples e diretas de *context enrichment*. Ap√≥s a recupera√ß√£o do trecho inicial, o sistema identifica as senten√ßas imediatamente anteriores e posteriores a este trecho e as adiciona ao contexto a ser fornecido ao LLM. A premissa √© que senten√ßas vizinhas frequentemente cont√™m informa√ß√µes complementares que ajudam a esclarecer ou contextualizar o trecho original.

Formalmente, seja $T$ o trecho recuperado inicialmente e $S_{i-n}, ..., S_{i-1}$ as *n* senten√ßas anteriores a $T$, e $S_{i+1}, ..., S_{i+m}$ as *m* senten√ßas posteriores a $T$. O contexto enriquecido $C$ seria dado por:

$$C = S_{i-n} \cup \ldots \cup S_{i-1} \cup T \cup S_{i+1} \cup \ldots \cup S_{i+m}$$

A escolha de *n* e *m* depende das caracter√≠sticas do dom√≠nio e do documento, e pode ser otimizada empiricamente.

> üí° **Exemplo Num√©rico:**
>
> Suponha que o trecho recuperado $T$ seja: "A taxa de juros Selic subiu para 13,75\% ao ano.".
>
> E as senten√ßas vizinhas sejam:
> - $S_{i-1}$: "O Banco Central anunciou a nova taxa."
> - $S_{i+1}$: "Essa decis√£o visa controlar a infla√ß√£o."
>
> Ent√£o, o contexto enriquecido $C$ seria:
>
> $C$ = "O Banco Central anunciou a nova taxa. A taxa de juros Selic subiu para 13,75\% ao ano. Essa decis√£o visa controlar a infla√ß√£o."
>
> Aqui, $n = 1$ e $m = 1$. A adi√ß√£o das senten√ßas vizinhas fornece mais contexto sobre a decis√£o do Banco Central e seu objetivo.  Este enriquecimento permite que o LLM responda perguntas como "Qual o objetivo do aumento da Selic?" de forma mais precisa.

**Teorema 1:** *A expans√£o do contexto com senten√ßas vizinhas monotonicamente aumenta o tamanho do contexto fornecido ao LLM.*

*Demonstra√ß√£o:* Seja $C_0 = T$ o contexto inicial, e $C_k$ o contexto ap√≥s a adi√ß√£o de *k* senten√ßas vizinhas.  Ent√£o, $|C_k| > |C_{k-1}|$ para todo $k > 0$, onde $|.|$ denota o tamanho do contexto.  Portanto, o tamanho do contexto aumenta monotonicamente com a adi√ß√£o de senten√ßas vizinhas.

**Corol√°rio 1.1:** *Sob a premissa de um limite m√°ximo de tokens permitido pelo LLM, existe um n√∫mero m√°ximo de senten√ßas vizinhas que podem ser adicionadas sem exceder esse limite.*

*Demonstra√ß√£o:* Seja $L$ o limite m√°ximo de tokens permitido pelo LLM. Seja $|C|$ o n√∫mero de tokens no contexto atual, e $|S|$ o n√∫mero m√©dio de tokens por senten√ßa vizinha. O n√∫mero m√°ximo de senten√ßas vizinhas, $k_{max}$, √© limitado por $C + k_{max} * |S| \le L$, portanto $k_{max} \le (L - |C|) / |S|$.

> üí° **Exemplo Num√©rico:**
>
> Suponha que o LLM tenha um limite de $L = 2048$ tokens. O trecho inicial $T$ tem $|C| = 100$ tokens e o n√∫mero m√©dio de tokens por senten√ßa vizinha √© $|S| = 25$.
>
> Ent√£o, o n√∫mero m√°ximo de senten√ßas vizinhas que podem ser adicionadas √©:
>
> $k_{max} \le (2048 - 100) / 25 = 1948 / 25 = 77.92$
>
> Portanto, no m√°ximo 77 senten√ßas vizinhas podem ser adicionadas sem exceder o limite do LLM. Na pr√°tica, pode ser interessante escolher um valor menor para evitar outros problemas como a dilui√ß√£o da informa√ß√£o relevante.



![Sentence Window Retrieval: Diagram illustrating the technique of retrieving a single relevant sentence and expanding context for the LLM.](./../images/image3.png)

**Divis√£o Recursiva em Parent Chunks e Child Chunks:**

Uma abordagem mais sofisticada de *context enrichment* envolve a divis√£o recursiva de documentos em *parent chunks* e *child chunks* [^1]. Esta t√©cnica visa capturar tanto a granularidade fina da informa√ß√£o contida nos *child chunks* quanto o contexto mais amplo fornecido pelos *parent chunks*.

O processo se inicia dividindo o documento em peda√ßos grandes (*parent chunks*) e, em seguida, dividindo esses peda√ßos grandes em unidades menores (*child chunks*) [^1]. Os *child chunks* s√£o indexados e utilizados na busca inicial, enquanto os *parent chunks* s√£o mantidos como contexto suplementar.

Quando um *child chunk* √© recuperado como relevante para a consulta do usu√°rio, o sistema tamb√©m recupera o *parent chunk* correspondente e o inclui no contexto fornecido ao LLM [^1]. Isso permite que o LLM tenha acesso tanto √† informa√ß√£o detalhada contida no *child chunk* quanto ao contexto mais amplo fornecido pelo *parent chunk*.

Este processo pode ser formalizado da seguinte maneira:

1. **Defini√ß√£o da Fun√ß√£o de Divis√£o:** Seja $D$ um documento. Definimos uma fun√ß√£o de divis√£o $f(D) = \{P_1, P_2, \ldots, P_k\}$, onde $P_i$ s√£o os *parent chunks*.
2. **Divis√£o Recursiva:** Para cada *parent chunk* $P_i$, aplicamos uma segunda fun√ß√£o de divis√£o $g(P_i) = \{C_{i1}, C_{i2}, \ldots, C_{il}\}$, onde $C_{ij}$ s√£o os *child chunks* correspondentes ao *parent chunk* $P_i$.
3. **Indexa√ß√£o dos Child Chunks:** Os *child chunks* $C_{ij}$ s√£o indexados para busca.
4. **Recupera√ß√£o:** Dada uma consulta $Q$, o sistema recupera um conjunto de *child chunks* relevantes $R = \{C_{1}, C_{2}, \ldots, C_{n}\}$ tal que $C_i \in \{C_{ij}\}$.
5. **Enriquecimento do Contexto:** Para cada *child chunk* $C_i \in R$, o sistema recupera o *parent chunk* correspondente $P_i$ e inclui ambos no contexto fornecido ao LLM.

O contexto final $C$ √© dado por:

$$C = \bigcup_{i=1}^{n} \{C_i \cup P_i\}$$

A escolha dos tamanhos dos *parent chunks* e *child chunks*, bem como das fun√ß√µes de divis√£o *f* e *g*, depende das caracter√≠sticas do dom√≠nio e do documento, e pode ser otimizada empiricamente.

> üí° **Exemplo Num√©rico:**
>
> Considere um documento $D$ sobre a hist√≥ria da computa√ß√£o.
>
> 1. **Divis√£o em Parent Chunks:**
>    $f(D)$ pode dividir o documento em se√ß√µes como: "Introdu√ß√£o", "Primeiros Computadores", "A Era dos Microprocessadores", "A Ascens√£o da Internet".  Cada se√ß√£o √© um $P_i$.
>
> 2. **Divis√£o em Child Chunks:**
>    $g(P_i)$ para "A Era dos Microprocessadores" pode gerar child chunks como: "Intel 4004", "Intel 8080", "Motorola 68000". Cada um desses √© um $C_{ij}$.
>
> 3. **Indexa√ß√£o:** Os child chunks "Intel 4004", "Intel 8080", "Motorola 68000" s√£o indexados.
>
> 4. **Recupera√ß√£o:** Uma consulta $Q$ = "Qual foi o primeiro microprocessador da Intel?" pode retornar o child chunk $C_1$ = "Intel 4004".
>
> 5. **Enriquecimento:** O contexto final ser√° $C = C_1 \cup P_3$, onde $C_1$ = "Intel 4004" e $P_3$ = "A Era dos Microprocessadores".  O LLM ter√° a informa√ß√£o detalhada sobre o Intel 4004 e o contexto hist√≥rico da sua cria√ß√£o.
>
> Nesse exemplo, podemos definir o tamanho dos parent chunks como 500 tokens e o tamanho dos child chunks como 100 tokens. A fun√ß√£o de divis√£o $f$ divide o documento em se√ß√µes (parent chunks) e a fun√ß√£o $g$ divide cada se√ß√£o em par√°grafos (child chunks).

**Proposi√ß√£o 2:** *A divis√£o recursiva em parent e child chunks preserva a informa√ß√£o contida no documento original, embora possa alterar a ordem.*

*Demonstra√ß√£o:* A fun√ß√£o de divis√£o $f(D)$ particiona o documento $D$ em *parent chunks*, e a fun√ß√£o $g(P_i)$ particiona cada *parent chunk* em *child chunks*. Portanto, a uni√£o de todos os *child chunks* √© igual ao documento original, ou seja, $\bigcup_{i=1}^{k} \bigcup_{j=1}^{l} C_{ij} = D$. A ordem pode ser alterada dependendo da implementa√ß√£o das fun√ß√µes *f* e *g*.

**Lema 2.1:** *O processo de divis√£o recursiva √© idempotente no n√≠vel dos child chunks, ou seja, aplicar novamente as fun√ß√µes de divis√£o aos child chunks n√£o altera o conjunto de child chunks.*

*Demonstra√ß√£o:* Como os *child chunks* representam a menor granularidade de divis√£o neste contexto, aplicar $f$ e $g$ novamente aos *child chunks* resultaria apenas em fragmentos menores que n√£o s√£o √∫teis para indexa√ß√£o ou recupera√ß√£o. Portanto, $g(C_{ij}) = C_{ij}$, mostrando a propriedade de idempot√™ncia.



![Parent-child chunks retrieval enhances context for LLMs by merging related leaf chunks into a larger parent chunk during retrieval.](./../images/image10.png)

**Vantagens e Desafios do Context Enrichment:**

*   **Vantagens:** O *context enrichment* pode melhorar significativamente a qualidade das respostas geradas pelos LLMs, fornecendo um contexto mais completo e relevante. A divis√£o recursiva em *parent chunks* e *child chunks* permite capturar tanto a granularidade fina da informa√ß√£o quanto o contexto mais amplo [^1].
*   **Desafios:** A implementa√ß√£o eficaz do *context enrichment* requer a otimiza√ß√£o dos par√¢metros das t√©cnicas utilizadas, como o n√∫mero de senten√ßas vizinhas a serem inclu√≠das ou os tamanhos dos *parent chunks* e *child chunks*. Al√©m disso, a expans√£o excessiva do contexto pode levar a um aumento no ru√≠do e a uma diminui√ß√£o na precis√£o da informa√ß√£o fornecida ao LLM.

> üí° **Exemplo Num√©rico: Compara√ß√£o de M√©todos:**
>
> Suponha que temos um sistema de RAG e estamos testando diferentes m√©todos de context enrichment. Usamos as m√©tricas de Precision e Recall para avaliar a qualidade do contexto recuperado.
>
> | M√©todo                     | Precision | Recall |
> | -------------------------- | --------- | ------ |
> | Sem Context Enrichment     | 0.60      | 0.50   |
> | Senten√ßas Vizinhas (n=1, m=1) | 0.75      | 0.65   |
> | Parent/Child Chunks        | 0.80      | 0.70   |
>
> *Interpreta√ß√£o:* Os m√©todos de Context Enrichment melhoram tanto a Precision quanto o Recall em rela√ß√£o a n√£o usar nenhuma t√©cnica.  Parent/Child Chunks apresenta o melhor resultado neste exemplo, indicando que capturar o contexto mais amplo √© ben√©fico para este dataset.

### Conclus√£o

O *context enrichment* √© uma t√©cnica fundamental para melhorar a qualidade dos sistemas RAG [^1]. Ao permitir a recupera√ß√£o de trechos menores e a suplementa√ß√£o com informa√ß√µes contextuais relevantes, essa abordagem possibilita que os LLMs gerem respostas mais precisas e informativas. A escolha da t√©cnica de *context enrichment* mais adequada, bem como a otimiza√ß√£o dos seus par√¢metros, depende das caracter√≠sticas espec√≠ficas do dom√≠nio e dos documentos utilizados. A combina√ß√£o de diferentes t√©cnicas e a experimenta√ß√£o emp√≠rica s√£o essenciais para alcan√ßar o melhor desempenho poss√≠vel.

### Refer√™ncias
[^1]: Context enrichment focuses on improving search quality by retrieving smaller chunks and supplementing them with surrounding context for the LLM. This can be achieved by expanding the context with neighboring sentences or recursively splitting documents into parent and child chunks.
<!-- END -->