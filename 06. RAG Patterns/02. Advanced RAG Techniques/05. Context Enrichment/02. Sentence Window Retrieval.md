## Sentence Window Retrieval para Enriquecimento de Contexto em RAG

### IntroduÃ§Ã£o
Em sistemas de **Retrieval-Augmented Generation (RAG)**, a precisÃ£o na recuperaÃ§Ã£o de contexto Ã© crucial para a geraÃ§Ã£o de respostas relevantes e informativas. EstratÃ©gias de **Context Enrichment** visam aprimorar a qualidade do contexto fornecido ao Large Language Model (LLM), melhorando assim o desempenho do sistema RAG. Dentro deste domÃ­nio, o **Sentence Window Retrieval** emerge como uma tÃ©cnica eficaz para identificar e expandir o contexto relevante para uma dada consulta [^2]. Este capÃ­tulo explora em detalhes o Sentence Window Retrieval, analisando sua metodologia, vantagens e aplicaÃ§Ãµes no contexto de RAG com LLMs.

### Conceitos Fundamentais
O **Sentence Window Retrieval** Ã© uma abordagem que se concentra em aumentar a granularidade da busca de contexto para o nÃ­vel da frase, em vez de documentos ou parÃ¡grafos inteiros. A ideia central Ã© que a incorporaÃ§Ã£o de cada frase separadamente permite uma maior precisÃ£o na identificaÃ§Ã£o de segmentos textuais que sÃ£o altamente relevantes para a consulta do usuÃ¡rio [^2].

**Metodologia:**
1. **FragmentaÃ§Ã£o do Documento:** Inicialmente, o documento de origem Ã© dividido em frases individuais.
2. **Embedding de Frases:** Cada frase Ã© entÃ£o transformada em um vetor de embedding, utilizando um modelo de embedding prÃ©-treinado (e.g., `SentenceTransformer`). Este passo Ã© crucial para representar semanticamente cada frase em um espaÃ§o vetorial.
3. **IndexaÃ§Ã£o:** Os vetores de embedding das frases sÃ£o indexados em um banco de dados vetorial (e.g., `FAISS`, `Annoy`).
4. **Busca por Similaridade:** Dada uma consulta do usuÃ¡rio, seu vetor de embedding Ã© calculado e usado para realizar uma busca de similaridade no banco de dados vetorial, identificando as frases mais relevantes com base na distÃ¢ncia cosseno [^2].
5. **ExpansÃ£o da Janela de Contexto:** Uma vez identificada a frase mais relevante, uma janela de contexto Ã© expandida ao redor desta frase, incluindo frases vizinhas antes e depois. O tamanho desta janela Ã© um hiperparÃ¢metro que pode ser ajustado para otimizar o desempenho.
6. **Fornecimento ao LLM:** Finalmente, o contexto expandido (a janela de frases) Ã© fornecido ao LLM como entrada para gerar a resposta [^2].

![Sentence Window Retrieval: Diagram illustrating the technique of retrieving a single relevant sentence and expanding context for the LLM.](./../images/image3.png)

**FormalizaÃ§Ã£o:**
Seja $D$ um documento de origem, que Ã© dividido em um conjunto de frases $S = \{s_1, s_2, ..., s_n\}$. Cada frase $s_i$ Ã© transformada em um vetor de embedding $v_i = embed(s_i)$, onde $embed$ Ã© a funÃ§Ã£o de embedding. Dado uma consulta $q$, o vetor de embedding da consulta Ã© $v_q = embed(q)$.

A similaridade entre a consulta e cada frase Ã© calculada usando a distÃ¢ncia cosseno:
$$
similarity(v_q, v_i) = \frac{v_q \cdot v_i}{||v_q|| \cdot ||v_i||}
$$

A frase mais relevante $s^*$ Ã© aquela que maximiza a similaridade:
$$
s^* = \arg \max_{s_i \in S} similarity(v_q, v_i)
$$

A janela de contexto Ã© entÃ£o definida como um conjunto de frases ao redor de $s^*$:
$$
Window(s^*, k) = \{s_{i} \mid i \in [index(s^*) - k, index(s^*) + k] \}
$$
Onde $k$ Ã© o tamanho da janela e $index(s^*)$ Ã© o Ã­ndice da frase mais relevante no documento original. Este `Window(s*, k)` Ã© entÃ£o fornecido ao LLM.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos o seguinte documento simples dividido em frases:
>
> $D$ = "O cÃ©u Ã© azul. A grama Ã© verde. O sol Ã© amarelo."
>
> Assim, $S$ = \{$s_1$: "O cÃ©u Ã© azul.", $s_2$: "A grama Ã© verde.", $s_3$: "O sol Ã© amarelo."\}
>
> Agora, vamos criar embeddings simplificados para essas frases e para a consulta:
>
> $v_1$ (O cÃ©u Ã© azul) = [0.8, 0.2]
>
> $v_2$ (A grama Ã© verde) = [0.3, 0.7]
>
> $v_3$ (O sol Ã© amarelo) = [0.5, 0.5]
>
> Consulta $q$ = "Cor do cÃ©u"
>
> $v_q$ (Cor do cÃ©u) = [0.7, 0.3]
>
> Agora, calculamos a similaridade do cosseno entre a consulta e cada frase:
>
> $similarity(v_q, v_1) = \frac{(0.7 * 0.8 + 0.3 * 0.2)}{\sqrt{(0.7^2 + 0.3^2)} * \sqrt{(0.8^2 + 0.2^2)}} = \frac{0.56 + 0.06}{\sqrt{0.58} * \sqrt{0.68}} = \frac{0.62}{0.626} \approx 0.99$
>
> $similarity(v_q, v_2) = \frac{(0.7 * 0.3 + 0.3 * 0.7)}{\sqrt{(0.7^2 + 0.3^2)} * \sqrt{(0.3^2 + 0.7^2)}} = \frac{0.21 + 0.21}{\sqrt{0.58} * \sqrt{0.58}} = \frac{0.42}{0.58} \approx 0.72$
>
> $similarity(v_q, v_3) = \frac{(0.7 * 0.5 + 0.3 * 0.5)}{\sqrt{(0.7^2 + 0.3^2)} * \sqrt{(0.5^2 + 0.5^2)}} = \frac{0.35 + 0.15}{\sqrt{0.58} * \sqrt{0.5}} = \frac{0.5}{0.539} \approx 0.93$
>
> A frase mais relevante $s^*$ Ã© $s_1$ ("O cÃ©u Ã© azul.") porque tem a maior similaridade (0.99).
>
> Se o tamanho da janela $k = 1$, entÃ£o $Window(s^*, k) = $ \{$s_1$, $s_2$\} = \{"O cÃ©u Ã© azul.", "A grama Ã© verde."\}
>
> Este contexto seria entÃ£o passado para o LLM.

**Teorema 1** [Optimal Window Size]
Existe um tamanho de janela Ã³timo $k^*$ que maximiza a relevÃ¢ncia e minimiza o ruÃ­do no contexto fornecido ao LLM.

*DiscussÃ£o:*
Determinar o valor ideal de $k$ Ã© um desafio empÃ­rico. Um $k$ muito pequeno pode nÃ£o fornecer contexto suficiente, enquanto um $k$ muito grande pode introduzir informaÃ§Ãµes irrelevantes que prejudicam o desempenho do LLM. A escolha de $k$ depende da natureza dos documentos, das consultas e das capacidades do LLM. TÃ©cnicas de validaÃ§Ã£o cruzada podem ser usadas para estimar $k^*$.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que, para um dado conjunto de documentos e um LLM especÃ­fico, realizamos uma validaÃ§Ã£o cruzada para determinar o tamanho Ã³timo da janela $k$. Avaliamos o desempenho do RAG (por exemplo, usando a precisÃ£o da resposta gerada em relaÃ§Ã£o a uma resposta de referÃªncia) para diferentes valores de $k$:
>
> | Tamanho da Janela (k) | PrecisÃ£o MÃ©dia |
> |-----------------------|-----------------|
> | 0                     | 0.65            |
> | 1                     | 0.80            |
> | 2                     | 0.85            |
> | 3                     | 0.82            |
> | 4                     | 0.78            |
>
> Neste caso, $k^* = 2$ parece ser o tamanho de janela Ã³timo, pois proporciona a maior precisÃ£o mÃ©dia. Um valor de $k$ maior (e.g., 3 ou 4) pode estar introduzindo ruÃ­do no contexto, diminuindo a precisÃ£o.

A escolha da funÃ§Ã£o `embed` tambÃ©m Ã© importante. Diferentes modelos de embedding podem capturar diferentes aspectos da semÃ¢ntica das frases, influenciando a qualidade da busca por similaridade. Modelos de embedding mais recentes, treinados em grandes volumes de dados, tendem a oferecer melhor desempenho. AlÃ©m disso, pode-se considerar o uso de embeddings contextuais, que levam em conta o contexto da frase no documento.

**Lema 1.1** [Embedding Quality and Retrieval Performance]
A qualidade da funÃ§Ã£o de embedding $embed$ afeta diretamente a precisÃ£o da recuperaÃ§Ã£o de frases relevantes.

*Proof Sketch:*
Se a funÃ§Ã£o $embed$ nÃ£o capturar adequadamente as relaÃ§Ãµes semÃ¢nticas entre as frases e a consulta, a medida de similaridade (neste caso, a distÃ¢ncia cosseno) nÃ£o refletirÃ¡ a relevÃ¢ncia real. Isso leva Ã  seleÃ§Ã£o de frases irrelevantes e, consequentemente, a um contexto de baixa qualidade para o LLM.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos comparar dois modelos de embedding: `SentenceTransformer` (modelo mais recente) e um modelo TF-IDF bÃ¡sico (modelo mais simples). Usaremos o mesmo documento e consulta do exemplo anterior.
>
> | Modelo de Embedding | Similaridade (Consulta, Frase 1) | Similaridade (Consulta, Frase 2) | Similaridade (Consulta, Frase 3) | Frase Mais Relevante Recuperada |
> |----------------------|---------------------------------|---------------------------------|---------------------------------|-------------------------------|
> | TF-IDF               | 0.6                            | 0.2                            | 0.3                            | Frase 1                       |
> | SentenceTransformer  | 0.99                           | 0.72                           | 0.93                           | Frase 1                       |
>
> Neste exemplo (hipotÃ©tico, jÃ¡ que os valores sÃ£o simplificados), ambos os modelos identificam a Frase 1 como a mais relevante. No entanto, o `SentenceTransformer` atribui uma pontuaÃ§Ã£o de similaridade muito maior Ã  Frase 1, indicando uma representaÃ§Ã£o semÃ¢ntica mais precisa da relaÃ§Ã£o entre a consulta e a frase. Em casos mais complexos, a maior precisÃ£o do `SentenceTransformer` pode ser crucial para identificar a frase *correta*.

AlÃ©m disso, Ã© possÃ­vel refinar o processo de busca por similaridade atravÃ©s da aplicaÃ§Ã£o de tÃ©cnicas de re-ranking.

**Lema 1.2** [Re-ranking Improves Relevance]
Aplicar um modelo de re-ranking apÃ³s a busca inicial por similaridade pode melhorar a precisÃ£o da seleÃ§Ã£o de frases relevantes.

*Proof Sketch:*
A busca inicial por similaridade baseada na distÃ¢ncia cosseno pode ser limitada em sua capacidade de capturar nuances semÃ¢nticas complexas. Um modelo de re-ranking, treinado para avaliar a relevÃ¢ncia entre a consulta e as frases recuperadas, pode refinar a ordenaÃ§Ã£o das frases, promovendo aquelas que sÃ£o mais relevantes e suprimindo as menos relevantes. Modelos como cross-encoders podem ser utilizados para este fim.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> ApÃ³s a busca inicial por similaridade, temos as seguintes pontuaÃ§Ãµes de relevÃ¢ncia para as 5 principais frases:
>
> | Frase | Similaridade Cosseno |
> |-------|----------------------|
> |   1   | 0.99                 |
> |   2   | 0.95                 |
> |   3   | 0.92                 |
> |   4   | 0.90                 |
> |   5   | 0.88                 |
>
> Um modelo de re-ranking (e.g., um cross-encoder) analisa cada frase no contexto da consulta e atribui novas pontuaÃ§Ãµes de relevÃ¢ncia:
>
> | Frase | Similaridade Cosseno | PontuaÃ§Ã£o Re-ranking |
> |-------|----------------------|----------------------|
> |   1   | 0.99                 | 0.98                 |
> |   2   | 0.95                 | 0.97                 |
> |   3   | 0.92                 | 0.93                 |
> |   4   | 0.90                 | 0.85                 |
> |   5   | 0.88                 | 0.80                 |
>
> Neste exemplo, o modelo de re-ranking aumentou a pontuaÃ§Ã£o da Frase 2, indicando que, embora sua similaridade cosseno fosse ligeiramente inferior Ã  da Frase 1, o re-ranker determinou que ela Ã©, de fato, mais relevante no contexto da consulta. A Frase 2 agora seria priorizada.

Ainda sobre a formalizaÃ§Ã£o, podemos definir uma funÃ§Ã£o para representar o conteÃºdo informacional da janela de contexto.

**DefiniÃ§Ã£o:** Seja $I(Window(s^*, k))$ o conteÃºdo informacional da janela de contexto $Window(s^*, k)$.

O conteÃºdo informacional pode ser quantificado de diversas formas, dependendo da aplicaÃ§Ã£o. Por exemplo, pode-se usar medidas de entropia ou similaridade semÃ¢ntica entre as frases na janela. Uma janela com alta similaridade semÃ¢ntica entre suas frases tende a ser mais coerente e informativa.

**Vantagens do Sentence Window Retrieval:**
*   **PrecisÃ£o Aprimorada:** Ao incorporar frases individualmente, o sistema pode identificar nuances e contextos especÃ­ficos que seriam perdidos em uma abordagem de nÃ­vel de documento ou parÃ¡grafo.
*   **RelevÃ¢ncia Contextual:** A expansÃ£o da janela de contexto garante que o LLM receba informaÃ§Ãµes adicionais que ajudam a contextualizar a frase mais relevante, resultando em respostas mais coerentes e informativas.
*   **Flexibilidade:** O tamanho da janela de contexto pode ser ajustado para equilibrar a quantidade de informaÃ§Ãµes fornecidas ao LLM com o ruÃ­do potencial de informaÃ§Ãµes irrelevantes.

**ImplementaÃ§Ã£o:**
A implementaÃ§Ã£o do Sentence Window Retrieval pode ser realizada usando bibliotecas Python como `SentenceTransformers` para embedding de frases e `FAISS` ou `Annoy` para indexaÃ§Ã£o vetorial e busca por similaridade. As etapas envolvem:
1.  Carregar o documento e dividir em frases.
2.  Calcular os embeddings das frases.
3.  Criar um Ã­ndice vetorial.
4.  Receber a consulta do usuÃ¡rio e calcular seu embedding.
5.  Buscar as frases mais similares no Ã­ndice.
6.  Expandir a janela de contexto.
7.  Passar o contexto expandido para o LLM para geraÃ§Ã£o de resposta.

**Exemplo:**
Considere um documento sobre a histÃ³ria da inteligÃªncia artificial. Uma consulta do usuÃ¡rio poderia ser: "Quais foram os principais desafios no desenvolvimento do aprendizado profundo?". O Sentence Window Retrieval identificaria a frase mais relevante, por exemplo: "*Um dos principais desafios no desenvolvimento do aprendizado profundo foi a necessidade de grandes quantidades de dados rotulados*". A janela de contexto entÃ£o incluiria frases vizinhas, como "*Inicialmente, as redes neurais enfrentaram dificuldades em lidar com problemas complexos devido Ã  falta de dados e poder computacional. A disponibilidade limitada de dados rotulados restringia a capacidade de treinar modelos profundos de forma eficaz.*" e "*Com o advento de conjuntos de dados maiores e avanÃ§os no hardware, o aprendizado profundo comeÃ§ou a superar os mÃ©todos tradicionais em vÃ¡rias tarefas.*". Este contexto expandido permite que o LLM gere uma resposta mais completa e precisa.

**Teorema 2** [Sentence Window Retrieval with Metadata Filtering]
A incorporaÃ§Ã£o de filtragem baseada em metadados no processo de Sentence Window Retrieval pode melhorar ainda mais a precisÃ£o e relevÃ¢ncia do contexto recuperado.

*DiscussÃ£o:*
Metadados associados Ã s frases (e.g., fonte, data de criaÃ§Ã£o, autor) podem ser utilizados para restringir a busca por similaridade apenas a um subconjunto de frases que satisfazem determinados critÃ©rios. Por exemplo, pode-se filtrar as frases por data para recuperar apenas informaÃ§Ãµes recentes, ou por fonte para priorizar informaÃ§Ãµes de fontes confiÃ¡veis.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que cada frase em nosso corpus tenha metadados indicando a data de publicaÃ§Ã£o. Queremos responder Ã  consulta "Qual a abordagem mais recente para resolver X?". Podemos filtrar as frases para incluir apenas aquelas publicadas nos Ãºltimos 5 anos.
>
> Inicialmente, o sistema recupera 10 frases com alta similaridade cosseno. No entanto, apenas 3 dessas frases foram publicadas nos Ãºltimos 5 anos:
>
> | Frase | Similaridade Cosseno | Data de PublicaÃ§Ã£o |
> |-------|----------------------|-------------------|
> |   1   | 0.99                 | 2010              |
> |   2   | 0.95                 | 2022              |
> |   3   | 0.92                 | 2018              |
> |   4   | 0.90                 | 2015              |
> |   5   | 0.88                 | 2005              |
> |   6   | 0.85                 | 2023              |
> |   7   | 0.82                 | 2019              |
> |   8   | 0.80                 | 2012              |
> |   9   | 0.78                 | 2000              |
> |   10  | 0.75                 | 2017              |
>
> ApÃ³s a filtragem por data (considerando apenas os Ãºltimos 5 anos), apenas as frases 2, 3, 6 e 7 sÃ£o consideradas. A frase 6 (publicada em 2023) pode agora ser a frase mais relevante apÃ³s a filtragem, mesmo que sua similaridade cosseno inicial fosse menor do que a da Frase 1.

**CorolÃ¡rio 2.1** [Metadata-Aware Window Expansion]
A expansÃ£o da janela de contexto pode ser adaptada para considerar os metadados das frases vizinhas. Por exemplo, a janela pode ser expandida preferencialmente em direÃ§Ã£o a frases com metadados semelhantes Ã  frase mais relevante.

### ConclusÃ£o
O **Sentence Window Retrieval** representa uma tÃ©cnica valiosa para **Context Enrichment** em sistemas RAG com LLMs. Sua capacidade de focar na granularidade da frase, combinada com a expansÃ£o da janela de contexto, resulta em uma recuperaÃ§Ã£o de contexto mais precisa e relevante. A flexibilidade no ajuste do tamanho da janela permite otimizar o desempenho do sistema para diferentes tipos de consultas e documentos. Ao integrar o Sentence Window Retrieval em sistemas RAG, Ã© possÃ­vel melhorar significativamente a qualidade das respostas geradas pelo LLM.

### ReferÃªncias
[^2]: DescriÃ§Ã£o do Sentence Window Retrieval como uma tÃ©cnica para aumentar a granularidade da busca de contexto para o nÃ­vel da frase, resultando em maior precisÃ£o na identificaÃ§Ã£o de segmentos textuais relevantes.
<!-- END -->