## Sentence Window Retrieval para Enriquecimento de Contexto em RAG

### Introdu√ß√£o
Em sistemas de **Retrieval-Augmented Generation (RAG)**, a precis√£o na recupera√ß√£o de contexto √© crucial para a gera√ß√£o de respostas relevantes e informativas. Estrat√©gias de **Context Enrichment** visam aprimorar a qualidade do contexto fornecido ao Large Language Model (LLM), melhorando assim o desempenho do sistema RAG. Dentro deste dom√≠nio, o **Sentence Window Retrieval** emerge como uma t√©cnica eficaz para identificar e expandir o contexto relevante para uma dada consulta [^2]. Este cap√≠tulo explora em detalhes o Sentence Window Retrieval, analisando sua metodologia, vantagens e aplica√ß√µes no contexto de RAG com LLMs.

### Conceitos Fundamentais
O **Sentence Window Retrieval** √© uma abordagem que se concentra em aumentar a granularidade da busca de contexto para o n√≠vel da frase, em vez de documentos ou par√°grafos inteiros. A ideia central √© que a incorpora√ß√£o de cada frase separadamente permite uma maior precis√£o na identifica√ß√£o de segmentos textuais que s√£o altamente relevantes para a consulta do usu√°rio [^2].

**Metodologia:**
1. **Fragmenta√ß√£o do Documento:** Inicialmente, o documento de origem √© dividido em frases individuais.
2. **Embedding de Frases:** Cada frase √© ent√£o transformada em um vetor de embedding, utilizando um modelo de embedding pr√©-treinado (e.g., `SentenceTransformer`). Este passo √© crucial para representar semanticamente cada frase em um espa√ßo vetorial.
3. **Indexa√ß√£o:** Os vetores de embedding das frases s√£o indexados em um banco de dados vetorial (e.g., `FAISS`, `Annoy`).
4. **Busca por Similaridade:** Dada uma consulta do usu√°rio, seu vetor de embedding √© calculado e usado para realizar uma busca de similaridade no banco de dados vetorial, identificando as frases mais relevantes com base na dist√¢ncia cosseno [^2].
5. **Expans√£o da Janela de Contexto:** Uma vez identificada a frase mais relevante, uma janela de contexto √© expandida ao redor desta frase, incluindo frases vizinhas antes e depois. O tamanho desta janela √© um hiperpar√¢metro que pode ser ajustado para otimizar o desempenho.
6. **Fornecimento ao LLM:** Finalmente, o contexto expandido (a janela de frases) √© fornecido ao LLM como entrada para gerar a resposta [^2].

![Sentence Window Retrieval: Diagram illustrating the technique of retrieving a single relevant sentence and expanding context for the LLM.](./../images/image3.png)

**Formaliza√ß√£o:**
Seja $D$ um documento de origem, que √© dividido em um conjunto de frases $S = \{s_1, s_2, ..., s_n\}$. Cada frase $s_i$ √© transformada em um vetor de embedding $v_i = embed(s_i)$, onde $embed$ √© a fun√ß√£o de embedding. Dado uma consulta $q$, o vetor de embedding da consulta √© $v_q = embed(q)$.

A similaridade entre a consulta e cada frase √© calculada usando a dist√¢ncia cosseno:
$$
similarity(v_q, v_i) = \frac{v_q \cdot v_i}{||v_q|| \cdot ||v_i||}
$$

A frase mais relevante $s^*$ √© aquela que maximiza a similaridade:
$$
s^* = \arg \max_{s_i \in S} similarity(v_q, v_i)
$$

A janela de contexto √© ent√£o definida como um conjunto de frases ao redor de $s^*$:
$$
Window(s^*, k) = \{s_{i} \mid i \in [index(s^*) - k, index(s^*) + k] \}
$$
Onde $k$ √© o tamanho da janela e $index(s^*)$ √© o √≠ndice da frase mais relevante no documento original. Este `Window(s*, k)` √© ent√£o fornecido ao LLM.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos o seguinte documento simples dividido em frases:
>
> $D$ = "O c√©u √© azul. A grama √© verde. O sol √© amarelo."
>
> Assim, $S$ = \{$s_1$: "O c√©u √© azul.", $s_2$: "A grama √© verde.", $s_3$: "O sol √© amarelo."\}
>
> Agora, vamos criar embeddings simplificados para essas frases e para a consulta:
>
> $v_1$ (O c√©u √© azul) = [0.8, 0.2]
>
> $v_2$ (A grama √© verde) = [0.3, 0.7]
>
> $v_3$ (O sol √© amarelo) = [0.5, 0.5]
>
> Consulta $q$ = "Cor do c√©u"
>
> $v_q$ (Cor do c√©u) = [0.7, 0.3]
>
> Agora, calculamos a similaridade do cosseno entre a consulta e cada frase:
>
> $similarity(v_q, v_1) = \frac{(0.7 * 0.8 + 0.3 * 0.2)}{\sqrt{(0.7^2 + 0.3^2)} * \sqrt{(0.8^2 + 0.2^2)}} = \frac{0.56 + 0.06}{\sqrt{0.58} * \sqrt{0.68}} = \frac{0.62}{0.626} \approx 0.99$
>
> $similarity(v_q, v_2) = \frac{(0.7 * 0.3 + 0.3 * 0.7)}{\sqrt{(0.7^2 + 0.3^2)} * \sqrt{(0.3^2 + 0.7^2)}} = \frac{0.21 + 0.21}{\sqrt{0.58} * \sqrt{0.58}} = \frac{0.42}{0.58} \approx 0.72$
>
> $similarity(v_q, v_3) = \frac{(0.7 * 0.5 + 0.3 * 0.5)}{\sqrt{(0.7^2 + 0.3^2)} * \sqrt{(0.5^2 + 0.5^2)}} = \frac{0.35 + 0.15}{\sqrt{0.58} * \sqrt{0.5}} = \frac{0.5}{0.539} \approx 0.93$
>
> A frase mais relevante $s^*$ √© $s_1$ ("O c√©u √© azul.") porque tem a maior similaridade (0.99).
>
> Se o tamanho da janela $k = 1$, ent√£o $Window(s^*, k) = $ \{$s_1$, $s_2$\} = \{"O c√©u √© azul.", "A grama √© verde."\}
>
> Este contexto seria ent√£o passado para o LLM.

**Teorema 1** [Optimal Window Size]
Existe um tamanho de janela √≥timo $k^*$ que maximiza a relev√¢ncia e minimiza o ru√≠do no contexto fornecido ao LLM.

*Discuss√£o:*
Determinar o valor ideal de $k$ √© um desafio emp√≠rico. Um $k$ muito pequeno pode n√£o fornecer contexto suficiente, enquanto um $k$ muito grande pode introduzir informa√ß√µes irrelevantes que prejudicam o desempenho do LLM. A escolha de $k$ depende da natureza dos documentos, das consultas e das capacidades do LLM. T√©cnicas de valida√ß√£o cruzada podem ser usadas para estimar $k^*$.

> üí° **Exemplo Num√©rico:**
>
> Suponha que, para um dado conjunto de documentos e um LLM espec√≠fico, realizamos uma valida√ß√£o cruzada para determinar o tamanho √≥timo da janela $k$. Avaliamos o desempenho do RAG (por exemplo, usando a precis√£o da resposta gerada em rela√ß√£o a uma resposta de refer√™ncia) para diferentes valores de $k$:
>
> | Tamanho da Janela (k) | Precis√£o M√©dia |
> |-----------------------|-----------------|
> | 0                     | 0.65            |
> | 1                     | 0.80            |
> | 2                     | 0.85            |
> | 3                     | 0.82            |
> | 4                     | 0.78            |
>
> Neste caso, $k^* = 2$ parece ser o tamanho de janela √≥timo, pois proporciona a maior precis√£o m√©dia. Um valor de $k$ maior (e.g., 3 ou 4) pode estar introduzindo ru√≠do no contexto, diminuindo a precis√£o.

A escolha da fun√ß√£o `embed` tamb√©m √© importante. Diferentes modelos de embedding podem capturar diferentes aspectos da sem√¢ntica das frases, influenciando a qualidade da busca por similaridade. Modelos de embedding mais recentes, treinados em grandes volumes de dados, tendem a oferecer melhor desempenho. Al√©m disso, pode-se considerar o uso de embeddings contextuais, que levam em conta o contexto da frase no documento.

**Lema 1.1** [Embedding Quality and Retrieval Performance]
A qualidade da fun√ß√£o de embedding $embed$ afeta diretamente a precis√£o da recupera√ß√£o de frases relevantes.

*Proof Sketch:*
Se a fun√ß√£o $embed$ n√£o capturar adequadamente as rela√ß√µes sem√¢nticas entre as frases e a consulta, a medida de similaridade (neste caso, a dist√¢ncia cosseno) n√£o refletir√° a relev√¢ncia real. Isso leva √† sele√ß√£o de frases irrelevantes e, consequentemente, a um contexto de baixa qualidade para o LLM.

> üí° **Exemplo Num√©rico:**
>
> Vamos comparar dois modelos de embedding: `SentenceTransformer` (modelo mais recente) e um modelo TF-IDF b√°sico (modelo mais simples). Usaremos o mesmo documento e consulta do exemplo anterior.
>
> | Modelo de Embedding | Similaridade (Consulta, Frase 1) | Similaridade (Consulta, Frase 2) | Similaridade (Consulta, Frase 3) | Frase Mais Relevante Recuperada |
> |----------------------|---------------------------------|---------------------------------|---------------------------------|-------------------------------|
> | TF-IDF               | 0.6                            | 0.2                            | 0.3                            | Frase 1                       |
> | SentenceTransformer  | 0.99                           | 0.72                           | 0.93                           | Frase 1                       |
>
> Neste exemplo (hipot√©tico, j√° que os valores s√£o simplificados), ambos os modelos identificam a Frase 1 como a mais relevante. No entanto, o `SentenceTransformer` atribui uma pontua√ß√£o de similaridade muito maior √† Frase 1, indicando uma representa√ß√£o sem√¢ntica mais precisa da rela√ß√£o entre a consulta e a frase. Em casos mais complexos, a maior precis√£o do `SentenceTransformer` pode ser crucial para identificar a frase *correta*.

Al√©m disso, √© poss√≠vel refinar o processo de busca por similaridade atrav√©s da aplica√ß√£o de t√©cnicas de re-ranking.

**Lema 1.2** [Re-ranking Improves Relevance]
Aplicar um modelo de re-ranking ap√≥s a busca inicial por similaridade pode melhorar a precis√£o da sele√ß√£o de frases relevantes.

*Proof Sketch:*
A busca inicial por similaridade baseada na dist√¢ncia cosseno pode ser limitada em sua capacidade de capturar nuances sem√¢nticas complexas. Um modelo de re-ranking, treinado para avaliar a relev√¢ncia entre a consulta e as frases recuperadas, pode refinar a ordena√ß√£o das frases, promovendo aquelas que s√£o mais relevantes e suprimindo as menos relevantes. Modelos como cross-encoders podem ser utilizados para este fim.

> üí° **Exemplo Num√©rico:**
>
> Ap√≥s a busca inicial por similaridade, temos as seguintes pontua√ß√µes de relev√¢ncia para as 5 principais frases:
>
> | Frase | Similaridade Cosseno |
> |-------|----------------------|
> |   1   | 0.99                 |
> |   2   | 0.95                 |
> |   3   | 0.92                 |
> |   4   | 0.90                 |
> |   5   | 0.88                 |
>
> Um modelo de re-ranking (e.g., um cross-encoder) analisa cada frase no contexto da consulta e atribui novas pontua√ß√µes de relev√¢ncia:
>
> | Frase | Similaridade Cosseno | Pontua√ß√£o Re-ranking |
> |-------|----------------------|----------------------|
> |   1   | 0.99                 | 0.98                 |
> |   2   | 0.95                 | 0.97                 |
> |   3   | 0.92                 | 0.93                 |
> |   4   | 0.90                 | 0.85                 |
> |   5   | 0.88                 | 0.80                 |
>
> Neste exemplo, o modelo de re-ranking aumentou a pontua√ß√£o da Frase 2, indicando que, embora sua similaridade cosseno fosse ligeiramente inferior √† da Frase 1, o re-ranker determinou que ela √©, de fato, mais relevante no contexto da consulta. A Frase 2 agora seria priorizada.

Ainda sobre a formaliza√ß√£o, podemos definir uma fun√ß√£o para representar o conte√∫do informacional da janela de contexto.

**Defini√ß√£o:** Seja $I(Window(s^*, k))$ o conte√∫do informacional da janela de contexto $Window(s^*, k)$.

O conte√∫do informacional pode ser quantificado de diversas formas, dependendo da aplica√ß√£o. Por exemplo, pode-se usar medidas de entropia ou similaridade sem√¢ntica entre as frases na janela. Uma janela com alta similaridade sem√¢ntica entre suas frases tende a ser mais coerente e informativa.

**Vantagens do Sentence Window Retrieval:**
*   **Precis√£o Aprimorada:** Ao incorporar frases individualmente, o sistema pode identificar nuances e contextos espec√≠ficos que seriam perdidos em uma abordagem de n√≠vel de documento ou par√°grafo.
*   **Relev√¢ncia Contextual:** A expans√£o da janela de contexto garante que o LLM receba informa√ß√µes adicionais que ajudam a contextualizar a frase mais relevante, resultando em respostas mais coerentes e informativas.
*   **Flexibilidade:** O tamanho da janela de contexto pode ser ajustado para equilibrar a quantidade de informa√ß√µes fornecidas ao LLM com o ru√≠do potencial de informa√ß√µes irrelevantes.

**Implementa√ß√£o:**
A implementa√ß√£o do Sentence Window Retrieval pode ser realizada usando bibliotecas Python como `SentenceTransformers` para embedding de frases e `FAISS` ou `Annoy` para indexa√ß√£o vetorial e busca por similaridade. As etapas envolvem:
1.  Carregar o documento e dividir em frases.
2.  Calcular os embeddings das frases.
3.  Criar um √≠ndice vetorial.
4.  Receber a consulta do usu√°rio e calcular seu embedding.
5.  Buscar as frases mais similares no √≠ndice.
6.  Expandir a janela de contexto.
7.  Passar o contexto expandido para o LLM para gera√ß√£o de resposta.

**Exemplo:**
Considere um documento sobre a hist√≥ria da intelig√™ncia artificial. Uma consulta do usu√°rio poderia ser: "Quais foram os principais desafios no desenvolvimento do aprendizado profundo?". O Sentence Window Retrieval identificaria a frase mais relevante, por exemplo: "*Um dos principais desafios no desenvolvimento do aprendizado profundo foi a necessidade de grandes quantidades de dados rotulados*". A janela de contexto ent√£o incluiria frases vizinhas, como "*Inicialmente, as redes neurais enfrentaram dificuldades em lidar com problemas complexos devido √† falta de dados e poder computacional. A disponibilidade limitada de dados rotulados restringia a capacidade de treinar modelos profundos de forma eficaz.*" e "*Com o advento de conjuntos de dados maiores e avan√ßos no hardware, o aprendizado profundo come√ßou a superar os m√©todos tradicionais em v√°rias tarefas.*". Este contexto expandido permite que o LLM gere uma resposta mais completa e precisa.

**Teorema 2** [Sentence Window Retrieval with Metadata Filtering]
A incorpora√ß√£o de filtragem baseada em metadados no processo de Sentence Window Retrieval pode melhorar ainda mais a precis√£o e relev√¢ncia do contexto recuperado.

*Discuss√£o:*
Metadados associados √†s frases (e.g., fonte, data de cria√ß√£o, autor) podem ser utilizados para restringir a busca por similaridade apenas a um subconjunto de frases que satisfazem determinados crit√©rios. Por exemplo, pode-se filtrar as frases por data para recuperar apenas informa√ß√µes recentes, ou por fonte para priorizar informa√ß√µes de fontes confi√°veis.

> üí° **Exemplo Num√©rico:**
>
> Suponha que cada frase em nosso corpus tenha metadados indicando a data de publica√ß√£o. Queremos responder √† consulta "Qual a abordagem mais recente para resolver X?". Podemos filtrar as frases para incluir apenas aquelas publicadas nos √∫ltimos 5 anos.
>
> Inicialmente, o sistema recupera 10 frases com alta similaridade cosseno. No entanto, apenas 3 dessas frases foram publicadas nos √∫ltimos 5 anos:
>
> | Frase | Similaridade Cosseno | Data de Publica√ß√£o |
> |-------|----------------------|-------------------|
> |   1   | 0.99                 | 2010              |
> |   2   | 0.95                 | 2022              |
> |   3   | 0.92                 | 2018              |
> |   4   | 0.90                 | 2015              |
> |   5   | 0.88                 | 2005              |
> |   6   | 0.85                 | 2023              |
> |   7   | 0.82                 | 2019              |
> |   8   | 0.80                 | 2012              |
> |   9   | 0.78                 | 2000              |
> |   10  | 0.75                 | 2017              |
>
> Ap√≥s a filtragem por data (considerando apenas os √∫ltimos 5 anos), apenas as frases 2, 3, 6 e 7 s√£o consideradas. A frase 6 (publicada em 2023) pode agora ser a frase mais relevante ap√≥s a filtragem, mesmo que sua similaridade cosseno inicial fosse menor do que a da Frase 1.

**Corol√°rio 2.1** [Metadata-Aware Window Expansion]
A expans√£o da janela de contexto pode ser adaptada para considerar os metadados das frases vizinhas. Por exemplo, a janela pode ser expandida preferencialmente em dire√ß√£o a frases com metadados semelhantes √† frase mais relevante.

### Conclus√£o
O **Sentence Window Retrieval** representa uma t√©cnica valiosa para **Context Enrichment** em sistemas RAG com LLMs. Sua capacidade de focar na granularidade da frase, combinada com a expans√£o da janela de contexto, resulta em uma recupera√ß√£o de contexto mais precisa e relevante. A flexibilidade no ajuste do tamanho da janela permite otimizar o desempenho do sistema para diferentes tipos de consultas e documentos. Ao integrar o Sentence Window Retrieval em sistemas RAG, √© poss√≠vel melhorar significativamente a qualidade das respostas geradas pelo LLM.

### Refer√™ncias
[^2]: Descri√ß√£o do Sentence Window Retrieval como uma t√©cnica para aumentar a granularidade da busca de contexto para o n√≠vel da frase, resultando em maior precis√£o na identifica√ß√£o de segmentos textuais relevantes.
<!-- END -->