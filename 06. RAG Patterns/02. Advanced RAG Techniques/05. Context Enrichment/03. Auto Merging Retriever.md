## Auto-Merging Retriever: Contexto Extendido para RAG

### Introdu√ß√£o

O *Retrieval-Augmented Generation* (RAG) tem se mostrado uma abordagem eficaz para integrar conhecimento externo em modelos de linguagem grandes (LLMs). Um dos desafios centrais no RAG √© garantir que o LLM receba contexto suficiente e relevante para gerar respostas precisas e informativas. O Auto-merging Retriever, tamb√©m conhecido como Parent Document Retriever, surge como uma solu√ß√£o para este desafio, explorando a ideia de buscar informa√ß√µes em granularidades menores e, em seguida, ampliar o contexto fornecido ao LLM [^3]. Este cap√≠tulo detalha o funcionamento e os benef√≠cios do Auto-merging Retriever, focando em como ele supera as limita√ß√µes dos m√©todos de recupera√ß√£o tradicionais ao lidar com documentos complexos e informa√ß√µes inter-relacionadas.

### Conceitos Fundamentais

O Auto-merging Retriever endere√ßa o problema da granularidade no contexto de RAG. Em abordagens de recupera√ß√£o mais simples, os documentos s√£o geralmente divididos em *chunks* (peda√ßos) menores para indexa√ß√£o e recupera√ß√£o. No entanto, essa divis√£o pode levar √† perda de contexto importante, pois as rela√ß√µes entre diferentes partes do documento podem n√£o ser capturadas. O Auto-merging Retriever resolve este problema ao introduzir uma hierarquia de *chunks* pai e filho [^3].

A ideia central √©:

1.  **Divis√£o em *Chunks* Filhos:** Inicialmente, os documentos s√£o divididos em *chunks* menores, que s√£o indexados e utilizados para a busca inicial. Estes s√£o os *chunks* filhos, representando unidades de informa√ß√£o mais granulares.
2.  **Cria√ß√£o de *Chunks* Pais:** *Chunks* filhos s√£o agrupados para formar *chunks* pais maiores, representando um contexto mais amplo. Cada *chunk* filho mant√©m uma refer√™ncia ao seu *chunk* pai.
3.  **Recupera√ß√£o Inicial:** A busca √© realizada nos *chunks* filhos.
4.  **Expans√£o do Contexto:** Se um *chunk* filho relevante √© encontrado, o sistema recupera o *chunk* pai correspondente. Isso permite que o LLM tenha acesso tanto √† informa√ß√£o granular quanto ao contexto mais amplo [^3].
5.  **Auto-Merging (Opcional):** Em algumas implementa√ß√µes, *chunks* pais que s√£o adjacentes e relevantes podem ser automaticamente combinados (*merged*) para formar um contexto ainda maior. Isso √© particularmente √∫til quando a resposta √† pergunta requer informa√ß√µes distribu√≠das em v√°rias se√ß√µes do documento.

Essa abordagem hier√°rquica permite que o sistema capture tanto a especificidade das informa√ß√µes contidas nos *chunks* filhos quanto o contexto mais amplo fornecido pelos *chunks* pais [^3].

![Parent-child chunks retrieval enhances context for LLMs by merging related leaf chunks into a larger parent chunk during retrieval.](./../images/image10.png)

**Proposi√ß√£o 1:** *A efic√°cia do Auto-merging Retriever depende criticamente da qualidade da rela√ß√£o sem√¢ntica entre os chunks filhos e seus respectivos chunks pais. Se a rela√ß√£o n√£o for forte, a recupera√ß√£o do chunk pai pode introduzir ru√≠do em vez de contexto relevante.*

*Prova (esbo√ßo):* A premissa do Auto-merging Retriever √© que o chunk pai fornece um contexto relevante para o chunk filho. Se o chunk pai contiver informa√ß√µes n√£o relacionadas ou fracamente relacionadas ao chunk filho, o LLM receber√° informa√ß√µes desnecess√°rias que podem diluir o sinal relevante, prejudicando a gera√ß√£o da resposta. A qualidade da rela√ß√£o sem√¢ntica pode ser medida por m√©tricas de similaridade sem√¢ntica entre os embeddings dos chunks filhos e pais. $\blacksquare$

**Vantagens do Auto-merging Retriever:**

*   **Melhor Contexto para o LLM:** Ao fornecer *chunks* pais, o LLM tem acesso a um contexto mais completo e relevante, o que pode levar a respostas mais precisas e informativas.
*   **Redu√ß√£o da Perda de Informa√ß√£o:** A hierarquia de *chunks* ajuda a preservar as rela√ß√µes entre diferentes partes do documento, evitando a perda de informa√ß√£o que pode ocorrer com a divis√£o em *chunks* independentes.
*   **Flexibilidade na Granularidade:** O sistema pode ajustar o tamanho dos *chunks* filhos e pais para otimizar o desempenho da recupera√ß√£o e a qualidade das respostas.
*   **Capacidade de Lidar com Documentos Complexos:** O Auto-merging Retriever √© particularmente √∫til para documentos longos e complexos, onde a informa√ß√£o relevante pode estar distribu√≠da em v√°rias se√ß√µes [^3].

**Implementa√ß√£o e Considera√ß√µes Pr√°ticas:**

A implementa√ß√£o do Auto-merging Retriever envolve v√°rias etapas:

1.  **Defini√ß√£o da Estrat√©gia de *Chunking*:** √â crucial definir uma estrat√©gia de *chunking* adequada, determinando o tamanho dos *chunks* filhos e pais. Essa escolha deve levar em considera√ß√£o a estrutura dos documentos e a natureza das perguntas que ser√£o feitas ao sistema.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um documento sobre "Fotoss√≠ntese". Podemos considerar duas estrat√©gias de *chunking*:
>
> **Estrat√©gia 1 (Chunks pequenos):**
> *   *Chunk* Filho 1: "A fotoss√≠ntese √© um processo..." (10 palavras)
> *   *Chunk* Filho 2: "As plantas usam clorofila..." (8 palavras)
> *   *Chunk* Pai 1: "Introdu√ß√£o √† Fotoss√≠ntese" (Cont√©m Chunk Filho 1 e 2)
>
> **Estrat√©gia 2 (Chunks maiores):**
> *   *Chunk* Filho 1: "A fotoss√≠ntese √© um processo pelo qual as plantas, algas e algumas bact√©rias convertem energia luminosa em energia qu√≠mica..." (25 palavras)
> *   *Chunk* Filho 2: "As plantas usam clorofila e outros pigmentos para capturar a luz solar..." (20 palavras)
> *   *Chunk* Pai 1: "Introdu√ß√£o √† Fotoss√≠ntese" (Cont√©m Chunk Filho 1 e 2)
>
> | Estrat√©gia | Tamanho M√©dio Chunk Filho | Contexto Granular | Contexto Amplo | Adequa√ß√£o para Perguntas Simples | Adequa√ß√£o para Perguntas Complexas |
> |------------|--------------------------|-------------------|---------------|---------------------------------|-----------------------------------|
> | 1          | 9 palavras               | Sim               | N√£o           | Boa                              | Ruim                              |
> | 2          | 22.5 palavras              | Moderado          | Sim           | Moderada                         | Boa                              |
>
> A Estrat√©gia 1 √© boa para perguntas diretas sobre defini√ß√µes. A Estrat√©gia 2 √© melhor para perguntas que requerem um entendimento mais profundo do processo.

2.  **Cria√ß√£o dos √çndices:** √çndices separados podem ser criados para os *chunks* filhos e pais, ou um √∫nico √≠ndice pode ser utilizado com metadados para identificar a rela√ß√£o entre eles.

**Teorema 1:** *Utilizar um √∫nico √≠ndice com metadados para chunks filhos e pais pode otimizar o uso da mem√≥ria, mas introduz complexidade na l√≥gica de busca. Criar √≠ndices separados simplifica a busca, mas aumenta o consumo de mem√≥ria.*

*Prova (esbo√ßo):* Um √∫nico √≠ndice requer que cada entrada contenha informa√ß√µes sobre se √© um chunk pai ou filho, bem como o relacionamento entre eles. A busca nesse √≠ndice requer filtragem baseada nesses metadados, aumentando a complexidade. √çndices separados permitem buscas diretas, mas duplicam (parcialmente) os dados, aumentando o consumo de mem√≥ria. A escolha depende das restri√ß√µes de mem√≥ria e dos requisitos de desempenho da busca. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Vamos supor que temos 1000 *chunks* filhos e 100 *chunks* pais. Cada *chunk* filho tem um ID e um ponteiro para o ID do seu *chunk* pai.
>
> **Op√ß√£o 1: √çndice √önico**
>
> *   Tamanho do √≠ndice: 1100 entradas.
> *   Cada entrada cont√©m: Texto do *chunk*, ID do *chunk*, Tipo (*pai* ou *filho*), ID do *chunk* pai (se for filho).
> *   Complexidade da busca: Requer filtrar por tipo de *chunk* e potencialmente seguir o ponteiro para o *chunk* pai.
>
> **Op√ß√£o 2: √çndices Separados**
>
> *   Tamanho total dos √≠ndices: 1000 (filhos) + 100 (pais) = 1100 entradas.
> *   √çndice dos filhos: Texto do *chunk*, ID do *chunk*, ID do *chunk* pai.
> *   √çndice dos pais: Texto do *chunk*, ID do *chunk*.
> *   Complexidade da busca: Busca direta em um √≠ndice para *chunks* filhos, busca separada no √≠ndice dos pais se necess√°rio.
>
> Se o tamanho do texto em cada *chunk* for grande, a diferen√ßa no uso da mem√≥ria pode ser significativa se chunks pais e filhos tiverem textos muito similares (levando a duplica√ß√£o). Caso contr√°rio, a sobrecarga do √≠ndice em si √© o fator determinante.

3.  **Implementa√ß√£o do Mecanismo de Recupera√ß√£o:** O mecanismo de recupera√ß√£o deve ser capaz de buscar nos *chunks* filhos e, em seguida, recuperar os *chunks* pais correspondentes.

> üí° **Exemplo Num√©rico:**
>
> Uma consulta "Qual o papel da clorofila na fotoss√≠ntese?" √© feita.
>
> $\text{Step 1: Busca nos chunks filhos}$
>
> Suponha que o sistema BM25 retorna os seguintes scores para 3 *chunks* filhos:
>
> *   *Chunk* Filho 1: "As plantas usam clorofila..." - Score: 0.8
> *   *Chunk* Filho 2: "A fotoss√≠ntese produz glicose..." - Score: 0.2
> *   *Chunk* Filho 3: "Clorofila absorve luz..." - Score: 0.75
>
> $\text{Step 2: Seleciona o chunk filho mais relevante (threshold = 0.5)}$
>
> *Chunk* Filho 1 √© selecionado.
>
> $\text{Step 3: Recupera o chunk pai correspondente}$
>
> Suponha que o *Chunk* Filho 1 pertence ao *Chunk* Pai "Mecanismos da Fotoss√≠ntese".
>
> O LLM recebe o *Chunk* Filho 1 e o *Chunk* Pai "Mecanismos da Fotoss√≠ntese" como contexto.

4.  **Estrat√©gia de Auto-Merging (Opcional):** Se o auto-merging for implementado, √© necess√°rio definir crit√©rios para determinar quando *chunks* pais adjacentes devem ser combinados.

**Lema 1:** *A estrat√©gia de auto-merging deve considerar a similaridade sem√¢ntica entre chunks pais adjacentes para evitar a combina√ß√£o de contextos n√£o relacionados.*

*Prova (esbo√ßo):* Se dois chunks pais adjacentes forem combinados sem levar em considera√ß√£o sua similaridade sem√¢ntica, o contexto resultante pode ser incoerente ou irrelevante para a consulta original. Isso pode levar a respostas piores do LLM. A similaridade sem√¢ntica pode ser medida usando embeddings e m√©tricas de dist√¢ncia. Um limiar de similaridade deve ser definido para determinar quando a combina√ß√£o √© apropriada. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos dois *chunks* pais adjacentes:
>
> *   *Chunk* Pai 1: "Mecanismos da Fotoss√≠ntese"
> *   *Chunk* Pai 2: "Fatores que afetam a Fotoss√≠ntese"
>
> $\text{Step 1: Calcula Embeddings}$
>
> Usamos um modelo de embedding para gerar vetores para cada *chunk* pai:
>
> *   Embedding(*Chunk* Pai 1) = $\vec{v_1}$
> *   Embedding(*Chunk* Pai 2) = $\vec{v_2}$
>
> $\text{Step 2: Calcula a similaridade de cossenos}$
>
> $\text{Cosine Similarity} = \frac{\vec{v_1} \cdot \vec{v_2}}{||\vec{v_1}|| \cdot ||\vec{v_2}||}$
>
> Suponha que a similaridade de cossenos seja 0.85.
>
> $\text{Step 3: Compara com o threshold}$
>
> Se o threshold de similaridade for 0.8, os *chunks* pais ser√£o combinados, pois 0.85 > 0.8. Se o threshold fosse 0.9, eles n√£o seriam combinados.

**Exemplo:**

Considere um longo documento sobre a hist√≥ria da computa√ß√£o.

1.  O documento √© dividido em *chunks* filhos menores, cada um contendo um par√°grafo ou se√ß√£o espec√≠fica (e.g., "A inven√ß√£o do transistor," "O desenvolvimento da internet").
2.  Esses *chunks* filhos s√£o agrupados em *chunks* pais maiores, cada um representando um cap√≠tulo ou se√ß√£o do documento (e.g., "A Era dos Semicondutores," "A Ascens√£o da Internet").
3.  Quando um usu√°rio pergunta "Quem inventou o transistor?", o sistema busca nos *chunks* filhos e encontra o *chunk* "A inven√ß√£o do transistor".
4.  Em seguida, o sistema recupera o *chunk* pai correspondente, "A Era dos Semicondutores", fornecendo ao LLM um contexto mais amplo sobre a inven√ß√£o do transistor [^3].

**Desafios e Limita√ß√µes:**

Embora o Auto-merging Retriever ofere√ßa v√°rias vantagens, ele tamb√©m apresenta alguns desafios:

*   **Complexidade da Implementa√ß√£o:** A implementa√ß√£o do Auto-merging Retriever √© mais complexa do que a de abordagens de recupera√ß√£o mais simples.
*   **Overhead Computacional:** A recupera√ß√£o dos *chunks* pais adiciona um overhead computacional ao processo de recupera√ß√£o.
*   **Escolha Adequada dos Tamanhos de *Chunk*:** A escolha dos tamanhos de *chunk* filhos e pais pode ser crucial para o desempenho do sistema.
*   **Complexidade da Estrat√©gia de Auto-Merging:** Determinar quais *chunks* pais devem ser combinados pode ser um desafio, especialmente em documentos complexos e n√£o estruturados.

**Teorema 2:** *O tamanho √≥timo dos chunks filhos e pais √© dependente da densidade informacional do documento e da complexidade das consultas esperadas.*

*Prova (esbo√ßo):* Um documento com alta densidade informacional requer chunks menores para evitar a dilui√ß√£o da informa√ß√£o relevante. Consultas complexas, que exigem um contexto amplo, se beneficiam de chunks pais maiores. Portanto, o tamanho √≥timo √© um compromisso entre esses dois fatores, podendo ser determinado empiricamente atrav√©s de testes A/B com diferentes tamanhos de chunk e m√©tricas de avalia√ß√£o de resposta do LLM (e.g., precis√£o, relev√¢ncia, completude). $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que estamos ajustando os par√¢metros de chunking para um RAG que responde a perguntas sobre artigos cient√≠ficos.
>
> | Tamanho Chunk Filho | Tamanho Chunk Pai | Precis√£o | Recall | Tempo de Resposta (s) |
> |----------------------|--------------------|----------|--------|------------------------|
> | 100 palavras        | 500 palavras       | 0.75     | 0.65   | 2.5                    |
> | 200 palavras        | 1000 palavras      | 0.80     | 0.70   | 3.0                    |
> | 50 palavras         | 250 palavras       | 0.70     | 0.60   | 2.0                    |
>
> Observamos que o tamanho de chunk filho de 200 palavras e pai de 1000 palavras oferece o melhor equil√≠brio entre precis√£o, recall e tempo de resposta para este conjunto de dados e tipo de consulta.

### Conclus√£o

O Auto-merging Retriever representa um avan√ßo significativo nas t√©cnicas de RAG, permitindo que os LLMs acessem e utilizem informa√ß√µes de forma mais eficaz. Ao combinar a granularidade fina dos *chunks* filhos com o contexto mais amplo dos *chunks* pais, o Auto-merging Retriever ajuda a superar as limita√ß√µes dos m√©todos de recupera√ß√£o tradicionais e a gerar respostas mais precisas, informativas e contextualmente relevantes.  Embora a implementa√ß√£o possa ser mais complexa, os benef√≠cios em termos de qualidade da resposta e capacidade de lidar com documentos complexos justificam o esfor√ßo. As considera√ß√µes sobre estrat√©gias de *chunking* adequadas e os trade-offs de desempenho s√£o cruciais para otimizar o uso desta t√©cnica.

### Refer√™ncias

[^3]: Informa√ß√µes retiradas da descri√ß√£o do t√≥pico: "Auto-merging Retriever (also known as Parent Document Retriever) searches for granular pieces of information and extends the context window by splitting documents into smaller child chunks that reference larger parent chunks, feeding this extended context to the LLM for reasoning."
<!-- END -->