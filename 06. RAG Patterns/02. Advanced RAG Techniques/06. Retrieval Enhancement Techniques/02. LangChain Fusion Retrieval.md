## Recupera√ß√£o Fusionada com LangChain e LlamaIndex

### Introdu√ß√£o

A recupera√ß√£o aprimorada (Retrieval Enhancement) busca otimizar o processo de busca e sele√ß√£o de documentos relevantes para uma dada consulta, maximizando a precis√£o e abrang√™ncia das informa√ß√µes recuperadas. Um dos m√©todos para alcan√ßar tal objetivo √© a **recupera√ß√£o fusionada**, que combina diferentes *retrievers* e emprega t√©cnicas de reordena√ß√£o para refinar os resultados. Este cap√≠tulo explora a implementa√ß√£o da recupera√ß√£o fusionada utilizando as bibliotecas LangChain e LlamaIndex, focando no uso do *Rank Aggregation* Rec√≠proco (RRF) para reordena√ß√£o.

### Conceitos Fundamentais

**Recupera√ß√£o Fusionada (Fusion Retrieval)**: Consiste em utilizar m√∫ltiplos *retrievers* (indexadores e mecanismos de busca) para obter um conjunto mais diversificado de documentos relevantes. A ideia central √© que cada *retriever* pode capturar diferentes aspectos da relev√¢ncia, e a combina√ß√£o de seus resultados pode levar a uma melhor cobertura das informa√ß√µes relevantes.

**Rank Aggregation Rec√≠proco (RRF)**: √â um algoritmo de reordena√ß√£o que combina as classifica√ß√µes de diferentes *retrievers* em uma √∫nica classifica√ß√£o final. O RRF atribui pontua√ß√µes mais altas aos documentos que aparecem no topo da lista de v√°rios *retrievers*. A pontua√ß√£o RRF para um documento √© calculada como a soma do inverso do seu rank em cada lista de *retriever*, ajustada por uma constante $k$.

> üí° **Exemplo Num√©rico:** Imagine que temos dois retrievers. O Documento A est√° em primeiro lugar no Retriever 1 e em terceiro lugar no Retriever 2. O Documento B est√° em segundo lugar no Retriever 1 e em segundo lugar no Retriever 2. Usando k=10, o score RRF do Documento A √© (1/(10+1)) + (1/(10+3)) = 0.091 + 0.077 = 0.168. O score RRF do Documento B √© (1/(10+2)) + (1/(10+2)) = 0.083 + 0.083 = 0.166. Neste caso, o Documento A seria classificado ligeiramente acima do Documento B.

**LangChain e LlamaIndex**: S√£o frameworks que facilitam a constru√ß√£o de aplica√ß√µes de *Retrieval-Augmented Generation* (RAG). Ambos oferecem ferramentas e classes para implementar diversas t√©cnicas de recupera√ß√£o, incluindo a recupera√ß√£o fusionada.

### Implementa√ß√£o com LangChain

A LangChain oferece a classe `EnsembleRetriever` para implementar a recupera√ß√£o fusionada [^1]. Essa classe permite combinar m√∫ltiplos *retrievers* e aplicar um algoritmo de reordena√ß√£o, como o RRF, para gerar uma lista final de documentos classificados.

**Passos para implementar a recupera√ß√£o fusionada com LangChain:**

1.  **Criar m√∫ltiplos retrievers**: Inicialize diferentes *retrievers* com diferentes configura√ß√µes ou usando diferentes fontes de dados. Por exemplo, voc√™ pode ter um *retriever* baseado em similaridade de cossenos e outro baseado em busca sem√¢ntica.

    > üí° **Exemplo Num√©rico:** Suponha que voc√™ tem um retriever baseado em TF-IDF e outro baseado em embeddings. O TF-IDF retriever retorna 5 documentos, enquanto o retriever de embeddings retorna outros 5. O EnsembleRetriever combinar√° esses resultados.

2.  **Instanciar o `EnsembleRetriever`**: Crie uma inst√¢ncia de `EnsembleRetriever`, passando uma lista de *retrievers* e o m√©todo de reordena√ß√£o desejado.

3.  **Executar a busca**: Utilize o m√©todo `get_relevant_documents` do `EnsembleRetriever` para realizar a busca. O m√©todo combinar√° os resultados dos *retrievers* subjacentes e aplicar√° o algoritmo de reordena√ß√£o para gerar a lista final de documentos relevantes.

**Exemplo de c√≥digo (ilustrativo):**

```python
from langchain.retrievers import EnsembleRetriever
from langchain.retrievers import BM25Retriever, VectorDBRetriever
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma

# Carregar documentos de exemplo
loader = TextLoader("state_of_the_union.txt")  # Substitua pelo caminho do seu arquivo
documents = loader.load()

# Dividir os documentos em partes menores
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Inicializar embeddings
embeddings = OpenAIEmbeddings()

# Criar um VectorDBRetriever
db = Chroma.from_documents(texts, embeddings)
vectorstore_retriever = VectorDBRetriever(vectorstore=db)

# Criar um BM25Retriever
bm25_retriever = BM25Retriever.from_documents(texts)
bm25_retriever.k = 3 # N√∫mero de documentos a serem retornados pelo BM25

vectorstore_retriever.k = 3 # N√∫mero de documentos a serem retornados pelo VectorDB


ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, vectorstore_retriever], weights=[0.5, 0.5])

docs = ensemble_retriever.get_relevant_documents("Qual o melhor m√©todo para...")
print(docs)
```

Neste exemplo, `bm25_retriever` e `vectorstore_retriever` representam dois *retrievers* distintos. O `EnsembleRetriever` combina seus resultados, ponderando-os igualmente (weights=[0.5, 0.5]). A fun√ß√£o `get_relevant_documents` retorna os documentos mais relevantes, reordenados pelo algoritmo de RRF (ou outro especificado).

> üí° **Exemplo Num√©rico:** Suponha que o `bm25_retriever` retorna os documentos D1, D2 e D3, enquanto o `vectorstore_retriever` retorna D2, D4 e D5. O `EnsembleRetriever` combinar√° esses resultados e aplicar√° o RRF. Se k=10, e as posi√ß√µes forem D1 (BM25=1), D2 (BM25=2, VectorDB=1), D3 (BM25=3), D4 (VectorDB=2), D5 (VectorDB=3), os scores RRF seriam: D1: 1/(10+1) = 0.091, D2: 1/(10+2) + 1/(10+1) = 0.083 + 0.091 = 0.174, D3: 1/(10+3) = 0.077, D4: 1/(10+2) = 0.083, D5: 1/(10+3) = 0.077. Portanto, a ordem final seria D2, D1, D4, D3, D5.

**Reordena√ß√£o com RRF:**

O RRF √© um m√©todo eficaz para combinar resultados de diferentes *retrievers* devido √† sua capacidade de dar maior peso aos documentos que s√£o considerados relevantes por m√∫ltiplos *retrievers*. A f√≥rmula geral para o RRF √©:

$$
RRF\_score(d) = \sum_{i=1}^{N} \frac{1}{k + rank_i(d)}
$$

Onde:

*   $RRF\_score(d)$ √© a pontua√ß√£o RRF do documento *d*.
*   $N$ √© o n√∫mero de *retrievers*.
*   $rank_i(d)$ √© a posi√ß√£o do documento *d* na lista de resultados do *retriever* *$i$*.
*   $k$ √© uma constante de ajuste (tipicamente 10).

A constante $k$ serve para atenuar o impacto de *retrievers* que classificam documentos irrelevantes no topo da lista.

> üí° **Exemplo Num√©rico:** Se k=10, um documento classificado em primeiro lugar tem um score de 1/(10+1) = 0.091. Se k=100, o score seria 1/(100+1) = 0.0099. Um valor maior de k suaviza a import√¢ncia dos ranks mais altos.

**Teorema 1** [Pondera√ß√£o √ìtima de Retrievers]: A escolha dos pesos para cada retriever no `EnsembleRetriever` impacta diretamente na qualidade dos resultados. A determina√ß√£o dos pesos √≥timos pode ser formulada como um problema de otimiza√ß√£o, buscando maximizar uma m√©trica de avalia√ß√£o (e.g., precision@k, recall@k, MAP) em um conjunto de dados de valida√ß√£o.

*Estrat√©gia de Prova:* A prova envolve formular o problema de otimiza√ß√£o, definir uma fun√ß√£o objetivo baseada em uma m√©trica de avalia√ß√£o, e aplicar algoritmos de otimiza√ß√£o (e.g., gradiente descendente, algoritmos gen√©ticos) para encontrar os pesos que maximizam a fun√ß√£o objetivo. A valida√ß√£o √© crucial para evitar overfitting aos dados de treinamento.

> üí° **Exemplo Num√©rico:** Suponha que temos dois retrievers, A e B. Para otimizar os pesos, podemos testar combina√ß√µes como (0.1, 0.9), (0.2, 0.8), (0.3, 0.7)... (0.9, 0.1) e medir a precis√£o@5 para cada combina√ß√£o. A combina√ß√£o que resultar na maior precis√£o@5 ser√° considerada a ideal.

### Implementa√ß√£o com LlamaIndex

LlamaIndex tamb√©m oferece funcionalidades para implementar a recupera√ß√£o fusionada, embora a implementa√ß√£o espec√≠fica possa variar em compara√ß√£o com LangChain. A ideia geral √© similar: combinar os resultados de diferentes *retrievers* e usar um algoritmo de reordena√ß√£o para refinar os resultados.

**Passos para implementar a recupera√ß√£o fusionada com LlamaIndex:**

1.  **Criar m√∫ltiplos Indexadores e Query Engines**: Construa diferentes indexadores (e.g., `VectorStoreIndex`, `KeywordTableIndex`) e *query engines* com diferentes configura√ß√µes ou usando diferentes fontes de dados.

    > üí° **Exemplo Num√©rico:** Podemos criar um `VectorStoreIndex` usando embeddings de senten√ßas e um `KeywordTableIndex` que indexa documentos com base em palavras-chave.

2.  **Combinar os resultados**: LlamaIndex oferece diferentes estrat√©gias para combinar os resultados dos *query engines*, incluindo a agrega√ß√£o simples, a pondera√ß√£o por confian√ßa e o uso de modelos de *reranking*.

3.  **Executar a busca**: Execute a busca utilizando os *query engines* combinados. LlamaIndex ir√° combinar os resultados e aplicar a estrat√©gia de reordena√ß√£o escolhida.

**Exemplo de c√≥digo (ilustrativo):**

```python
from llama_index import VectorStoreIndex, KeywordTableIndex, SimpleDirectoryReader
from llama_index.query_engine import SubQuestionQueryEngine
from llama_index.tools import QueryEngineTool, ToolMetadata
from llama_index import Document

# Suponha que voc√™ j√° tenha criado dois indexadores: vector_index e keyword_index
# Criar documentos de exemplo
documents = [
    Document(text="O c√©u √© azul."),
    Document(text="A grama √© verde."),
    Document(text="O sol √© amarelo."),
    Document(text="A lua √© branca.")
]

vector_index = VectorStoreIndex.from_documents(documents)
keyword_index = KeywordTableIndex.from_documents(documents)

# Crie QueryEngineTools para cada indexador
vector_tool = QueryEngineTool(
    query_engine=vector_index.as_query_engine(),
    metadata=ToolMetadata(name="vector_tool", description="√ötil para encontrar informa√ß√µes com base em similaridade sem√¢ntica."),
)

keyword_tool = QueryEngineTool(
    query_engine=keyword_index.as_query_engine(),
    metadata=ToolMetadata(name="keyword_tool", description="√ötil para encontrar informa√ß√µes com base em palavras-chave."),
)

# Combine os QueryEngineTools usando SubQuestionQueryEngine
from llama_index.retrievers import ToolRetriever
from llama_index.query_engine import RouterQueryEngine

tool_retriever = ToolRetriever(tools=[vector_tool, keyword_tool])
query_engine = RouterQueryEngine.from_defaults(retriever=tool_retriever)


response = query_engine.query("Qual a cor do c√©u?")
print(response)
```

Neste exemplo, `vector_index` e `keyword_index` representam dois indexadores distintos. Os `QueryEngineTool`s encapsulam os *query engines* associados a cada indexador. O `SubQuestionQueryEngine` combina os resultados, dividindo a consulta em sub-perguntas e roteando-as para os *query engines* apropriados.

> üí° **Exemplo Num√©rico:** Se a consulta for "Cor do c√©u e da grama?", o `SubQuestionQueryEngine` pode dividir a consulta em "Qual a cor do c√©u?" e "Qual a cor da grama?". A primeira sub-pergunta pode ser roteada para o `vector_tool`, enquanto a segunda pode ser roteada para o `keyword_tool`, dependendo da descri√ß√£o no `ToolMetadata`.

**Proposi√ß√£o 1** [Relev√¢ncia da Descri√ß√£o da Ferramenta (ToolMetadata)]: A descri√ß√£o fornecida no `ToolMetadata` tem um impacto significativo no roteamento de consultas pelo `SubQuestionQueryEngine`. Descri√ß√µes mais precisas e informativas resultam em um roteamento mais eficaz das sub-perguntas para as ferramentas apropriadas.

*Estrat√©gia de Prova:* A prova pode ser realizada empiricamente, comparando o desempenho do `SubQuestionQueryEngine` com diferentes descri√ß√µes para as mesmas ferramentas em um conjunto de dados de avalia√ß√£o. M√©tricas como a precis√£o do roteamento e a qualidade das respostas geradas podem ser utilizadas para quantificar o impacto da descri√ß√£o.

> üí° **Exemplo Num√©rico:** Se a descri√ß√£o do `vector_tool` for alterada para "√ötil para encontrar informa√ß√µes gerais", o roteamento da consulta "Qual a cor do c√©u?" pode se tornar menos preciso.





![Diagram illustrating the Fusion Retrieval technique, combining keyword-based and semantic search for enhanced RAG.](./../images/image7.png)


### Vantagens e Desafios

**Vantagens:**

*   **Melhoria da Precis√£o**: Combinar m√∫ltiplos *retrievers* pode aumentar a precis√£o da busca, reduzindo o n√∫mero de falsos positivos.
*   **Aumento da Cobertura**: A recupera√ß√£o fusionada pode aumentar a cobertura das informa√ß√µes relevantes, garantindo que todos os aspectos importantes da consulta sejam abordados.
*   **Robustez**: A combina√ß√£o de diferentes *retrievers* torna o sistema mais robusto a ru√≠dos e varia√ß√µes nos dados.

**Desafios:**

*   **Complexidade**: A implementa√ß√£o da recupera√ß√£o fusionada pode ser mais complexa do que a utiliza√ß√£o de um √∫nico *retriever*.
*   **Custo Computacional**: A execu√ß√£o de m√∫ltiplos *retrievers* pode aumentar o custo computacional da busca.
*   **Ajuste de Par√¢metros**: A escolha dos *retrievers* a serem combinados e o ajuste dos par√¢metros do algoritmo de reordena√ß√£o (e.g., o valor de $k$ no RRF) podem ser desafiadores.

> üí° **Exemplo Num√©rico:** Se o BM25 √© muito mais r√°pido do que o retriever vetorial, o tempo total de resposta pode ser limitado pelo retriever vetorial. O custo computacional √© aditivo.

**Teorema 2** [Complexidade do RRF]: A complexidade computacional do algoritmo RRF √© O(N*M), onde N √© o n√∫mero de retrievers e M √© o n√∫mero m√°ximo de documentos retornados por cada retriever.

*Estrat√©gia de Prova:* A prova segue diretamente da an√°lise do algoritmo RRF. Para cada documento retornado por cada retriever, o algoritmo calcula a pontua√ß√£o RRF, o que requer O(1) opera√ß√µes. Como h√° N retrievers e cada um retorna no m√°ximo M documentos, a complexidade total √© O(N*M).

> üí° **Exemplo Num√©rico:** Se temos 3 retrievers (N=3) e cada um retorna no m√°ximo 10 documentos (M=10), ent√£o a complexidade do RRF √© O(3*10) = O(30).

### Conclus√£o

A recupera√ß√£o fusionada, implementada com LangChain e LlamaIndex, representa uma abordagem avan√ßada para melhorar o desempenho de sistemas de RAG. Ao combinar os pontos fortes de diferentes *retrievers* e utilizar t√©cnicas de reordena√ß√£o como o RRF, √© poss√≠vel obter resultados de busca mais precisos, abrangentes e robustos. A escolha da biblioteca e da estrat√©gia de implementa√ß√£o depender√° das necessidades espec√≠ficas da aplica√ß√£o e dos recursos dispon√≠veis.

### Refer√™ncias
[^1]: Adapta√ß√£o do conhecimento geral sobre a biblioteca LangChain, focando na classe `EnsembleRetriever` e seus componentes para recupera√ß√£o fusionada.
<!-- END -->