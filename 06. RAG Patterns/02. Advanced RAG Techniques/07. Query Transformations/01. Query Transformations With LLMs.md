## Transforma√ß√µes de Query com LLMs para Recupera√ß√£o de Informa√ß√£o Neural

### Introdu√ß√£o

A Recupera√ß√£o de Informa√ß√£o Neural (NIR) tem evolu√≠do significativamente com a incorpora√ß√£o de Large Language Models (LLMs). Uma √°rea promissora √© a transforma√ß√£o de *queries*, que utiliza LLMs para refinar a entrada do usu√°rio, visando melhorar a qualidade da recupera√ß√£o [^1]. Este cap√≠tulo explora as t√©cnicas de transforma√ß√£o de query, incluindo decomposi√ß√£o de query, *step-back prompting* e reescrita de query.

### Conceitos Fundamentais

A necessidade de transformar *queries* surge da complexidade inerente √† linguagem natural e das limita√ß√µes dos modelos de recupera√ß√£o em lidar diretamente com a ambiguidade ou falta de especificidade nas *queries* originais. LLMs, com sua capacidade de compreender e gerar texto, oferecem um meio poderoso para contornar essas limita√ß√µes.

**Teorema 1:** A transforma√ß√£o de query, se bem aplicada, pode aumentar a precis√£o e revoca√ß√£o da recupera√ß√£o de informa√ß√£o neural, dado que as *queries* transformadas representem melhor a inten√ß√£o do usu√°rio e se alinhem com a estrutura do √≠ndice de documentos.

**1. Decomposi√ß√£o de Query:**

A decomposi√ß√£o de *query* envolve a divis√£o de uma *query* complexa em sub-*queries* mais simples e focadas [^1]. O racioc√≠nio por tr√°s dessa t√©cnica √© que a recupera√ß√£o separada de informa√ß√µes relevantes para cada sub-*query* e, posteriormente, a combina√ß√£o dos resultados, pode levar a uma recupera√ß√£o mais precisa e abrangente.

*   **Processo:**
    1.  O LLM recebe a *query* original como entrada.
    2.  O LLM decomp√µe a *query* em um conjunto de sub-*queries*. A estrat√©gia de decomposi√ß√£o pode variar dependendo da complexidade da *query* e do conhecimento do dom√≠nio.
    3.  Cada sub-*query* √© usada para recuperar documentos relevantes.
    4.  Os resultados recuperados para cada sub-*query* s√£o combinados (e.g., por meio de interse√ß√£o, uni√£o ou ranking ponderado) para gerar o conjunto final de documentos recuperados.

*   **Exemplo:**
    Uma *query* como *"Quais foram os impactos econ√¥micos e sociais da pandemia de COVID-19 na ind√∫stria do turismo?"* pode ser decomposta em:

    *   Sub-*query* 1: *"Impactos econ√¥micos da pandemia de COVID-19 na ind√∫stria do turismo"*
    *   Sub-*query* 2: *"Impactos sociais da pandemia de COVID-19 na ind√∫stria do turismo"*

    A recupera√ß√£o √© realizada separadamente para cada sub-*query*, e os resultados s√£o combinados para fornecer uma resposta abrangente.

*   **Vantagens:**
    *   Lida melhor com *queries* complexas e multifacetadas.
    *   Permite a recupera√ß√£o de informa√ß√µes de diferentes perspectivas ou aspectos da *query* original.

*   **Desafios:**
    *   A qualidade da decomposi√ß√£o depende fortemente da capacidade do LLM de interpretar a *query* original.
    *   A combina√ß√£o dos resultados das sub-*queries* pode ser complexa e exigir t√©cnicas de ranking sofisticadas.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos 3 documentos e 2 sub-queries geradas pela decomposi√ß√£o da query original. Ap√≥s executar cada sub-query, obtemos os seguintes scores de relev√¢ncia para cada documento:
>
> | Documento | Sub-query 1 Score | Sub-query 2 Score |
> | --------- | ----------------- | ----------------- |
> | 1         | 0.8               | 0.2               |
> | 2         | 0.5               | 0.7               |
> | 3         | 0.1               | 0.9               |
>
> Uma simples combina√ß√£o linear, dando pesos iguais √†s sub-queries, resulta em:
>
> $\text{Final Score (Document i)} = 0.5 \times \text{Sub-query 1 Score (Document i)} + 0.5 \times \text{Sub-query 2 Score (Document i)}$
>
> Aplicando isso, obtemos:
>
> | Documento | Final Score |
> | --------- | ----------- |
> | 1         | 0.5         |
> | 2         | 0.6         |
> | 3         | 0.5         |
>
> Neste exemplo, o documento 2 seria classificado como o mais relevante ap√≥s a combina√ß√£o dos resultados das sub-queries.  Se atribuirmos pesos diferentes (por exemplo, 0.7 para sub-query 1 e 0.3 para sub-query 2), os resultados mudariam, demonstrando a import√¢ncia da pondera√ß√£o na combina√ß√£o dos resultados.

**Lema 1:** A efic√°cia da decomposi√ß√£o de query √© maximizada quando as subqueries s√£o ortogonais entre si, minimizando a redund√¢ncia na recupera√ß√£o de documentos e aumentando a diversidade dos resultados.

*Prova (Esbo√ßo):* A ortogonalidade das subqueries garante que cada subquery explore um aspecto diferente da query original. A redund√¢ncia √© reduzida porque cada subquery tende a recuperar um conjunto de documentos distintos. A combina√ß√£o dos resultados, portanto, abrange uma gama mais ampla de informa√ß√µes relevantes.

**1.1 Otimiza√ß√£o da Decomposi√ß√£o de Query:**

Para otimizar a decomposi√ß√£o de query, podemos considerar abordagens que envolvem a pondera√ß√£o das sub-*queries* com base em sua relev√¢ncia percebida para a *query* original. Al√©m disso, t√©cnicas de *clustering* podem ser aplicadas aos resultados das sub-*queries* para identificar e remover informa√ß√µes redundantes antes da combina√ß√£o final.

**2. *Step-Back Prompting***

*Step-back prompting* √© uma t√©cnica que envolve a utiliza√ß√£o de um LLM para gerar uma *query* mais gen√©rica e conceitual, retrocedendo a partir da *query* original [^1]. O objetivo √© capturar o contexto de alto n√≠vel e os princ√≠pios subjacentes √† *query* original, o que pode auxiliar na recupera√ß√£o de informa√ß√µes relevantes que podem n√£o ser diretamente relacionadas √† *query* original, mas que fornecem um contexto importante.

*   **Processo:**
    1.  O LLM recebe a *query* original como entrada.
    2.  O LLM gera uma *query* de "n√≠vel superior" que representa o conceito fundamental por tr√°s da *query* original.
    3.  A *query* de "n√≠vel superior" √© usada para recuperar documentos relevantes.
    4.  Os documentos recuperados s√£o combinados com os resultados da *query* original ou usados para refinar a resposta final.

*   **Exemplo:**
    *Query* original: *"Quais s√£o os tratamentos mais recentes para a doen√ßa de Alzheimer?"*

    *Query* de "n√≠vel superior" gerada pelo LLM: *"Pesquisa recente sobre tratamento de doen√ßas neurodegenerativas"*

    Ao recuperar informa√ß√µes sobre pesquisas recentes em doen√ßas neurodegenerativas, podemos obter *insights* que tamb√©m s√£o relevantes para o tratamento da doen√ßa de Alzheimer, mesmo que n√£o mencionem diretamente a doen√ßa.

*   **Vantagens:**
    *   Auxilia na recupera√ß√£o de informa√ß√µes contextuais e de conhecimento de base.
    *   Ajuda a identificar informa√ß√µes relevantes que podem n√£o ser encontradas apenas com a *query* original.

*   **Desafios:**
    *   Requer que o LLM tenha um bom entendimento do dom√≠nio e da rela√ß√£o entre diferentes conceitos.
    *   A gera√ß√£o de *queries* de "n√≠vel superior" relevantes pode ser dif√≠cil para *queries* muito espec√≠ficas ou complexas.

> üí° **Exemplo Num√©rico:**
>
> Suponha que executamos a query original e a query de "n√≠vel superior" e obtivemos os seguintes resultados para os top-3 documentos:
>
> | Documento | Score (Query Original) | Score (Step-Back Query) |
> | --------- | ---------------------- | ----------------------- |
> | 1         | 0.9                    | 0.3                     |
> | 2         | 0.7                    | 0.6                     |
> | 3         | 0.6                    | 0.8                     |
>
> Para combinar esses resultados, podemos usar uma m√©dia ponderada:
>
> $\text{Final Score (Document i)} = \alpha \times \text{Score Original (Document i)} + (1 - \alpha) \times \text{Score Step-Back (Document i)}$
>
> Se $\alpha = 0.6$ (mais peso para a query original), ent√£o:
>
> | Documento | Final Score |
> | --------- | ----------- |
> | 1         | 0.66        |
> | 2         | 0.64        |
> | 3         | 0.68        |
>
> Neste caso, o Documento 3, que tinha um score mais alto na query de "n√≠vel superior", se torna o mais relevante ap√≥s a combina√ß√£o, demonstrando como o *step-back prompting* pode alterar a ordem dos resultados.

**Lema 2:** A escolha do n√≠vel de abstra√ß√£o na query gerada por *step-back prompting* influencia diretamente no balan√ßo entre precis√£o e revoca√ß√£o. Um n√≠vel muito abstrato pode aumentar a revoca√ß√£o, mas diminuir a precis√£o, e vice-versa.

*Prova (Esbo√ßo):* Queries de n√≠vel superior muito gen√©ricas podem recuperar muitos documentos irrelevantes (aumentando a revoca√ß√£o mas diminuindo a precis√£o), enquanto queries excessivamente espec√≠ficas podem perder informa√ß√µes contextuais importantes (diminuindo a revoca√ß√£o).

**2.1 Adapta√ß√£o Iterativa do *Step-Back Prompting***

Uma extens√£o do *step-back prompting* √© a adapta√ß√£o iterativa.  Nesta abordagem, a *query* de "n√≠vel superior" gerada inicialmente √© refinada em itera√ß√µes subsequentes, com base nos resultados da recupera√ß√£o inicial. O LLM pode analisar os documentos recuperados e ajustar a *query* de "n√≠vel superior" para melhor focar em aspectos relevantes do contexto.

**3. Reescrita de Query:**

A reescrita de *query* envolve a modifica√ß√£o da *query* original usando um LLM para melhorar sua clareza, especificidade ou adequa√ß√£o ao modelo de recupera√ß√£o subjacente [^1]. Isso pode incluir a expans√£o da *query* com sin√¥nimos, a corre√ß√£o de erros gramaticais, a remo√ß√£o de termos irrelevantes ou a reformula√ß√£o da *query* para melhor corresponder √† estrutura dos documentos no √≠ndice.

*   **Processo:**
    1.  O LLM recebe a *query* original como entrada.
    2.  O LLM analisa a *query* e identifica poss√≠veis melhorias.
    3.  O LLM reescreve a *query* com base nas melhorias identificadas.
    4.  A *query* reescrita √© usada para recuperar documentos relevantes.

*   **Exemplo:**
    *Query* original: *"melhor hotel paris"*

    *Query* reescrita pelo LLM: *"melhores hot√©is em Paris com boa avalia√ß√£o dos clientes e localiza√ß√£o central"*

    A *query* reescrita √© mais espec√≠fica e inclui crit√©rios importantes para a sele√ß√£o de um hotel, o que deve levar a resultados de pesquisa mais relevantes.

*   **Vantagens:**
    *   Melhora a precis√£o e a relev√¢ncia dos resultados da pesquisa.
    *   Pode corrigir erros e ambiguidades na *query* original.
    *   Adapta a *query* para melhor corresponder ao modelo de recupera√ß√£o subjacente.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um pequeno exemplo para ilustrar como a reescrita de query pode impactar o TF-IDF. Suponha que temos os seguintes:
>
> *   **Query Original:** "ma√ß√£"
> *   **Query reescrita:** "receitas com ma√ß√£"
> *   **Documento:** "Esta receita usa ma√ß√£ Fuji. √â uma deliciosa receita de outono."
>
> Vamos calcular o TF-IDF para ambas as queries. Primeiro, definimos um vocabul√°rio simplificado: {"ma√ß√£", "receita", "com", "fuji", "esta", "usa", "√©", "uma", "de", "outono", "deliciosa"}.
>
> **C√°lculo TF (Term Frequency):**
>
> *   **TF (Query Original, "ma√ß√£")**: 1/1 = 1
> *   **TF (Query Reescrita, "ma√ß√£")**: 1/3 = 0.33
> *   **TF (Query Reescrita, "receitas")**: 1/3 = 0.33
> *   **TF (Query Reescrita, "com")**: 1/3 = 0.33
> *   **TF (Documento, "ma√ß√£")**: 1/11 = 0.09
> *   **TF (Documento, "receita")**: 2/11 = 0.18
>
> **C√°lculo IDF (Inverse Document Frequency):**
>
> Assumindo que temos 10 documentos no total, e:
>
> *   "ma√ß√£" aparece em 5 documentos.  $\text{IDF("ma√ß√£")} = log(10/5) = 0.30$
> *   "receita" aparece em 3 documentos.  $\text{IDF("receita")} = log(10/3) = 0.52$
> *   "com" aparece em 8 documentos.  $\text{IDF("com")} = log(10/8) = 0.09$
>
> **C√°lculo TF-IDF:**
>
> *   **TF-IDF (Query Original, "ma√ß√£")**: 1 * 0.30 = 0.30
> *   **TF-IDF (Query Reescrita, "ma√ß√£")**: 0.33 * 0.30 = 0.10
> *   **TF-IDF (Query Reescrita, "receitas")**: 0.33 * 0.52 = 0.17
> *   **TF-IDF (Query Reescrita, "com")**: 0.33 * 0.09 = 0.03
>
> **Score do Documento:** (Considerando apenas os termos da query)
>
> *   **Score (Query Original)**:  0.09 (TF da "ma√ß√£" no documento) * 0.30 (IDF da "ma√ß√£") = 0.027
> *   **Score (Query Reescrita)**: (0.09 * 0.30) + (0.18 * 0.52) = 0.027 + 0.094 = 0.121
>
> Neste exemplo simplificado, a *query* reescrita, ao incluir termos adicionais como "receitas", aumentou o score do documento porque o documento continha a palavra "receita" com uma frequ√™ncia relativamente alta. Isto demonstra como a reescrita de query, mesmo com t√©cnicas simples como TF-IDF, pode impactar a relev√¢ncia dos documentos recuperados.

**Proposi√ß√£o 1:** A efic√°cia da reescrita de query depende criticamente da qualidade e cobertura do vocabul√°rio utilizado pelo LLM, especialmente em dom√≠nios espec√≠ficos onde a terminologia pode ser especializada.

*Prova (Esbo√ßo):* Um LLM com vocabul√°rio limitado pode n√£o ser capaz de expandir a query original com sin√¥nimos relevantes ou corrigir ambiguidades de forma precisa, resultando em uma query reescrita que n√£o melhora (ou at√© piora) os resultados da recupera√ß√£o.

**3.1 Reescrita de Query Sens√≠vel ao Contexto do Usu√°rio:**

Uma abordagem promissora √© a reescrita de query sens√≠vel ao contexto do usu√°rio. Isso envolve a utiliza√ß√£o do hist√≥rico de pesquisa do usu√°rio, suas prefer√™ncias declaradas e outras informa√ß√µes contextuais para personalizar a reescrita da query. Por exemplo, se um usu√°rio pesquisa frequentemente sobre "energia solar", o LLM pode reescrever queries relacionadas a "energia" para incluir explicitamente o termo "solar", mesmo que a query original n√£o o mencione.





![Diagrama ilustrativo da transforma√ß√£o de consultas em um sistema RAG, mostrando a decomposi√ß√£o e o enriquecimento da consulta inicial para melhorar a recupera√ß√£o.](./../images/image5.png)

### Conclus√£o

As transforma√ß√µes de *query* utilizando LLMs representam uma abordagem poderosa para melhorar a efic√°cia da Recupera√ß√£o de Informa√ß√£o Neural [^1]. Atrav√©s da decomposi√ß√£o de *queries*, do *step-back prompting* e da reescrita de *queries*, os LLMs podem ajudar a superar as limita√ß√µes dos modelos de recupera√ß√£o tradicionais e a fornecer resultados de pesquisa mais precisos e abrangentes. No entanto, √© crucial considerar os desafios associados a cada t√©cnica, como a depend√™ncia da capacidade do LLM, a complexidade da combina√ß√£o de resultados e o risco de introduzir vi√©s. O desenvolvimento cont√≠nuo de t√©cnicas de transforma√ß√£o de *query* e a avalia√ß√£o rigorosa de seu impacto na qualidade da recupera√ß√£o s√£o essenciais para o avan√ßo da √°rea de NIR.

### Refer√™ncias

[^1]: Informa√ß√£o retirada do contexto fornecido: "Query transformations utilize LLMs to modify user input and improve retrieval quality. Techniques include query decomposition, step-back prompting, and query re-writing."
<!-- END -->