## Transforma√ß√µes de Query em RAG: Step-Back Prompting e Query Rewriting

### Introdu√ß√£o

As transforma√ß√µes de query representam um conjunto de t√©cnicas cruciais para otimizar o desempenho de sistemas de *Retrieval-Augmented Generation* (RAG) em *Neural Information Retrieval*. Em particular, o *step-back prompting* e o *query rewriting* s√£o abordagens que exploram a capacidade dos *Large Language Models* (LLMs) para refinar e contextualizar as consultas originais, resultando em um processo de recupera√ß√£o de informa√ß√£o mais eficaz e respostas mais precisas. Este cap√≠tulo se aprofunda nessas duas t√©cnicas, explorando seus mecanismos, benef√≠cios e implementa√ß√µes pr√°ticas.

### Conceitos Fundamentais

#### Step-Back Prompting

O *step-back prompting* √© uma t√©cnica que visa melhorar a qualidade do contexto recuperado, instruindo o LLM a gerar uma query mais gen√©rica a partir da consulta original [^n√∫mero]. O objetivo √© obter um contexto de alto n√≠vel que sirva como base para responder √† consulta original, fornecendo uma compreens√£o mais ampla do t√≥pico em quest√£o [^n√∫mero].

O processo envolve as seguintes etapas:

1.  **Recebimento da Query Original:** O sistema RAG recebe a consulta inicial do usu√°rio.
2.  **Gera√ß√£o da Query Gen√©rica:** O LLM √© solicitado a gerar uma query mais gen√©rica, "retrocedendo" na especificidade da consulta original. Essa nova query foca em aspectos mais amplos e fundamentais relacionados ao t√≥pico.
3.  **Recupera√ß√£o de Contexto de Alto N√≠vel:** A query gen√©rica √© utilizada para recuperar informa√ß√µes de alto n√≠vel de um banco de dados de conhecimento ou corpus documental.
4.  **Retorno √† Query Original:** O contexto de alto n√≠vel recuperado √© combinado com a query original. Essa combina√ß√£o serve como input para o LLM gerar a resposta final.

**Exemplo:**

Suponha que a query original seja: "Quais foram os principais desafios enfrentados durante a constru√ß√£o da Ponte Golden Gate?".

O *step-back prompting* pode gerar a seguinte query gen√©rica: "Hist√≥ria e engenharia de pontes suspensas".

A informa√ß√£o recuperada com a query gen√©rica fornece um contexto mais amplo sobre os princ√≠pios de engenharia de pontes suspensas e os desafios comuns enfrentados em projetos semelhantes. Esse contexto, combinado com a query original, permite que o LLM gere uma resposta mais completa e precisa.

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um corpus de documentos e a query original √© $Q_o$ = "Efeitos da globaliza√ß√£o na economia brasileira". Ap√≥s o *step-back prompting*, a query gen√©rica gerada √© $Q_g$ = "Globaliza√ß√£o e seus impactos econ√¥micos".
>
> Para ilustrar a relev√¢ncia, podemos imaginar que a recupera√ß√£o com $Q_o$ retorna documentos com relev√¢ncia m√©dia de 0.6 (em uma escala de 0 a 1). No entanto, a recupera√ß√£o com $Q_g$ retorna documentos com relev√¢ncia m√©dia de 0.8 para o contexto geral, que, ao serem combinados com os documentos recuperados por $Q_o$, elevam a relev√¢ncia m√©dia final da resposta para 0.75.
>
> Este aumento de relev√¢ncia demonstra o benef√≠cio de fornecer um contexto mais amplo para o LLM.
>
> A relev√¢ncia poderia ser calculada usando m√©tricas como o nDCG (Normalized Discounted Cumulative Gain) para avaliar a qualidade da ordena√ß√£o dos documentos recuperados.

Para formalizar um pouco mais essa ideia, podemos definir a fun√ß√£o de *step-back prompting* da seguinte forma:

**Defini√ß√£o 1:** Seja $Q_o$ a query original. A fun√ß√£o de *step-back prompting* $S(Q_o)$ retorna uma query gen√©rica $Q_g$ tal que $Q_g$ abrange um contexto mais amplo que $Q_o$. Formalmente, $S: Q_o \mapsto Q_g$, onde o escopo de $Q_g$ $\supseteq$ o escopo de $Q_o$.

**Teorema 1:** A utiliza√ß√£o do *step-back prompting* pode melhorar a precis√£o da resposta gerada pelo sistema RAG.

*Prova (Esbo√ßo):* Ao introduzir um contexto de alto n√≠vel atrav√©s da query gen√©rica, o LLM tem acesso a informa√ß√µes fundamentais e princ√≠pios relacionados ao t√≥pico da query original. Isso permite que o LLM filtre informa√ß√µes irrelevantes e concentre-se em detalhes mais relevantes, resultando em uma resposta mais precisa. A combina√ß√£o do contexto gen√©rico com a query original atua como um filtro, direcionando a aten√ß√£o do LLM para os aspectos mais importantes da quest√£o. $\blacksquare$

<!-- NEW CONTENT -->
**Lema 1.1:** A efic√°cia do *step-back prompting* depende da relev√¢ncia do contexto de alto n√≠vel recuperado.

*Prova (Esbo√ßo):* Se a query gen√©rica $Q_g$ recuperar informa√ß√µes que n√£o s√£o relevantes para a query original $Q_o$, o contexto de alto n√≠vel pode introduzir ru√≠do e diminuir a precis√£o da resposta gerada pelo LLM. Portanto, √© crucial que $Q_g$ seja cuidadosamente elaborada para garantir que o contexto recuperado esteja relacionado ao t√≥pico de $Q_o$. A similaridade sem√¢ntica entre $Q_g$ e $Q_o$ √© um fator determinante para a relev√¢ncia do contexto. $\blacksquare$

**Teorema 1.1:** A combina√ß√£o √≥tima entre a query original e o contexto recuperado via *step-back prompting* √© aquela que maximiza a informa√ß√£o m√∫tua entre o contexto e a resposta correta.

*Prova (Esbo√ßo):* Seja $C$ o contexto recuperado usando a query gen√©rica $Q_g$, e seja $A$ a resposta correta para a query original $Q_o$. O objetivo √© maximizar $I(C; A)$, onde $I$ representa a informa√ß√£o m√∫tua. Isso implica encontrar um $Q_g$ que capture o contexto $C$ mais relevante para a gera√ß√£o da resposta $A$. T√©cnicas de otimiza√ß√£o podem ser aplicadas para ajustar o LLM e refinar a gera√ß√£o de $Q_g$ de forma a maximizar $I(C; A)$. $\blacksquare$
<!-- END NEW CONTENT -->

#### Query Rewriting

O *query rewriting* √© uma t√©cnica que utiliza LLMs para reformular as queries iniciais, visando otimizar a recupera√ß√£o de informa√ß√µes relevantes [^n√∫mero]. O objetivo √© melhorar a clareza, precis√£o e relev√¢ncia da consulta, de forma que ela se alinhe melhor com a estrutura e o conte√∫do do banco de dados de conhecimento [^n√∫mero].

A LlamaIndex oferece uma solu√ß√£o robusta para *query rewriting*, aproveitando a capacidade dos LLMs para:

*   **Corrigir erros ortogr√°ficos e gramaticais:** O LLM pode identificar e corrigir erros na query original, garantindo que ela seja processada corretamente pelo sistema de recupera√ß√£o.
*   **Expandir a query com sin√¥nimos e termos relacionados:** O LLM pode adicionar sin√¥nimos e termos relacionados √† query original, aumentando a probabilidade de recuperar documentos relevantes que utilizem diferentes vocabul√°rios.
*   **Desambiguar termos amb√≠guos:** O LLM pode identificar termos amb√≠guos na query original e adicionar contexto para esclarecer o significado pretendido.
*   **Reformular a query para melhor corresponder √† estrutura do banco de dados de conhecimento:** O LLM pode reformular a query para que ela se alinhe melhor com a forma como as informa√ß√µes s√£o organizadas e indexadas no banco de dados de conhecimento.

**Exemplo:**

Suponha que a query original seja: "O que √© NLP?".

O *query rewriting* pode transformar essa query em: "Defini√ß√£o e aplica√ß√µes de Processamento de Linguagem Natural".

Essa reformula√ß√£o torna a query mais espec√≠fica e direcionada, aumentando a probabilidade de recuperar documentos relevantes que forne√ßam uma defini√ß√£o clara e exemplos de aplica√ß√µes de NLP.

> üí° **Exemplo Num√©rico:**
>
> Considere um sistema de recupera√ß√£o onde a query original $Q_o$ = "melhor celular samsung" retorna os seguintes resultados com scores de relev√¢ncia:
>
> | Documento                                     | Score de Relev√¢ncia |
> | --------------------------------------------- | ------------------- |
> | "Review do Samsung A52"                       | 0.5                 |
> | "Comparativo de celulares Android"              | 0.4                 |
> | "Samsung lan√ßa novo modelo de TV"           | 0.2                 |
>
> Ap√≥s o *query rewriting*, a query se torna $Q_r$ = "melhores smartphones Samsung com bom custo-benef√≠cio em 2024". Os resultados agora s√£o:
>
> | Documento                                                     | Score de Relev√¢ncia |
> | ------------------------------------------------------------- | ------------------- |
> | "Guia de compra: Melhores celulares Samsung custo-benef√≠cio 2024" | 0.8                 |
> | "Review do Samsung A54: vale a pena?"                         | 0.7                 |
> | "Samsung A34 vs A54: Qual o melhor para voc√™?"              | 0.6                 |
>
> O *query rewriting* melhorou significativamente a relev√¢ncia dos resultados, como evidenciado pelos scores mais altos. Isso demonstra como reformular a query pode direcionar melhor a busca no banco de dados de conhecimento.

Podemos formalizar o *query rewriting* da seguinte forma:

**Defini√ß√£o 2:** Seja $Q_o$ a query original. A fun√ß√£o de *query rewriting* $R(Q_o)$ retorna uma query reformulada $Q_r$ tal que $Q_r$ √© semanticamente equivalente a $Q_o$, mas otimizada para recupera√ß√£o de informa√ß√£o. Formalmente, $R: Q_o \mapsto Q_r$, onde a inten√ß√£o de $Q_r$ √© a mesma de $Q_o$, mas a forma de $Q_r$ √© adaptada para o sistema de recupera√ß√£o.

**Teorema 2:** O *query rewriting* pode aumentar a taxa de recupera√ß√£o de documentos relevantes em um sistema RAG.

*Prova (Esbo√ßo):* Ao corrigir erros, expandir com sin√¥nimos e desambiguar termos, o *query rewriting* aumenta a probabilidade de que a query reformulada corresponda aos termos e conceitos utilizados nos documentos relevantes. Isso leva a uma maior sobreposi√ß√£o entre a query e os documentos, resultando em uma maior taxa de recupera√ß√£o. $\blacksquare$

<!-- NEW CONTENT -->
**Lema 2.1:** A efic√°cia do *query rewriting* depende da qualidade do LLM utilizado para a reformula√ß√£o.

*Prova (Esbo√ßo):* Se o LLM n√£o for capaz de identificar e corrigir erros com precis√£o, ou se adicionar sin√¥nimos irrelevantes ou desambigua√ß√µes incorretas, o *query rewriting* pode, na verdade, diminuir a taxa de recupera√ß√£o. Portanto, √© crucial utilizar um LLM bem treinado e ajustado para a tarefa de *query rewriting*. A capacidade do LLM de compreender a sem√¢ntica da query original e de gerar reformula√ß√µes relevantes √© fundamental para o sucesso do *query rewriting*. $\blacksquare$

**Proposi√ß√£o 1:** A combina√ß√£o de *step-back prompting* e *query rewriting* pode levar a um desempenho superior em sistemas RAG comparado ao uso de apenas uma das t√©cnicas.

*Prova (Esbo√ßo):* O *step-back prompting* fornece um contexto de alto n√≠vel que enriquece a compreens√£o do LLM sobre a query original. Em seguida, o *query rewriting* otimiza a query original (ou a query combinada com o contexto) para uma recupera√ß√£o mais precisa. A combina√ß√£o sin√©rgica dessas duas t√©cnicas permite que o sistema RAG explore tanto o contexto amplo quanto os detalhes espec√≠ficos da query, resultando em respostas mais completas e relevantes. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha um cen√°rio onde inicialmente o sistema RAG, sem nenhuma transforma√ß√£o de query, atinge uma precis√£o de 60% e um recall de 50%.
>
> Aplicando apenas *step-back prompting*, a precis√£o sobe para 65% e o recall para 55%.
>
> Aplicando apenas *query rewriting*, a precis√£o sobe para 70% e o recall para 60%.
>
> Combinando ambas as t√©cnicas, a precis√£o atinge 75% e o recall 65%. Essa melhoria sin√©rgica demonstra a proposi√ß√£o. A tabela abaixo resume os resultados:
>
> | M√©todo                              | Precis√£o | Recall |
> | ----------------------------------- | -------- | ------ |
> | Sem Transforma√ß√£o                   | 60%      | 50%    |
> | Apenas Step-Back Prompting          | 65%      | 55%    |
> | Apenas Query Rewriting              | 70%      | 60%    |
> | Step-Back Prompting + Query Rewriting | 75%      | 65%    |

**Corol√°rio 1:** Em sistemas RAG com recursos computacionais limitados, a escolha entre *step-back prompting* e *query rewriting* deve ser baseada na natureza das queries e na estrutura do banco de dados de conhecimento. Queries complexas e bancos de dados de conhecimento mal estruturados podem se beneficiar mais do *step-back prompting*, enquanto queries simples e bancos de dados bem estruturados podem se beneficiar mais do *query rewriting*.
<!-- END NEW CONTENT -->

### Conclus√£o

Tanto o *step-back prompting* quanto o *query rewriting* representam abordagens promissoras para melhorar o desempenho de sistemas RAG. Enquanto o *step-back prompting* foca na recupera√ß√£o de contexto de alto n√≠vel para fornecer uma base mais s√≥lida para a resposta, o *query rewriting* busca otimizar a pr√≥pria query para garantir uma recupera√ß√£o mais precisa e relevante. A combina√ß√£o dessas t√©cnicas pode levar a sistemas RAG mais robustos e capazes de fornecer respostas mais informativas e contextualmente relevantes. O uso de LLMs, como demonstrado pela solu√ß√£o da LlamaIndex para *query rewriting*, √© fundamental para a implementa√ß√£o eficaz dessas transforma√ß√µes de query.

### Refer√™ncias

[^n√∫mero]: A refer√™ncia para essa afirma√ß√£o n√£o foi fornecida no contexto.
<!-- END -->