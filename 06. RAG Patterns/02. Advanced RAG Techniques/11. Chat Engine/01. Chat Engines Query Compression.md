## Chat Engines e Compress√£o de Query para Di√°logo Contextual em RAG

### Introdu√ß√£o

Em sistemas de Retrieval-Augmented Generation (RAG), a capacidade de manter o contexto do di√°logo √© crucial para fornecer respostas coerentes e relevantes em intera√ß√µes prolongadas com o usu√°rio. Os **Chat Engines** surgem como componentes essenciais para incorporar a l√≥gica de chat e o contexto do di√°logo, permitindo que o sistema entenda e responda a perguntas de acompanhamento e comandos do usu√°rio de forma eficaz [^1]. Uma t√©cnica fundamental para alcan√ßar esse objetivo √© a **compress√£o de query**, que visa condensar o hist√≥rico de intera√ß√µes em uma representa√ß√£o concisa e informativa, a qual pode ser utilizada para recuperar informa√ß√µes relevantes da base de conhecimento [^1]. Este cap√≠tulo explora os fundamentos dos Chat Engines e as t√©cnicas de compress√£o de query, detalhando como eles s√£o aplicados para resolver o desafio de manter o contexto do di√°logo em sistemas RAG.

### Conceitos Fundamentais

**Chat Engines** s√£o projetados para gerenciar o fluxo de conversas, mantendo o hist√≥rico das intera√ß√µes e utilizando-o para influenciar as respostas futuras. Ao contr√°rio dos sistemas de RAG tradicionais, que tratam cada query de forma independente, os Chat Engines consideram o contexto do di√°logo para melhorar a relev√¢ncia e a coer√™ncia das respostas. Isso √© particularmente importante em cen√°rios onde o usu√°rio faz perguntas de acompanhamento ou se refere a informa√ß√µes mencionadas em intera√ß√µes anteriores [^1].

A **compress√£o de query** √© uma t√©cnica que visa reduzir a complexidade e o tamanho da query, mantendo ao mesmo tempo sua informa√ß√£o essencial. Em contextos de di√°logo, a compress√£o de query √© utilizada para condensar o hist√≥rico de intera√ß√µes em uma representa√ß√£o compacta, que pode ser utilizada para recuperar informa√ß√µes relevantes da base de conhecimento [^1]. Existem diversas abordagens para a compress√£o de query, incluindo:

*   **Sumariza√ß√£o:** T√©cnicas de sumariza√ß√£o s√£o utilizadas para gerar um resumo conciso do hist√≥rico de intera√ß√µes, destacando os pontos-chave e as informa√ß√µes relevantes. Esse resumo pode ent√£o ser utilizado como query para o sistema de recupera√ß√£o.
*   **Sele√ß√£o de Senten√ßas:** Essa abordagem envolve a sele√ß√£o das senten√ßas mais relevantes do hist√≥rico de intera√ß√µes, que s√£o ent√£o combinadas para formar uma nova query. A sele√ß√£o de senten√ßas pode ser baseada em crit√©rios como relev√¢ncia para a pergunta atual, import√¢ncia no contexto do di√°logo e similaridade com a query original.
*   **Reformula√ß√£o de Query:** Essa t√©cnica envolve a reformula√ß√£o da query original, levando em considera√ß√£o o hist√≥rico de intera√ß√µes. A reformula√ß√£o pode envolver a adi√ß√£o de termos contextuais, a remo√ß√£o de termos amb√≠guos ou a modifica√ß√£o da estrutura da query para refletir o contexto do di√°logo.
*   **Embeddings Contextuais:** Representa√ß√µes vetoriais densas, como embeddings, podem ser utilizadas para representar o hist√≥rico de intera√ß√µes. A query original e o contexto do di√°logo s√£o convertidos em embeddings, que s√£o ent√£o combinados para gerar um novo embedding que representa a query contextualizada.

> üí° **Exemplo Num√©rico: Embeddings Contextuais**
>
> Suponha que a query original seja $Q = \text{"temperatura em S√£o Paulo"}$ e a intera√ß√£o anterior foi sobre "previs√£o do tempo". Usamos um modelo de embedding contextual (e.g., BERT) para gerar os seguintes embeddings:
>
> $\text{Embedding}(Q) = V_Q = [0.1, 0.2, 0.3, 0.4]$
>
> $\text{Embedding}(\text{"previs√£o do tempo"}) = V_H = [0.5, 0.6, 0.7, 0.8]$
>
> Podemos combinar esses embeddings usando uma m√©dia ponderada:
>
> $V_{Q'} = \alpha V_Q + (1 - \alpha) V_H$, onde $\alpha = 0.6$.
>
> $V_{Q'} = 0.6 * [0.1, 0.2, 0.3, 0.4] + 0.4 * [0.5, 0.6, 0.7, 0.8] = [0.26, 0.36, 0.46, 0.56]$
>
> O novo embedding $V_{Q'}$ representa a query comprimida e contextualizada, pronta para ser usada na etapa de recupera√ß√£o.  Este embedding √© ent√£o usado para calcular a similaridade (e.g., cosseno) com os embeddings dos documentos na base de conhecimento.

A escolha da t√©cnica de compress√£o de query depende das caracter√≠sticas do dom√≠nio, do tamanho do hist√≥rico de intera√ß√µes e dos requisitos de desempenho do sistema.

**Teorema 1:** *A compress√£o ideal de query minimiza a perda de informa√ß√£o relevante ao contexto, maximizando a efici√™ncia da recupera√ß√£o.*

*Demonstra√ß√£o (Esbo√ßo):* A compress√£o de query pode ser vista como uma transforma√ß√£o $C: Q \times H \rightarrow Q'$, onde $Q$ √© a query original, $H$ √© o hist√≥rico de intera√ß√µes, e $Q'$ √© a query comprimida. O objetivo √© encontrar uma transforma√ß√£o $C$ que minimize a dist√¢ncia sem√¢ntica entre a informa√ß√£o contida em $(Q, H)$ e a informa√ß√£o contida em $Q'$, enquanto simultaneamente reduz a complexidade computacional da recupera√ß√£o usando $Q'$. Isto pode ser formalizado usando medidas de similaridade sem√¢ntica e complexidade computacional.

**Lema 1.1:** *A utiliza√ß√£o de embeddings contextuais, treinados em corpora relevantes ao dom√≠nio, tende a preservar melhor a informa√ß√£o sem√¢ntica durante a compress√£o, quando comparada a t√©cnicas de sumariza√ß√£o baseadas em regras.*

*Demonstra√ß√£o (Esbo√ßo):* Embeddings contextuais capturam nuances sem√¢nticas atrav√©s de treinamento em grandes volumes de texto. T√©cnicas baseadas em regras, por outro lado, s√£o limitadas pela expressividade das regras definidas. Portanto, embeddings contextuais possuem maior potencial para representar fielmente o contexto.

**Implementa√ß√£o de Chat Engines com Compress√£o de Query:**

A implementa√ß√£o de um Chat Engine com compress√£o de query envolve os seguintes passos:

1.  **Captura do Hist√≥rico de Intera√ß√µes:** O sistema deve ser capaz de capturar e armazenar o hist√≥rico de intera√ß√µes com o usu√°rio, incluindo as perguntas e as respostas anteriores.
2.  **Compress√£o da Query:** A cada nova pergunta do usu√°rio, o sistema aplica uma t√©cnica de compress√£o de query para condensar o hist√≥rico de intera√ß√µes em uma representa√ß√£o compacta.
3.  **Recupera√ß√£o de Informa√ß√µes:** A query comprimida √© utilizada para recuperar informa√ß√µes relevantes da base de conhecimento. Essa etapa pode envolver o uso de t√©cnicas de similaridade sem√¢ntica ou modelos de ranking para identificar os documentos mais relevantes.
4.  **Gera√ß√£o da Resposta:** As informa√ß√µes recuperadas s√£o combinadas com a query original e o contexto do di√°logo para gerar uma resposta coerente e relevante. Essa etapa pode envolver o uso de modelos de linguagem generativos para sintetizar a resposta final.
5.  **Atualiza√ß√£o do Hist√≥rico:** A nova pergunta e a resposta gerada s√£o adicionadas ao hist√≥rico de intera√ß√µes, que ser√° utilizado para responder a perguntas futuras.



**Proposi√ß√£o 2:** *A efici√™ncia da compress√£o de query pode ser avaliada pela taxa de compress√£o (raz√£o entre o tamanho do hist√≥rico e o tamanho da query comprimida) e pela precis√£o da recupera√ß√£o (capacidade de recuperar documentos relevantes).*

> üí° **Exemplo Num√©rico: Taxa de Compress√£o e Precis√£o**
>
> Considere um hist√≥rico de intera√ß√£o com 1000 tokens. Ap√≥s a compress√£o, a query resultante tem 100 tokens. A taxa de compress√£o √©:
>
> $\text{Taxa de Compress√£o} = \frac{\text{Tamanho do Hist√≥rico}}{\text{Tamanho da Query Comprimida}} = \frac{1000}{100} = 10$
>
> Isso significa que a query foi reduzida em um fator de 10.
>
> Agora, vamos avaliar a precis√£o da recupera√ß√£o. Suponha que, sem compress√£o, a precis√£o seja de 0.8. Com a compress√£o, a precis√£o cai para 0.75. Embora a precis√£o tenha diminu√≠do um pouco, a taxa de compress√£o de 10 pode justificar essa pequena perda, dependendo dos requisitos de desempenho do sistema.
>
> | M√©todo             | Taxa de Compress√£o | Precis√£o |
> | ------------------ | -------------------- | -------- |
> | Sem Compress√£o     | 1                    | 0.80     |
> | Com Compress√£o     | 10                   | 0.75     |
> | Compress√£o Otimizada | 8                    | 0.78     |

**Corol√°rio 2.1:** *Um aumento na taxa de compress√£o nem sempre implica em uma redu√ß√£o na precis√£o da recupera√ß√£o, desde que a t√©cnica de compress√£o preserve a informa√ß√£o sem√¢ntica relevante.*





![Popular Chat Engine types within RAG architectures: context-augmented and condense-plus-context.](./../images/image6.png)

**Exemplo:**

Suponha que um usu√°rio fa√ßa a seguinte pergunta: "Quem foi Marie Curie?". O sistema responde com uma breve biografia de Marie Curie. Em seguida, o usu√°rio pergunta: "E quais foram suas principais descobertas?". Sem um Chat Engine, o sistema trataria essa segunda pergunta de forma independente, sem levar em considera√ß√£o que o usu√°rio est√° se referindo a Marie Curie. Com um Chat Engine e compress√£o de query, o sistema seria capaz de condensar o hist√≥rico de intera√ß√µes em uma representa√ß√£o que indica que o usu√°rio est√° perguntando sobre as principais descobertas de Marie Curie. Essa representa√ß√£o comprimida seria ent√£o utilizada para recuperar informa√ß√µes relevantes da base de conhecimento, permitindo que o sistema forne√ßa uma resposta precisa e contextualizada.

> üí° **Exemplo Num√©rico: Reformula√ß√£o de Query**
>
> *   **Intera√ß√£o 1:**
>     *   Usu√°rio: "Quem foi Marie Curie?"
>     *   Sistema: "Marie Curie foi uma f√≠sica e qu√≠mica polonesa e francesa..."
> *   **Intera√ß√£o 2:**
>     *   Usu√°rio: "E quais foram suas principais descobertas?"
>
> Sem compress√£o, a query para a intera√ß√£o 2 seria apenas "E quais foram suas principais descobertas?". Com reformula√ß√£o de query, poder√≠amos ter:
>
> *   **Query Reformulada:** "Quais foram as principais descobertas de Marie Curie?"
>
> Para quantificar a melhoria, podemos calcular a similaridade do cosseno entre os vetores TF-IDF da query original e da query reformulada em rela√ß√£o a documentos relevantes. Suponha que o documento relevante seja um artigo sobre as descobertas de Marie Curie.
>
> 1.  **TF-IDF da Query Original:**
>     *   "E": 0
>     *   "quais": 0.5
>     *   "foram": 0.4
>     *   "suas": 0.3
>     *   "principais": 0.6
>     *   "descobertas": 0.7
>
> $V_{original} = [0, 0.5, 0.4, 0.3, 0.6, 0.7]$
>
> 2.  **TF-IDF da Query Reformulada:**
>     *   "Quais": 0.5
>     *   "foram": 0.4
>     *   "as": 0.2
>     *   "principais": 0.6
>     *   "descobertas": 0.7
>     *   "de": 0.1
>     *   "Marie": 0.8
>     *   "Curie": 0.9
>
> $V_{reformulada} = [0.5, 0.4, 0.2, 0.6, 0.7, 0.1, 0.8, 0.9]$
>
> 3.  **TF-IDF do Documento Relevante:**
>     *   "Marie": 0.7
>     *   "Curie": 0.8
>     *   "descobertas": 0.6
>     *   "radioatividade": 0.9
>     *   "pol√¥nio": 0.7
>
> $V_{documento} = [0.7, 0.8, 0.6, 0.9, 0.7]$
>
> O c√°lculo da similaridade do cosseno entre $V_{original}$ e $V_{documento}$, e entre $V_{reformulada}$ e $V_{documento}$ mostrar√° que a query reformulada ter√° uma similaridade maior, indicando uma melhor recupera√ß√£o.

### Conclus√£o

Os Chat Engines, combinados com t√©cnicas de compress√£o de query, representam uma abordagem eficaz para lidar com o contexto do di√°logo em sistemas RAG [^1]. Ao considerar o hist√≥rico de intera√ß√µes, esses sistemas s√£o capazes de fornecer respostas mais coerentes, relevantes e personalizadas, melhorando a experi√™ncia do usu√°rio e a efic√°cia do sistema. A escolha da t√©cnica de compress√£o de query e a implementa√ß√£o do Chat Engine dependem das caracter√≠sticas do dom√≠nio e dos requisitos espec√≠ficos da aplica√ß√£o.

### Refer√™ncias
[^1]: Chat engines incorporate chat logic and dialogue context to support follow-up questions and user commands, solved via query compression techniques. The key idea is taking into account the dialogue context when responding to a query.
<!-- END -->