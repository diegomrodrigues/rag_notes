## Chat Engines e CompressÃ£o de Query para DiÃ¡logo Contextual em RAG

### IntroduÃ§Ã£o

Em sistemas de Retrieval-Augmented Generation (RAG), a capacidade de manter o contexto do diÃ¡logo Ã© crucial para fornecer respostas coerentes e relevantes em interaÃ§Ãµes prolongadas com o usuÃ¡rio. Os **Chat Engines** surgem como componentes essenciais para incorporar a lÃ³gica de chat e o contexto do diÃ¡logo, permitindo que o sistema entenda e responda a perguntas de acompanhamento e comandos do usuÃ¡rio de forma eficaz [^1]. Uma tÃ©cnica fundamental para alcanÃ§ar esse objetivo Ã© a **compressÃ£o de query**, que visa condensar o histÃ³rico de interaÃ§Ãµes em uma representaÃ§Ã£o concisa e informativa, a qual pode ser utilizada para recuperar informaÃ§Ãµes relevantes da base de conhecimento [^1]. Este capÃ­tulo explora os fundamentos dos Chat Engines e as tÃ©cnicas de compressÃ£o de query, detalhando como eles sÃ£o aplicados para resolver o desafio de manter o contexto do diÃ¡logo em sistemas RAG.

### Conceitos Fundamentais

**Chat Engines** sÃ£o projetados para gerenciar o fluxo de conversas, mantendo o histÃ³rico das interaÃ§Ãµes e utilizando-o para influenciar as respostas futuras. Ao contrÃ¡rio dos sistemas de RAG tradicionais, que tratam cada query de forma independente, os Chat Engines consideram o contexto do diÃ¡logo para melhorar a relevÃ¢ncia e a coerÃªncia das respostas. Isso Ã© particularmente importante em cenÃ¡rios onde o usuÃ¡rio faz perguntas de acompanhamento ou se refere a informaÃ§Ãµes mencionadas em interaÃ§Ãµes anteriores [^1].

A **compressÃ£o de query** Ã© uma tÃ©cnica que visa reduzir a complexidade e o tamanho da query, mantendo ao mesmo tempo sua informaÃ§Ã£o essencial. Em contextos de diÃ¡logo, a compressÃ£o de query Ã© utilizada para condensar o histÃ³rico de interaÃ§Ãµes em uma representaÃ§Ã£o compacta, que pode ser utilizada para recuperar informaÃ§Ãµes relevantes da base de conhecimento [^1]. Existem diversas abordagens para a compressÃ£o de query, incluindo:

*   **SumarizaÃ§Ã£o:** TÃ©cnicas de sumarizaÃ§Ã£o sÃ£o utilizadas para gerar um resumo conciso do histÃ³rico de interaÃ§Ãµes, destacando os pontos-chave e as informaÃ§Ãµes relevantes. Esse resumo pode entÃ£o ser utilizado como query para o sistema de recuperaÃ§Ã£o.
*   **SeleÃ§Ã£o de SentenÃ§as:** Essa abordagem envolve a seleÃ§Ã£o das sentenÃ§as mais relevantes do histÃ³rico de interaÃ§Ãµes, que sÃ£o entÃ£o combinadas para formar uma nova query. A seleÃ§Ã£o de sentenÃ§as pode ser baseada em critÃ©rios como relevÃ¢ncia para a pergunta atual, importÃ¢ncia no contexto do diÃ¡logo e similaridade com a query original.
*   **ReformulaÃ§Ã£o de Query:** Essa tÃ©cnica envolve a reformulaÃ§Ã£o da query original, levando em consideraÃ§Ã£o o histÃ³rico de interaÃ§Ãµes. A reformulaÃ§Ã£o pode envolver a adiÃ§Ã£o de termos contextuais, a remoÃ§Ã£o de termos ambÃ­guos ou a modificaÃ§Ã£o da estrutura da query para refletir o contexto do diÃ¡logo.
*   **Embeddings Contextuais:** RepresentaÃ§Ãµes vetoriais densas, como embeddings, podem ser utilizadas para representar o histÃ³rico de interaÃ§Ãµes. A query original e o contexto do diÃ¡logo sÃ£o convertidos em embeddings, que sÃ£o entÃ£o combinados para gerar um novo embedding que representa a query contextualizada.

> ðŸ’¡ **Exemplo NumÃ©rico: Embeddings Contextuais**
>
> Suponha que a query original seja $Q = \text{"temperatura em SÃ£o Paulo"}$ e a interaÃ§Ã£o anterior foi sobre "previsÃ£o do tempo". Usamos um modelo de embedding contextual (e.g., BERT) para gerar os seguintes embeddings:
>
> $\text{Embedding}(Q) = V_Q = [0.1, 0.2, 0.3, 0.4]$
>
> $\text{Embedding}(\text{"previsÃ£o do tempo"}) = V_H = [0.5, 0.6, 0.7, 0.8]$
>
> Podemos combinar esses embeddings usando uma mÃ©dia ponderada:
>
> $V_{Q'} = \alpha V_Q + (1 - \alpha) V_H$, onde $\alpha = 0.6$.
>
> $V_{Q'} = 0.6 * [0.1, 0.2, 0.3, 0.4] + 0.4 * [0.5, 0.6, 0.7, 0.8] = [0.26, 0.36, 0.46, 0.56]$
>
> O novo embedding $V_{Q'}$ representa a query comprimida e contextualizada, pronta para ser usada na etapa de recuperaÃ§Ã£o.  Este embedding Ã© entÃ£o usado para calcular a similaridade (e.g., cosseno) com os embeddings dos documentos na base de conhecimento.

A escolha da tÃ©cnica de compressÃ£o de query depende das caracterÃ­sticas do domÃ­nio, do tamanho do histÃ³rico de interaÃ§Ãµes e dos requisitos de desempenho do sistema.

**Teorema 1:** *A compressÃ£o ideal de query minimiza a perda de informaÃ§Ã£o relevante ao contexto, maximizando a eficiÃªncia da recuperaÃ§Ã£o.*

*DemonstraÃ§Ã£o (EsboÃ§o):* A compressÃ£o de query pode ser vista como uma transformaÃ§Ã£o $C: Q \times H \rightarrow Q'$, onde $Q$ Ã© a query original, $H$ Ã© o histÃ³rico de interaÃ§Ãµes, e $Q'$ Ã© a query comprimida. O objetivo Ã© encontrar uma transformaÃ§Ã£o $C$ que minimize a distÃ¢ncia semÃ¢ntica entre a informaÃ§Ã£o contida em $(Q, H)$ e a informaÃ§Ã£o contida em $Q'$, enquanto simultaneamente reduz a complexidade computacional da recuperaÃ§Ã£o usando $Q'$. Isto pode ser formalizado usando medidas de similaridade semÃ¢ntica e complexidade computacional.

**Lema 1.1:** *A utilizaÃ§Ã£o de embeddings contextuais, treinados em corpora relevantes ao domÃ­nio, tende a preservar melhor a informaÃ§Ã£o semÃ¢ntica durante a compressÃ£o, quando comparada a tÃ©cnicas de sumarizaÃ§Ã£o baseadas em regras.*

*DemonstraÃ§Ã£o (EsboÃ§o):* Embeddings contextuais capturam nuances semÃ¢nticas atravÃ©s de treinamento em grandes volumes de texto. TÃ©cnicas baseadas em regras, por outro lado, sÃ£o limitadas pela expressividade das regras definidas. Portanto, embeddings contextuais possuem maior potencial para representar fielmente o contexto.

**ImplementaÃ§Ã£o de Chat Engines com CompressÃ£o de Query:**

A implementaÃ§Ã£o de um Chat Engine com compressÃ£o de query envolve os seguintes passos:

1.  **Captura do HistÃ³rico de InteraÃ§Ãµes:** O sistema deve ser capaz de capturar e armazenar o histÃ³rico de interaÃ§Ãµes com o usuÃ¡rio, incluindo as perguntas e as respostas anteriores.
2.  **CompressÃ£o da Query:** A cada nova pergunta do usuÃ¡rio, o sistema aplica uma tÃ©cnica de compressÃ£o de query para condensar o histÃ³rico de interaÃ§Ãµes em uma representaÃ§Ã£o compacta.
3.  **RecuperaÃ§Ã£o de InformaÃ§Ãµes:** A query comprimida Ã© utilizada para recuperar informaÃ§Ãµes relevantes da base de conhecimento. Essa etapa pode envolver o uso de tÃ©cnicas de similaridade semÃ¢ntica ou modelos de ranking para identificar os documentos mais relevantes.
4.  **GeraÃ§Ã£o da Resposta:** As informaÃ§Ãµes recuperadas sÃ£o combinadas com a query original e o contexto do diÃ¡logo para gerar uma resposta coerente e relevante. Essa etapa pode envolver o uso de modelos de linguagem generativos para sintetizar a resposta final.
5.  **AtualizaÃ§Ã£o do HistÃ³rico:** A nova pergunta e a resposta gerada sÃ£o adicionadas ao histÃ³rico de interaÃ§Ãµes, que serÃ¡ utilizado para responder a perguntas futuras.



**ProposiÃ§Ã£o 2:** *A eficiÃªncia da compressÃ£o de query pode ser avaliada pela taxa de compressÃ£o (razÃ£o entre o tamanho do histÃ³rico e o tamanho da query comprimida) e pela precisÃ£o da recuperaÃ§Ã£o (capacidade de recuperar documentos relevantes).*

> ðŸ’¡ **Exemplo NumÃ©rico: Taxa de CompressÃ£o e PrecisÃ£o**
>
> Considere um histÃ³rico de interaÃ§Ã£o com 1000 tokens. ApÃ³s a compressÃ£o, a query resultante tem 100 tokens. A taxa de compressÃ£o Ã©:
>
> $\text{Taxa de CompressÃ£o} = \frac{\text{Tamanho do HistÃ³rico}}{\text{Tamanho da Query Comprimida}} = \frac{1000}{100} = 10$
>
> Isso significa que a query foi reduzida em um fator de 10.
>
> Agora, vamos avaliar a precisÃ£o da recuperaÃ§Ã£o. Suponha que, sem compressÃ£o, a precisÃ£o seja de 0.8. Com a compressÃ£o, a precisÃ£o cai para 0.75. Embora a precisÃ£o tenha diminuÃ­do um pouco, a taxa de compressÃ£o de 10 pode justificar essa pequena perda, dependendo dos requisitos de desempenho do sistema.
>
> | MÃ©todo             | Taxa de CompressÃ£o | PrecisÃ£o |
> | ------------------ | -------------------- | -------- |
> | Sem CompressÃ£o     | 1                    | 0.80     |
> | Com CompressÃ£o     | 10                   | 0.75     |
> | CompressÃ£o Otimizada | 8                    | 0.78     |

**CorolÃ¡rio 2.1:** *Um aumento na taxa de compressÃ£o nem sempre implica em uma reduÃ§Ã£o na precisÃ£o da recuperaÃ§Ã£o, desde que a tÃ©cnica de compressÃ£o preserve a informaÃ§Ã£o semÃ¢ntica relevante.*





![Popular Chat Engine types within RAG architectures: context-augmented and condense-plus-context.](./../images/image6.png)

**Exemplo:**

Suponha que um usuÃ¡rio faÃ§a a seguinte pergunta: "Quem foi Marie Curie?". O sistema responde com uma breve biografia de Marie Curie. Em seguida, o usuÃ¡rio pergunta: "E quais foram suas principais descobertas?". Sem um Chat Engine, o sistema trataria essa segunda pergunta de forma independente, sem levar em consideraÃ§Ã£o que o usuÃ¡rio estÃ¡ se referindo a Marie Curie. Com um Chat Engine e compressÃ£o de query, o sistema seria capaz de condensar o histÃ³rico de interaÃ§Ãµes em uma representaÃ§Ã£o que indica que o usuÃ¡rio estÃ¡ perguntando sobre as principais descobertas de Marie Curie. Essa representaÃ§Ã£o comprimida seria entÃ£o utilizada para recuperar informaÃ§Ãµes relevantes da base de conhecimento, permitindo que o sistema forneÃ§a uma resposta precisa e contextualizada.

> ðŸ’¡ **Exemplo NumÃ©rico: ReformulaÃ§Ã£o de Query**
>
> *   **InteraÃ§Ã£o 1:**
>     *   UsuÃ¡rio: "Quem foi Marie Curie?"
>     *   Sistema: "Marie Curie foi uma fÃ­sica e quÃ­mica polonesa e francesa..."
> *   **InteraÃ§Ã£o 2:**
>     *   UsuÃ¡rio: "E quais foram suas principais descobertas?"
>
> Sem compressÃ£o, a query para a interaÃ§Ã£o 2 seria apenas "E quais foram suas principais descobertas?". Com reformulaÃ§Ã£o de query, poderÃ­amos ter:
>
> *   **Query Reformulada:** "Quais foram as principais descobertas de Marie Curie?"
>
> Para quantificar a melhoria, podemos calcular a similaridade do cosseno entre os vetores TF-IDF da query original e da query reformulada em relaÃ§Ã£o a documentos relevantes. Suponha que o documento relevante seja um artigo sobre as descobertas de Marie Curie.
>
> 1.  **TF-IDF da Query Original:**
>     *   "E": 0
>     *   "quais": 0.5
>     *   "foram": 0.4
>     *   "suas": 0.3
>     *   "principais": 0.6
>     *   "descobertas": 0.7
>
> $V_{original} = [0, 0.5, 0.4, 0.3, 0.6, 0.7]$
>
> 2.  **TF-IDF da Query Reformulada:**
>     *   "Quais": 0.5
>     *   "foram": 0.4
>     *   "as": 0.2
>     *   "principais": 0.6
>     *   "descobertas": 0.7
>     *   "de": 0.1
>     *   "Marie": 0.8
>     *   "Curie": 0.9
>
> $V_{reformulada} = [0.5, 0.4, 0.2, 0.6, 0.7, 0.1, 0.8, 0.9]$
>
> 3.  **TF-IDF do Documento Relevante:**
>     *   "Marie": 0.7
>     *   "Curie": 0.8
>     *   "descobertas": 0.6
>     *   "radioatividade": 0.9
>     *   "polÃ´nio": 0.7
>
> $V_{documento} = [0.7, 0.8, 0.6, 0.9, 0.7]$
>
> O cÃ¡lculo da similaridade do cosseno entre $V_{original}$ e $V_{documento}$, e entre $V_{reformulada}$ e $V_{documento}$ mostrarÃ¡ que a query reformulada terÃ¡ uma similaridade maior, indicando uma melhor recuperaÃ§Ã£o.

### ConclusÃ£o

Os Chat Engines, combinados com tÃ©cnicas de compressÃ£o de query, representam uma abordagem eficaz para lidar com o contexto do diÃ¡logo em sistemas RAG [^1]. Ao considerar o histÃ³rico de interaÃ§Ãµes, esses sistemas sÃ£o capazes de fornecer respostas mais coerentes, relevantes e personalizadas, melhorando a experiÃªncia do usuÃ¡rio e a eficÃ¡cia do sistema. A escolha da tÃ©cnica de compressÃ£o de query e a implementaÃ§Ã£o do Chat Engine dependem das caracterÃ­sticas do domÃ­nio e dos requisitos especÃ­ficos da aplicaÃ§Ã£o.

### ReferÃªncias
[^1]: Chat engines incorporate chat logic and dialogue context to support follow-up questions and user commands, solved via query compression techniques. The key idea is taking into account the dialogue context when responding to a query.
<!-- END -->